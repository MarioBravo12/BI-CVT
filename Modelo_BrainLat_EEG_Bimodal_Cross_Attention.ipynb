{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bi-CVT: Bimodal Convolutional Vision Transformer with Cross-Attention\n",
        "\n",
        "## Model Architecture Implementation for Alzheimer's Disease Classification\n",
        "\n",
        "### Research Paper Implementation\n",
        "**Title**: \"Bi-CVT: An Interpretable Bimodal Convolutional Vision Transformer with Cross-Attention for EEG and Clinical Data Fusion in Alzheimer's Disease Classification\"\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook implements the complete **Bi-CVT (Bimodal Convolutional Vision Transformer)** model for classifying neurodegeneration using the BrainLat dataset. The model combines EEG spectrograms and clinical data through a novel Cross-Attention mechanism to achieve state-of-the-art performance in distinguishing between:\n",
        "\n",
        "- **AD**: Alzheimer's Disease patients  \n",
        "- **bvFTD**: Behavioral variant Frontotemporal Dementia patients\n",
        "- **HC**: Healthy Controls\n",
        "\n",
        "---\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "### Core Components:\n",
        "\n",
        "#### 1. **EEG Processing Branch**\n",
        "- **Input**: 224×224×128 STFT spectrograms (time-frequency representations)\n",
        "- **Architecture**: Convolutional layers with residual connections\n",
        "- **Purpose**: Extract spectral-temporal patterns from EEG signals\n",
        "- **Output**: High-level EEG feature representations\n",
        "\n",
        "#### 2. **Clinical Data Branch**  \n",
        "- **Input**: Neuropsychological and sociodemographic features\n",
        "- **Architecture**: 1D Convolutional layers + Dense layers\n",
        "- **Purpose**: Process structured clinical assessments\n",
        "- **Output**: Clinical feature embeddings\n",
        "\n",
        "#### 3. **Cross-Attention Mechanism**\n",
        "- **Purpose**: Enable bidirectional information exchange between modalities\n",
        "- **Implementation**: Multi-Head Attention with query-key-value structure\n",
        "- **Innovation**: Allows EEG patterns to modulate clinical features and vice versa\n",
        "- **Output**: Fused multimodal representations\n",
        "\n",
        "#### 4. **Classification Head**\n",
        "- **Input**: Concatenated multimodal features\n",
        "- **Architecture**: Dense layers with dropout for regularization\n",
        "- **Output**: 3-class probability distribution (AD/bvFTD/HC)\n",
        "\n",
        "---\n",
        "\n",
        "## Expected Performance\n",
        "\n",
        "Based on the BrainLat dataset evaluation:\n",
        "- **Accuracy**: 98.4%\n",
        "- **Diagnostic Groups**: 3-class classification\n",
        "- **Validation**: Stratified train-test split with cross-validation\n",
        "- **Interpretability**: Grad-CAM and Integrated Gradients support\n",
        "\n",
        "---\n",
        "\n",
        "## Technical Specifications\n",
        "\n",
        "- **Framework**: TensorFlow/Keras 2.15+\n",
        "- **Input Modalities**: EEG spectrograms + Clinical features\n",
        "- **Training Strategy**: Multi-modal end-to-end learning\n",
        "- **Optimization**: Adam optimizer with learning rate scheduling\n",
        "- **Regularization**: Dropout, BatchNormalization, Early Stopping\n",
        "- **Hardware**: GPU recommended for efficient training\n",
        "\n",
        "---\n",
        "\n",
        "## Data Requirements\n",
        "\n",
        "- **EEG Data**: Preprocessed STFT spectrograms (.npy format)\n",
        "- **Clinical Data**: CSV file with neuropsychological assessments\n",
        "- **Labels**: Encoded diagnostic categories (0=AD, 1=HC, 2=bvFTD)\n",
        "- **Organization**: BrainLat dataset structure\n",
        "\n",
        "---\n",
        "\n",
        "## Usage Workflow\n",
        "\n",
        "1. **Environment Setup**: Install dependencies and mount data\n",
        "2. **Data Loading**: Load and pair EEG spectrograms with clinical features  \n",
        "3. **Preprocessing**: Normalize features and encode labels\n",
        "4. **Model Definition**: Build Bi-CVT architecture with Cross-Attention\n",
        "5. **Training**: Train model with validation monitoring\n",
        "6. **Evaluation**: Assess performance and generate metrics\n",
        "7. **Model Saving**: Export trained model for deployment\n",
        "\n",
        "---\n",
        "\n",
        "## References\n",
        "\n",
        "1. **BrainLat Dataset**: Prado, P. et al. Synapse (2023)\n",
        "2. **Cross-Attention**: Vaswani, A. et al. \"Attention Is All You Need\" (2017)\n",
        "3. **Vision Transformers**: Dosovitskiy, A. et al. \"An Image is Worth 16x16 Words\" (2021)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Kq1luXELUX"
      },
      "source": [
        "# Libreria\n",
        "\n",
        "## Library Imports and Dependencies\n",
        "\n",
        "### Required packages for Bi-CVT implementation\n",
        "The following libraries are essential for building and training the Bimodal Convolutional Vision Transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwmyiK0Ex71H"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# OPTIONAL: INSTALL SPECIFIC TENSORFLOW VERSION\n",
        "# =============================================================================\n",
        "# Uncomment the following line if you need to install TensorFlow 2.15\n",
        "# This version ensures compatibility with all model components and attention mechanisms\n",
        "\n",
        "# !pip install tensorflow==2.15\n",
        "\n",
        "print(\"TensorFlow installation ready. Using environment's TensorFlow version.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7ubk3qVEs3k",
        "outputId": "18c7ed63-76ef-49c2-ee1b-4e4dbc9c0d46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2-348850448.py:38: DeprecationWarning: scipy.misc is deprecated and will be removed in 2.0.0\n",
            "  from scipy import ndimage, misc, signal\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CORE PYTHON LIBRARIES\n",
        "# =============================================================================\n",
        "# Librerías esenciales\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "print(\"✓ Core Python libraries imported\")\n",
        "\n",
        "# =============================================================================\n",
        "# DATA VISUALIZATION LIBRARIES\n",
        "# =============================================================================\n",
        "# Visualización\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"✓ Visualization libraries imported\")\n",
        "\n",
        "# =============================================================================\n",
        "# TENSORFLOW AND KERAS - DEEP LEARNING FRAMEWORK\n",
        "# =============================================================================\n",
        "# TensorFlow y Keras (usa solo tensorflow.keras, NO importes keras separado)\n",
        "# Core TensorFlow import (version 2.15+ recommended)\n",
        "import tensorflow as tf\n",
        "\n",
        "# Keras layers for building the Bi-CVT architecture\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,                    # Input layer for multi-modal data\n",
        "    Dense,                    # Fully connected layers\n",
        "    Dropout,                  # Regularization layer\n",
        "    Flatten,                  # Flatten layer for shape transformation\n",
        "    Conv2D,                   # 2D convolution for EEG spectrograms\n",
        "    MaxPooling2D,             # Max pooling for dimensionality reduction\n",
        "    BatchNormalization,       # Batch normalization for training stability\n",
        "    ReLU,                     # ReLU activation function\n",
        "    AveragePooling2D,         # Average pooling layer\n",
        "    GlobalAveragePooling2D,   # Global average pooling\n",
        "    UpSampling2D,             # Upsampling layer\n",
        "    Lambda,                   # Custom lambda functions\n",
        "    Add,                      # Addition layer for residual connections\n",
        "    Concatenate               # Concatenation layer for multimodal fusion\n",
        ")\n",
        "\n",
        "# Keras models and utilities\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers, regularizers\n",
        "from tensorflow.keras import layers  # Additional layers module\n",
        "\n",
        "# Import keras for compatibility (if needed)\n",
        "import keras\n",
        "\n",
        "print(\"✓ TensorFlow/Keras libraries imported\")\n",
        "\n",
        "# =============================================================================\n",
        "# MACHINE LEARNING AND EVALUATION LIBRARIES\n",
        "# =============================================================================\n",
        "# Machine Learning y métricas\n",
        "# Data preprocessing and model selection\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, label_binarize\n",
        "\n",
        "# Comprehensive evaluation metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,           # Classification accuracy\n",
        "    precision_score,          # Precision metric\n",
        "    recall_score,             # Recall (sensitivity) metric\n",
        "    f1_score,                 # F1-score (harmonic mean of precision/recall)\n",
        "    confusion_matrix,         # Confusion matrix\n",
        "    classification_report,    # Detailed classification report\n",
        "    roc_curve,                # ROC curve data\n",
        "    auc,                      # Area under curve\n",
        "    cohen_kappa_score,        # Cohen's kappa for inter-rater agreement\n",
        "    hamming_loss,             # Hamming loss for multi-label classification\n",
        "    log_loss,                 # Logarithmic loss\n",
        "    zero_one_loss,            # Zero-one loss\n",
        "    matthews_corrcoef         # Matthews correlation coefficient\n",
        ")\n",
        "\n",
        "print(\"✓ Machine learning libraries imported\")\n",
        "\n",
        "# =============================================================================\n",
        "# IMAGE PROCESSING AND SIGNAL PROCESSING LIBRARIES\n",
        "# =============================================================================\n",
        "# Procesamiento de imágenes\n",
        "import cv2                                    # OpenCV for image processing\n",
        "from skimage.util.shape import view_as_blocks # Image block processing\n",
        "from scipy import ndimage, misc, signal       # SciPy for signal processing\n",
        "\n",
        "print(\"✓ Image and signal processing libraries imported\")\n",
        "\n",
        "# =============================================================================\n",
        "# VISUALIZATION AND REPORTING LIBRARIES\n",
        "# =============================================================================\n",
        "# Yellowbrick (visualización de métricas)\n",
        "from yellowbrick.classifier import ClassificationReport  # Advanced classification visualization\n",
        "\n",
        "print(\"✓ Advanced visualization libraries imported\")\n",
        "\n",
        "# =============================================================================\n",
        "# VERIFY TENSORFLOW VERSION AND GPU AVAILABILITY\n",
        "# =============================================================================\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"ENVIRONMENT VERIFICATION\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n",
        "\n",
        "# Check for GPU availability\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✓ GPU available: {len(gpus)} device(s)\")\n",
        "    for i, gpu in enumerate(gpus):\n",
        "        print(f\"  GPU {i}: {gpu.name}\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU detected - training will use CPU\")\n",
        "\n",
        "print(f\"\\n✓ All libraries imported successfully!\")\n",
        "print(f\"Environment ready for Bi-CVT model implementation.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kcUbYkAi1kr",
        "outputId": "78ef0883-6ae6-4da6-8aa8-11466671997f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# VERIFY TENSORFLOW VERSION\n",
        "# =============================================================================\n",
        "# Ensure TensorFlow version compatibility for Bi-CVT implementation\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Check if version is compatible (2.10+ recommended)\n",
        "tf_version = tf.__version__.split('.')\n",
        "major, minor = int(tf_version[0]), int(tf_version[1])\n",
        "\n",
        "if major >= 2 and minor >= 10:\n",
        "    print(\"✓ TensorFlow version is compatible with Bi-CVT model\")\n",
        "else:\n",
        "    print(\"⚠️  TensorFlow version may have compatibility issues\")\n",
        "    print(\"Recommended: TensorFlow 2.10 or higher\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4UgQUmSnwo8",
        "outputId": "c09c87a6-0ebe-4957-c734-ce0cc096832e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# VERIFY PYTHON VERSION\n",
        "# =============================================================================\n",
        "# Check Python version for compatibility with deep learning libraries\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "\n",
        "# Extract Python version components\n",
        "python_version = sys.version_info\n",
        "\n",
        "if python_version.major == 3 and python_version.minor >= 8:\n",
        "    print(\"✓ Python version is compatible\")\n",
        "else:\n",
        "    print(\"⚠️  Python 3.8+ recommended for optimal performance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85R-L_pXHM3C",
        "outputId": "0bcb004d-847d-4a9e-ed8a-61e2c58e6516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# MOUNT GOOGLE DRIVE FOR BRAINLAT DATASET ACCESS\n",
        "# =============================================================================\n",
        "# Mount Google Drive to access the preprocessed BrainLat dataset\n",
        "# This includes both EEG spectrograms and clinical data\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Mounting Google Drive for BrainLat dataset access...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"✓ Google Drive mounted successfully!\")\n",
        "print(\"Dataset paths:\")\n",
        "print(\"  - EEG spectrograms: /content/drive/MyDrive/BrainLat/Vectores/sfft/\")\n",
        "print(\"  - Clinical data: /content/drive/MyDrive/BrainLat/Brainlat_Prueba/\")\n",
        "print(\"  - Model outputs: /content/drive/MyDrive/BrainLat/Bimodal/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k6kPNDhFJS_"
      },
      "source": [
        "# Data Loading and Preprocessing\n",
        "\n",
        "## Multimodal BrainLat Dataset Loading\n",
        "\n",
        "This section loads and preprocesses the multimodal BrainLat dataset for Bi-CVT model training. The process involves:\n",
        "\n",
        "1. **Clinical Data Loading**: Load neuropsychological and demographic features from CSV\n",
        "2. **EEG Data Pairing**: Match preprocessed STFT spectrograms with clinical data\n",
        "3. **Label Encoding**: Convert diagnostic labels to numerical format\n",
        "4. **Data Validation**: Ensure data integrity and proper pairing\n",
        "5. **Preprocessing**: Normalize features and prepare for model input\n",
        "\n",
        "### Dataset Structure:\n",
        "- **Clinical Features**: Neuropsychological assessments and demographics\n",
        "- **EEG Spectrograms**: 224×224×128 STFT representations  \n",
        "- **Labels**: AD (0), HC (1), bvFTD (2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBRHX3lgllXN"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CLINICAL DATA LOADING AND PREPROCESSING\n",
        "# =============================================================================\n",
        "# Import necessary libraries for data handling and preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "\n",
        "# Load clinical/flat data from CSV file\n",
        "# This CSV contains neuropsychological assessments and demographic features\n",
        "flat_data_path = \"/content/drive/MyDrive/BrainLat/Brainlat_Prueba/brainlat_EEG_Clean_Prueba.csv\"\n",
        "\n",
        "# Load the clinical dataset into a pandas DataFrame\n",
        "# This contains participant IDs, diagnostic labels, and clinical features\n",
        "flat_data = pd.read_csv(flat_data_path)  # Adjust delimiter if necessary\n",
        "\n",
        "print(\"✓ Clinical data loaded successfully!\")\n",
        "print(f\"Dataset shape: {flat_data.shape}\")\n",
        "print(f\"Columns: {list(flat_data.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojzz1FGTuLeP"
      },
      "outputs": [],
      "source": [
        "# Display the column names of the clinical dataset\n",
        "flat_data.columns\n",
        "\n",
        "# Encode the diagnostic labels and select features for model training\n",
        "# Convert categorical diagnosis labels to numerical format (0, 1, 2)\n",
        "flat_data['diagnosis_x'] = LabelEncoder().fit_transform(flat_data['diagnosis_x'])\n",
        "\n",
        "# Extract labels as numpy array for model training\n",
        "labels = flat_data['diagnosis_x'].to_numpy()\n",
        "\n",
        "# Create feature matrix by excluding non-feature columns\n",
        "# Remove participant ID and diagnosis columns to keep only clinical features\n",
        "features = flat_data.drop(['id EEG', 'diagnosis_x'], axis=1)  # Exclude irrelevant columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA6-pBj1Tj9x",
        "outputId": "ca1c319b-8d58-441e-e17f-fd72519bdbb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(features.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqtNSITSl4vN",
        "outputId": "abb5e805-945f-4fd4-a325-f8d469a0d94d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30001.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30002.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30004.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30008.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30009.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30011.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30012.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30013.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30015.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30018.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30020.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30022.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30026.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30029.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30031.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30003.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30006.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30016.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30021.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30023.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30019.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30024.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30025.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30027.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30028.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30033.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30035.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30034.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20001.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20003.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20006.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20009.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20010.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20012.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20014.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20015.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20016.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20017.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20018.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20019.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20002.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10002.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10003.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10004.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10006.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10007.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10009.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100012.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100015.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100018.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100020.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100022.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100024.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100026.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100031.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100033.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100035.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100010.npy\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# EEG SPECTROGRAM LOADING AND MULTIMODAL DATA PAIRING\n",
        "# =============================================================================\n",
        "# Base path for STFT spectrograms organized by diagnostic labels\n",
        "stft_folder = \"/content/drive/MyDrive/BrainLat/Vectores/sfft\"\n",
        "\n",
        "# Initialize lists to store paired multimodal data\n",
        "eeg_data = []           # EEG STFT spectrograms\n",
        "labels_stft = []        # Diagnostic labels for paired data\n",
        "flat_features = []      # Clinical features for paired participants\n",
        "\n",
        "# Iterate through clinical records to load corresponding STFT files and pair data\n",
        "for index, row in flat_data.iterrows():\n",
        "    participant_id = row['id EEG']\n",
        "    label_folder = None\n",
        "\n",
        "    # Map diagnostic labels to corresponding STFT subfolders\n",
        "    # Label encoding: AD=0, HC=1, bvFTD=2\n",
        "    if row['diagnosis_x'] == 0:  # Alzheimer's Disease\n",
        "        label_folder = \"1_AD\"\n",
        "    elif row['diagnosis_x'] == 2:  # Behavioral variant Frontotemporal Dementia\n",
        "        label_folder = \"2_bvFTD\"\n",
        "    elif row['diagnosis_x'] == 1:  # Healthy Controls\n",
        "        label_folder = \"5_HC\"\n",
        "\n",
        "    # Load STFT file if diagnostic folder is determined\n",
        "    if label_folder:\n",
        "        file_path = os.path.join(stft_folder, label_folder, f\"{participant_id}.npy\")\n",
        "        print(file_path)\n",
        "        if os.path.exists(file_path):\n",
        "            # Load EEG spectrogram (commented out to avoid memory issues during setup)\n",
        "            #eeg_array = np.load(file_path)\n",
        "            #eeg_data.append(eeg_array)\n",
        "            \n",
        "            # Store paired clinical data and labels\n",
        "            labels_stft.append(row['diagnosis_x'])\n",
        "            flat_features.append(features.loc[index].to_numpy())\n",
        "        else:\n",
        "            print(f\"File {file_path} not found. Skipping this participant.\")\n",
        "\n",
        "# Convert lists to numpy arrays for model compatibility\n",
        "#eeg_data = np.array(eeg_data)        # EEG STFT spectrograms (224x224x128)\n",
        "flat_features = np.array(flat_features)  # Clinical feature vectors\n",
        "labels_stft = np.array(labels_stft)      # Diagnostic labels\n",
        "\n",
        "# Create combined multimodal dataset structure\n",
        "# Each element contains (clinical_features, eeg_spectrogram, label)\n",
        "combined_data = list(zip(flat_features, eeg_data, labels_stft))\n",
        "\n",
        "# Split dataset into training and testing sets with stratified sampling\n",
        "# Ensures balanced representation of diagnostic classes in both sets\n",
        "train_data, test_data = train_test_split(\n",
        "    combined_data, \n",
        "    test_size=0.2,           # 80% train, 20% test\n",
        "    random_state=45,         # Fixed seed for reproducibility\n",
        "    stratify=labels_stft     # Maintain class distribution\n",
        ")\n",
        "\n",
        "# Separate multimodal components for model input\n",
        "X_train_flat, X_train_img, y_train = zip(*train_data)  # Training set\n",
        "X_test_flat, X_test_img, y_test = zip(*test_data)      # Test set\n",
        "\n",
        "# Convert tuples back to numpy arrays for TensorFlow compatibility\n",
        "X_train_flat = np.array(X_train_flat)  # Training clinical features\n",
        "X_train_img = np.array(X_train_img)    # Training EEG spectrograms\n",
        "y_train = np.array(y_train)            # Training labels\n",
        "\n",
        "X_test_flat = np.array(X_test_flat)    # Test clinical features\n",
        "X_test_img = np.array(X_test_img)      # Test EEG spectrograms\n",
        "y_test = np.array(y_test)              # Test labels\n",
        "\n",
        "# Standardize clinical features for improved model convergence\n",
        "# Fit scaler on training data only to prevent data leakage\n",
        "scaler = StandardScaler().fit(X_train_flat)\n",
        "X_train_flat = scaler.transform(X_train_flat)  # Normalize training features\n",
        "X_test_flat = scaler.transform(X_test_flat)    # Apply same scaling to test features\n",
        "\n",
        "# Display dataset dimensions for verification\n",
        "print(\"Clinical Features:\")\n",
        "print(f\"X_train_flat shape: {X_train_flat.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test_flat shape: {X_test_flat.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nEEG STFT Spectrograms:\")\n",
        "print(f\"X_train_img shape: {X_train_img.shape}\")\n",
        "print(f\"X_test_img shape: {X_test_img.shape}\")\n",
        "\n",
        "# Prepare multimodal data structures for Bi-CVT model input\n",
        "# Model expects list format: [clinical_features, eeg_spectrograms]\n",
        "train_data = [X_train_flat, X_train_img]  # Training data for both modalities\n",
        "test_data = [X_test_flat, X_test_img]     # Test data for both modalities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQmoVTciUF9g",
        "outputId": "d6947d66-59f0-44cf-b934-db973da316c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(58, 21)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyE04oUjFOIq"
      },
      "source": [
        "# Functions and Hyperfunctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa4I_2yVFluG"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SQUEEZE-AND-EXCITATION (SE) BLOCK IMPLEMENTATION\n",
        "# =============================================================================\n",
        "def squeeze_excitation_layer(input_layer, out_dim, ratio, conv):\n",
        "  \"\"\"\n",
        "  Implements Squeeze-and-Excitation block for channel attention mechanism.\n",
        "  \n",
        "  Args:\n",
        "    input_layer: Input tensor\n",
        "    out_dim: Output dimension for channel attention\n",
        "    ratio: Reduction ratio for squeeze operation\n",
        "    conv: Boolean flag to apply convolution shortcut\n",
        "  \n",
        "  Returns:\n",
        "    Enhanced feature tensor with channel attention applied\n",
        "  \"\"\"\n",
        "  # Squeeze: Global average pooling to capture channel-wise statistics\n",
        "  squeeze = tf.keras.layers.GlobalAveragePooling2D()(input_layer)\n",
        "  \n",
        "  # Excitation: Two fully connected layers for channel importance modeling\n",
        "  excitation = tf.keras.layers.Dense(units=out_dim / ratio, activation='relu')(squeeze)\n",
        "  excitation = tf.keras.layers.Dense(out_dim, activation='sigmoid')(excitation)\n",
        "  \n",
        "  # Reshape excitation weights for broadcasting\n",
        "  excitation = tf.reshape(excitation, [-1, 1, 1, out_dim])\n",
        "  \n",
        "  # Scale: Apply channel attention weights to input features\n",
        "  scale = tf.keras.layers.multiply([input_layer, excitation])\n",
        "  \n",
        "  # Shortcut connection with optional convolution for dimension matching\n",
        "  if conv:\n",
        "    shortcut = tf.keras.layers.Conv2D(out_dim, kernel_size=1, strides=1,\n",
        "                      padding='same', kernel_initializer='he_normal')(input_layer)\n",
        "    shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  else:\n",
        "    shortcut = input_layer\n",
        "  \n",
        "  # Residual connection: Add shortcut to attention-enhanced features\n",
        "  out = tf.keras.layers.add([shortcut, scale])\n",
        "  return out\n",
        "\n",
        "# =============================================================================\n",
        "# STANDARDIZED ACTIVATION FUNCTIONS\n",
        "# =============================================================================\n",
        "def sreLu(input):\n",
        "  \"\"\"\n",
        "  Standardized ReLU activation with leaky negative slope.\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor\n",
        "  \n",
        "  Returns:\n",
        "    Activated tensor with leaky ReLU (negative_slope=0.1)\n",
        "  \"\"\"\n",
        "  return ReLU(negative_slope=0.1, threshold=0)(input)\n",
        "\n",
        "# =============================================================================\n",
        "# STANDARDIZED CONVOLUTIONAL LAYERS\n",
        "# =============================================================================\n",
        "def sConv(input, parameters, size, nstrides):\n",
        "  \"\"\"\n",
        "  Standardized 2D Convolutional layer with L2 regularization.\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor\n",
        "    parameters: Number of output filters\n",
        "    size: Kernel size (square kernel)\n",
        "    nstrides: Stride value for convolution\n",
        "  \n",
        "  Returns:\n",
        "    Convolved feature tensor with regularization\n",
        "  \"\"\"\n",
        "  return Conv2D(parameters, (size, size), strides=(nstrides, nstrides),\n",
        "          padding=\"same\", kernel_initializer='glorot_normal', \n",
        "          kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
        "          bias_regularizer=tf.keras.regularizers.l2(0.0001))(input)\n",
        "\n",
        "# =============================================================================\n",
        "# STANDARDIZED BATCH NORMALIZATION\n",
        "# =============================================================================\n",
        "def sBN(input):\n",
        "  \"\"\"\n",
        "  Standardized Batch Normalization layer with optimized parameters.\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor\n",
        "  \n",
        "  Returns:\n",
        "    Normalized tensor with stable training parameters\n",
        "  \"\"\"\n",
        "  return tf.keras.layers.BatchNormalization(\n",
        "    momentum=0.2, epsilon=0.001, center=True, scale=True, \n",
        "    trainable=True, fused=None, renorm=False, \n",
        "    renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(input)\n",
        "\n",
        "# =============================================================================\n",
        "# STANDARDIZED POOLING OPERATIONS\n",
        "# =============================================================================\n",
        "def sGlobal_Avg_Pooling(input):\n",
        "  \"\"\"\n",
        "  Standardized Global Average Pooling for spatial dimension reduction.\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor with spatial dimensions\n",
        "  \n",
        "  Returns:\n",
        "    Globally pooled tensor (spatial dimensions collapsed)\n",
        "  \"\"\"\n",
        "  return tf.keras.layers.GlobalAveragePooling2D()(input)\n",
        "\n",
        "# =============================================================================\n",
        "# STANDARDIZED DENSE LAYERS\n",
        "# =============================================================================\n",
        "def sDense(input, n_units, activate_c):\n",
        "  \"\"\"\n",
        "  Standardized Dense (fully connected) layer.\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor\n",
        "    n_units: Number of output units\n",
        "    activate_c: Activation function name\n",
        "  \n",
        "  Returns:\n",
        "    Dense layer output with specified activation\n",
        "  \"\"\"\n",
        "  return tf.keras.layers.Dense(n_units, activation=activate_c)(input)\n",
        "\n",
        "# =============================================================================\n",
        "# STANDARDIZED TENSOR OPERATIONS\n",
        "# =============================================================================\n",
        "def smultiply(input_1, input_2):\n",
        "  \"\"\"\n",
        "  Element-wise multiplication of two tensors.\n",
        "  \n",
        "  Args:\n",
        "    input_1: First input tensor\n",
        "    input_2: Second input tensor\n",
        "  \n",
        "  Returns:\n",
        "    Element-wise product of input tensors\n",
        "  \"\"\"\n",
        "  return tf.keras.layers.multiply([input_1, input_2])\n",
        "\n",
        "def sadd(input_1, input_2):\n",
        "  \"\"\"\n",
        "  Element-wise addition of two tensors (residual connection).\n",
        "  \n",
        "  Args:\n",
        "    input_1: First input tensor\n",
        "    input_2: Second input tensor\n",
        "  \n",
        "  Returns:\n",
        "    Element-wise sum of input tensors\n",
        "  \"\"\"\n",
        "  return tf.keras.layers.add([input_1, input_2])\n",
        "\n",
        "# =============================================================================\n",
        "# LEARNING RATE SCHEDULING\n",
        "# =============================================================================\n",
        "# Initial learning rate for model training\n",
        "initial_learning_rate = 0.001\n",
        "\n",
        "# Exponential decay learning rate schedule for improved convergence\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "  initial_learning_rate,    # Starting learning rate\n",
        "  decay_steps=100000,       # Number of steps before applying decay\n",
        "  decay_rate=0.96,          # Multiplicative factor for decay\n",
        "  staircase=True           # Apply decay at discrete intervals\n",
        ")  # Custom learning rate schedule for Bi-CVT training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD13NMM1FwOi"
      },
      "source": [
        "# TF Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL2Kn8dJFrw-"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONVOLUTIONAL BUILDING BLOCKS FOR EEG SPECTROGRAM PROCESSING\n",
        "# =============================================================================\n",
        "from tensorflow.python.ops.gen_array_ops import shape\n",
        "\n",
        "def Block_3(input, parameter):  # Block A: Residual block with downsampling\n",
        "  \"\"\"\n",
        "  Residual block with spatial downsampling and Squeeze-and-Excitation attention.\n",
        "  \n",
        "  This block implements a bottleneck architecture with:\n",
        "  - 1x1 convolution for dimension matching (shortcut connection)\n",
        "  - 3x3 convolution with stride 2 for feature extraction and downsampling\n",
        "  - Squeeze-and-Excitation block for channel attention\n",
        "  - Residual connection for gradient flow\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor from previous layer\n",
        "    parameter: Number of output channels/filters\n",
        "  \n",
        "  Returns:\n",
        "    Enhanced feature tensor with spatial downsampling applied\n",
        "  \"\"\"\n",
        "  # Shortcut connection: 1x1 conv with stride 2 for dimension matching\n",
        "  addition = sConv(input, parameter, 1, 2)\n",
        "  addition = sBN(addition)\n",
        "  \n",
        "  # Main path: 3x3 convolution with downsampling\n",
        "  output = sConv(input, parameter, 3, 2)\n",
        "  output = sBN(output)\n",
        "  output = sreLu(output)\n",
        "  \n",
        "  # Second 3x3 convolution without downsampling\n",
        "  output = sConv(output, parameter, 3, 1)\n",
        "  output = sBN(output)\n",
        "  \n",
        "  # Apply Squeeze-and-Excitation attention mechanism\n",
        "  multiplier = SE_Block(output, parameter, parameter)\n",
        "  output = smultiply(multiplier, output)\n",
        "  \n",
        "  # Residual connection: Add shortcut to main path\n",
        "  output = sadd(output, addition)\n",
        "  return output\n",
        "\n",
        "def Block_1(input, parameter):  # Block B: Basic convolutional block\n",
        "  \"\"\"\n",
        "  Basic convolutional block for feature extraction.\n",
        "  \n",
        "  Simple 3x3 convolution followed by batch normalization and activation.\n",
        "  Used as a building component in more complex blocks.\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor\n",
        "    parameter: Number of output filters\n",
        "  \n",
        "  Returns:\n",
        "    Processed feature tensor with same spatial dimensions\n",
        "  \"\"\"\n",
        "  # Apply 3x3 convolution with same padding (no downsampling)\n",
        "  output = sConv(input, parameter, 3, 1)\n",
        "  output = sBN(output)\n",
        "  output = sreLu(output)\n",
        "  return output\n",
        "\n",
        "def Block_2(input, parameter):  # Block C: Residual block with identity mapping\n",
        "  \"\"\"\n",
        "  Residual block with identity shortcut connection.\n",
        "  \n",
        "  This block maintains spatial dimensions while applying feature transformations:\n",
        "  - Two sequential convolutional layers (via Block_1)\n",
        "  - Squeeze-and-Excitation attention for channel recalibration\n",
        "  - Identity shortcut connection for residual learning\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor\n",
        "    parameter: Number of output channels\n",
        "  \n",
        "  Returns:\n",
        "    Enhanced feature tensor with same spatial dimensions as input\n",
        "  \"\"\"\n",
        "  # Apply basic convolutional block\n",
        "  output = Block_1(input, parameter)\n",
        "  \n",
        "  # Second 3x3 convolution\n",
        "  output = sConv(output, parameter, 3, 1)\n",
        "  output = sBN(output)\n",
        "  \n",
        "  # Apply channel attention via Squeeze-and-Excitation\n",
        "  multiplier = SE_Block(output, parameter, parameter)\n",
        "  output = smultiply(multiplier, output)\n",
        "  \n",
        "  # Identity shortcut: Add input directly to output\n",
        "  output = sadd(output, input)\n",
        "  return output\n",
        "\n",
        "def SE_Block(input, out_dim, ratio):\n",
        "  \"\"\"\n",
        "  Squeeze-and-Excitation block for channel attention mechanism.\n",
        "  \n",
        "  Implements adaptive channel feature recalibration through:\n",
        "  1. Squeeze: Global average pooling to capture channel statistics\n",
        "  2. Excitation: Two FC layers to model channel interdependencies\n",
        "  3. Scale: Apply learned channel weights to input features\n",
        "  \n",
        "  Args:\n",
        "    input: Input feature tensor\n",
        "    out_dim: Output dimension (number of channels)\n",
        "    ratio: Reduction ratio for squeeze operation (controls bottleneck)\n",
        "  \n",
        "  Returns:\n",
        "    Channel attention weights for feature recalibration\n",
        "  \"\"\"\n",
        "  # Squeeze: Global average pooling across spatial dimensions\n",
        "  output = sGlobal_Avg_Pooling(input)\n",
        "  \n",
        "  # Excitation: First FC layer with dimensionality reduction\n",
        "  output = sDense(output, out_dim/ratio, 'relu')\n",
        "  \n",
        "  # Excitation: Second FC layer with sigmoid activation for attention weights\n",
        "  output = sDense(output, out_dim, 'sigmoid')\n",
        "  return output\n",
        "\n",
        "def Block_4(input, parameter):\n",
        "  \"\"\"\n",
        "  Final convolutional block for high-level feature extraction.\n",
        "  \n",
        "  Combines basic convolution (Block_1) with additional 3x3 convolution\n",
        "  for final feature refinement before transformer processing.\n",
        "  \n",
        "  Args:\n",
        "    input: Input tensor from previous layers\n",
        "    parameter: Number of output filters\n",
        "  \n",
        "  Returns:\n",
        "    High-level feature representation for transformer input\n",
        "  \"\"\"\n",
        "  # Apply basic convolutional processing\n",
        "  output = Block_1(input, parameter)\n",
        "  \n",
        "  # Additional 3x3 convolution for feature refinement\n",
        "  output = sConv(input, parameter, 3, 1)\n",
        "  output = sBN(output)\n",
        "  return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dmWVW-bF22N"
      },
      "source": [
        "#  TF Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLgmYditGDLJ",
        "outputId": "09c4567b-4ea3-48fc-871a-7d0617442b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# BI-CVT TRANSFORMER HYPERPARAMETERS CONFIGURATION\n",
        "# =============================================================================\n",
        "# Core transformer architecture parameters for Bi-CVT model\n",
        "\n",
        "# Number of transformer layers for deep feature learning\n",
        "NUM_LAYERS = 16\n",
        "\n",
        "# =============================================================================\n",
        "# IMAGE PATCH EXTRACTION PARAMETERS\n",
        "# =============================================================================\n",
        "# Input image dimensions after convolutional feature extraction\n",
        "IMAGE_SIZE_2 = 13     # Spatial dimension of feature maps (13x13)\n",
        "PATCH_SIZE_2 = 11     # Size of patches extracted from feature maps\n",
        "# Calculate number of patches for positional embedding\n",
        "NUM_PATCHES_2 = (IMAGE_SIZE_2 // PATCH_SIZE_2) ** 2\n",
        "print(NUM_PATCHES_2)  # Should output 1 patch (13//11 = 1, so 1^2 = 1)\n",
        "\n",
        "# =============================================================================\n",
        "# CLINICAL DATA ATTENTION PARAMETERS\n",
        "# =============================================================================\n",
        "# Self-attention configuration for clinical/flat data branch\n",
        "LAYER_NORM_EPS_1 = 1e-6        # Layer normalization epsilon for numerical stability\n",
        "PROJECTION_DIM_1 = 128         # Embedding dimension for clinical features (fixed)\n",
        "NUM_HEADS_1 = 16               # Number of attention heads for clinical data\n",
        "# MLP hidden units for clinical data transformer\n",
        "MLP_UNITS_1 = [\n",
        "    PROJECTION_DIM_1 * 2,      # First hidden layer: 256 units\n",
        "    PROJECTION_DIM_1           # Second hidden layer: 128 units (matches projection dim)\n",
        "]\n",
        "\n",
        "# =============================================================================\n",
        "# EEG IMAGE ATTENTION PARAMETERS\n",
        "# =============================================================================\n",
        "# Self-attention configuration for EEG spectrogram branch\n",
        "LAYER_NORM_EPS_2 = 1e-6        # Layer normalization epsilon for numerical stability\n",
        "PROJECTION_DIM_2 = 128         # Embedding dimension for EEG features\n",
        "NUM_HEADS_2 = 16               # Number of attention heads for EEG data\n",
        "# MLP hidden units for EEG transformer\n",
        "MLP_UNITS_2 = [\n",
        "    PROJECTION_DIM_2 * 2,      # First hidden layer: 256 units\n",
        "    PROJECTION_DIM_2           # Second hidden layer: 128 units (matches projection dim)\n",
        "]\n",
        "\n",
        "# =============================================================================\n",
        "# CROSS-ATTENTION PARAMETERS\n",
        "# =============================================================================\n",
        "# Cross-modal attention configuration for multimodal fusion\n",
        "NUM_HEADS_3 = 16               # Number of attention heads for cross-modal attention\n",
        "PROJECTION_DIM_3 = 128         # Key dimension for cross-attention mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbWdIqMHGXc9"
      },
      "source": [
        "# TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0ifUQvpZ2Os"
      },
      "outputs": [],
      "source": [
        "def position_embedding(projected_patches, num_patches=NUM_PATCHES_2, projection_dim=PROJECTION_DIM_2):\n",
        "  \"\"\"\n",
        "  Add positional embeddings to projected patches for transformer processing.\n",
        "  \n",
        "  This function creates learnable positional encodings that help the model\n",
        "  understand spatial relationships between different patches in the sequence.\n",
        "  \n",
        "  Args:\n",
        "    projected_patches: Tensor of shape (batch_size, num_patches, projection_dim)\n",
        "    num_patches: Number of patches in the sequence\n",
        "    projection_dim: Dimension of patch embeddings\n",
        "  \n",
        "  Returns:\n",
        "    Tensor with positional embeddings added to projected patches\n",
        "  \"\"\"\n",
        "  # Build the positions - create a sequence from 0 to num_patches-1\n",
        "  positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "  \n",
        "  # Encode the positions with an Embedding layer\n",
        "  # Each position gets a learnable embedding vector of size projection_dim\n",
        "  encoded_positions = layers.Embedding(\n",
        "    input_dim=num_patches, output_dim=projection_dim\n",
        "  )(positions)\n",
        "  \n",
        "  # Add encoded positions to the projected patches element-wise\n",
        "  # This gives each patch information about its position in the sequence\n",
        "  return projected_patches + encoded_positions\n",
        "\n",
        "def mlp(x, dropout_rate, hidden_units):\n",
        "  \"\"\"\n",
        "  Multi-Layer Perceptron (MLP) block for transformer feed-forward networks.\n",
        "  \n",
        "  Implements the feed-forward component of transformer blocks with:\n",
        "  - Multiple dense layers with GELU activation\n",
        "  - Dropout for regularization between layers\n",
        "  \n",
        "  Args:\n",
        "    x: Input tensor\n",
        "    dropout_rate: Dropout probability for regularization\n",
        "    hidden_units: List of hidden layer dimensions\n",
        "  \n",
        "  Returns:\n",
        "    Processed tensor after MLP transformation\n",
        "  \"\"\"\n",
        "  # Iterate over the hidden units and add Dense => Dropout layers\n",
        "  for units in hidden_units:\n",
        "    # Dense layer with GELU activation (smoother than ReLU)\n",
        "    x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "    # Apply dropout for regularization\n",
        "    x = layers.Dropout(dropout_rate)(x)\n",
        "  return x\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  \"\"\"\n",
        "  Cross-Attention mechanism for multimodal fusion in Bi-CVT.\n",
        "  \n",
        "  This layer enables information exchange between different modalities\n",
        "  (EEG spectrograms and clinical data) through attention mechanisms.\n",
        "  The query comes from one modality while key-value pairs come from another.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, **kwargs):\n",
        "    \"\"\"\n",
        "    Initialize Cross-Attention layer components.\n",
        "    \n",
        "    Args:\n",
        "      **kwargs: Keyword arguments passed to MultiHeadAttention\n",
        "           (num_heads, key_dim, etc.)\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    # Multi-head attention mechanism for cross-modal attention\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    # Addition layer for residual connection\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    # Layer normalization for training stability\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x, y, **kwargs):\n",
        "    \"\"\"\n",
        "    Forward pass of cross-attention mechanism.\n",
        "    \n",
        "    Args:\n",
        "      x: Query tensor (from first modality)\n",
        "      y: Key-Value tensor (from second modality)\n",
        "      **kwargs: Additional arguments for attention computation\n",
        "    \n",
        "    Returns:\n",
        "      Enhanced query tensor with cross-modal information\n",
        "    \"\"\"\n",
        "    # Compute cross-attention: x attends to y\n",
        "    # x provides queries, y provides keys and values\n",
        "    attn, attention_scores = self.mha(\n",
        "         query=x, value=y,\n",
        "         return_attention_scores=True)\n",
        "\n",
        "    # Store attention scores for potential visualization/analysis\n",
        "    self.last_attention_scores = attention_scores\n",
        "\n",
        "    # Apply residual connection: add attention output to original query\n",
        "    x = self.add([x, attn])\n",
        "    \n",
        "    # Apply layer normalization for training stability\n",
        "    return self.layernorm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt5IcLMLGWLw"
      },
      "outputs": [],
      "source": [
        "def Attention_Data(encoded_patches):\n",
        "    \"\"\"\n",
        "    Self-attention mechanism for clinical data processing.\n",
        "    \n",
        "    Applies transformer-style self-attention to clinical features:\n",
        "    1. Layer normalization for stable training\n",
        "    2. Multi-head self-attention for feature relationships\n",
        "    3. Residual connections for gradient flow\n",
        "    4. MLP for non-linear transformations\n",
        "    \n",
        "    Args:\n",
        "        encoded_patches: Clinical feature embeddings [batch_size, seq_len, dim]\n",
        "    \n",
        "    Returns:\n",
        "        Enhanced clinical features after self-attention processing\n",
        "    \"\"\"\n",
        "    # Layer normalization before self-attention\n",
        "    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS_1)(encoded_patches)\n",
        "    \n",
        "    # Multi-Head Self-Attention: clinical features attend to themselves\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS_1, key_dim=PROJECTION_DIM_1, dropout=0.1\n",
        "    )(x1, x1)\n",
        "    \n",
        "    # Residual connection 1: Add attention output to original input\n",
        "    x2 = layers.Add()([attention_output, encoded_patches])\n",
        "    \n",
        "    # Layer normalization after first residual connection\n",
        "    x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS_1)(x2)\n",
        "    \n",
        "    # Feed-forward MLP for non-linear feature transformation\n",
        "    x4 = mlp(x3, hidden_units=MLP_UNITS_1, dropout_rate=0.1)\n",
        "    \n",
        "    # Residual connection 2: Add MLP output to post-attention features\n",
        "    encoded_patches_1 = layers.Add()([x4, x2])\n",
        "    return encoded_patches_1\n",
        "\n",
        "def Attention_Images(encoded_patches):\n",
        "    \"\"\"\n",
        "    Self-attention mechanism for EEG spectrogram processing.\n",
        "    \n",
        "    Applies transformer-style self-attention to EEG visual features:\n",
        "    1. Layer normalization for training stability\n",
        "    2. Multi-head self-attention for spatial-spectral relationships\n",
        "    3. Residual connections for improved gradient flow\n",
        "    4. MLP for complex feature interactions\n",
        "    \n",
        "    Args:\n",
        "        encoded_patches: EEG patch embeddings [batch_size, num_patches, dim]\n",
        "    \n",
        "    Returns:\n",
        "        Enhanced EEG features after self-attention processing\n",
        "    \"\"\"\n",
        "    # Layer normalization before self-attention\n",
        "    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS_2)(encoded_patches)\n",
        "    \n",
        "    # Multi-Head Self-Attention: EEG patches attend to each other\n",
        "    # This captures spatial-temporal patterns in spectrograms\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS_2, key_dim=PROJECTION_DIM_2, dropout=0.1\n",
        "    )(x1, x1)  # Self-attention for EEG patches\n",
        "    \n",
        "    # Residual connection 1: Preserve original EEG information\n",
        "    x2 = layers.Add()([attention_output, encoded_patches])\n",
        "    \n",
        "    # Layer normalization after first residual connection\n",
        "    x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS_2)(x2)\n",
        "    \n",
        "    # Feed-forward MLP for non-linear EEG feature processing\n",
        "    x4 = mlp(x3, hidden_units=MLP_UNITS_2, dropout_rate=0.1)\n",
        "    \n",
        "    # Residual connection 2: Final feature enhancement\n",
        "    encoded_patches = layers.Add()([x4, x2])\n",
        "    return encoded_patches  # Ready for cross-attention with clinical data\n",
        "\n",
        "def Transformer(inputs, layer):  # inputs=EEG_features, layer=clinical_features\n",
        "    \"\"\"\n",
        "    Bi-CVT Transformer with Cross-Attention for multimodal fusion.\n",
        "    \n",
        "    This function implements the core Bi-CVT architecture:\n",
        "    1. EEG channel attention via Squeeze-and-Excitation\n",
        "    2. Patch extraction and positional encoding for EEG spectrograms\n",
        "    3. Iterative self-attention for both modalities\n",
        "    4. Cross-attention for bidirectional information exchange\n",
        "    5. Feature concatenation for final multimodal representation\n",
        "    \n",
        "    Args:\n",
        "        inputs: EEG spectrogram features [batch, height, width, channels]\n",
        "        layer: Clinical data features [batch, seq_len, features]\n",
        "    \n",
        "    Returns:\n",
        "        Concatenated multimodal features [batch, seq_len*2, dim]\n",
        "    \"\"\"\n",
        "    # Apply channel attention to EEG features using Squeeze-and-Excitation\n",
        "    input = squeeze_excitation_layer(inputs, out_dim=512, ratio=32.0, conv=False)\n",
        "    print(input.shape)\n",
        "    \n",
        "    # Extract patches from EEG spectrograms using convolution\n",
        "    # This converts 2D spectrograms into sequence of patch embeddings\n",
        "    projected_patches = layers.Conv2D(\n",
        "          filters=PROJECTION_DIM_2,\n",
        "          kernel_size=(PATCH_SIZE_2, PATCH_SIZE_2),\n",
        "          strides=(PATCH_SIZE_2, PATCH_SIZE_2),\n",
        "          padding=\"VALID\",\n",
        "      )(input)\n",
        "    \n",
        "    # Reshape patches into sequence format for transformer processing\n",
        "    _, h, w, c = projected_patches.shape\n",
        "    projected_patches = layers.Reshape((h * w, c))(\n",
        "          projected_patches\n",
        "      )  # Shape: (batch_size, number_patches, projection_dim)\n",
        "    \n",
        "    # Add learnable positional embeddings to EEG patches\n",
        "    # This helps the model understand spatial relationships\n",
        "    encoded_patches = position_embedding(\n",
        "          projected_patches\n",
        "      )\n",
        "    print(f'layer: {layer.shape}')\n",
        "    print(f'encoded_patches: {encoded_patches.shape}')\n",
        "\n",
        "    # Apply dropout to EEG patch embeddings for regularization\n",
        "    encoded_patches_2 = layers.Dropout(0.1)(encoded_patches)\n",
        "    \n",
        "    # Initialize clinical data features for transformer processing\n",
        "    encoded_patches_1 = layer\n",
        "    \n",
        "    # Initialize Cross-Attention mechanism for multimodal fusion\n",
        "    cross_attention_layer = CrossAttention(num_heads=NUM_HEADS_3, key_dim=PROJECTION_DIM_3)\n",
        "    \n",
        "    # Iterate through transformer layers for deep feature learning\n",
        "    for i in range(NUM_LAYERS):\n",
        "        # Self-attention for clinical data: captures clinical feature relationships\n",
        "        encoded_patches_1 = Attention_Data(encoded_patches_1)\n",
        "        \n",
        "        # Self-attention for EEG data: captures spatial-spectral patterns\n",
        "        encoded_patches_2 = Attention_Images(encoded_patches_2)\n",
        "        \n",
        "        # Cross-attention 1: Clinical data attends to EEG features\n",
        "        # Query=Clinical, Key/Value=EEG (clinical data learns from EEG patterns)\n",
        "        attn_1_to_2 = cross_attention_layer(encoded_patches_1, encoded_patches_2)\n",
        "        \n",
        "        # Cross-attention 2: EEG data attends to clinical features  \n",
        "        # Query=EEG, Key/Value=Clinical (EEG learns from clinical context)\n",
        "        attn_2_to_1 = cross_attention_layer(encoded_patches_2, encoded_patches_1)\n",
        "    \n",
        "    print(f'attn_1_to_2: {attn_1_to_2.shape}')\n",
        "    print(f'attn_2_to_1: {attn_2_to_1.shape}')\n",
        "    \n",
        "    # Concatenate cross-attended features for final multimodal representation\n",
        "    # This creates a unified feature vector combining both modalities\n",
        "    return tf.concat([attn_1_to_2, attn_2_to_1], axis=1)  # Shape: [batch, seq_len*2, dim]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ad1-ZVaGZ2o"
      },
      "source": [
        "# Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPcBjrya7vFK"
      },
      "outputs": [],
      "source": [
        "def new_arch():\n",
        "  \"\"\"\n",
        "  Build the complete Bi-CVT (Bimodal Convolutional Vision Transformer) architecture.\n",
        "  \n",
        "  This function creates a multimodal deep learning model that combines:\n",
        "  1. Clinical data processing through 1D CNN\n",
        "  2. EEG spectrogram processing through 2D CNN with residual blocks\n",
        "  3. Cross-attention mechanism for multimodal fusion\n",
        "  4. Classification head for 3-class diagnosis prediction\n",
        "  \n",
        "  Returns:\n",
        "    tf.keras.Model: Complete Bi-CVT model ready for training\n",
        "  \"\"\"\n",
        "  # Clear any existing models from memory to prevent conflicts\n",
        "  tf.keras.backend.clear_session()\n",
        "  \n",
        "  #---------------------------------------------------Clinical Data Branch------------------------------------------------------------------------#\n",
        "  # Input layer for clinical/flat data (neuropsychological assessments)\n",
        "  # Shape: (batch_size, 20, 1) - 20 clinical features reshaped for 1D convolution\n",
        "  inputs_1 = Input(shape=(20,1), name=\"input_B\")\n",
        "  \n",
        "  # Block 1: Initial feature extraction from clinical data\n",
        "  # 1D convolution to capture patterns in clinical assessments\n",
        "  Layer_1 = tf.keras.layers.Conv1D(8, 3, activation=\"selu\", padding=\"same\")(inputs_1)\n",
        "  \n",
        "  # Block 2: Increase feature depth and add pooling for dimensionality reduction\n",
        "  Layer_1 = tf.keras.layers.Conv1D(16, 3, activation=\"selu\", padding=\"same\")(Layer_1)\n",
        "  Pool_1 = tf.keras.layers.MaxPool1D(2)(Layer_1)  # Reduce temporal dimension\n",
        "  \n",
        "  # Block 3: Deeper feature extraction with regularization\n",
        "  Layer_1 = tf.keras.layers.Conv1D(32, 3, activation=\"selu\", padding=\"same\")(Pool_1)\n",
        "  Dropout_1 = tf.keras.layers.Dropout(rate=0.5)(Layer_1)  # Prevent overfitting\n",
        "  \n",
        "  # Block 4: Further feature abstraction\n",
        "  Layer_1 = tf.keras.layers.Conv1D(64, 3, activation=\"selu\", padding=\"same\")(Dropout_1)\n",
        "  Dropout_1 = tf.keras.layers.Dropout(rate=0.5)(Layer_1)  # Additional regularization\n",
        "  \n",
        "  # Block 5: Final clinical feature extraction\n",
        "  # Output will be used as input to cross-attention mechanism\n",
        "  Layer_1 = tf.keras.layers.Conv1D(128, 3, activation=\"selu\", padding=\"same\")(Dropout_1)\n",
        "  Dropout_1 = tf.keras.layers.Dropout(rate=0.5)(Layer_1)  # Final dropout layer\n",
        "  \n",
        "  # Clinical features ready for transformer processing\n",
        "  print(f'Clinical branch output shape: {Dropout_1.shape}')  # Expected: (None, sequence_length, 128)\n",
        "  \n",
        "  #---------------------------------------------------EEG Spectrogram Branch------------------------------------------------------------------------#\n",
        "  # Input layer for EEG STFT spectrograms\n",
        "  # Shape: (batch_size, 224, 224, 128) - Time-frequency representations\n",
        "  inputs_2 = tf.keras.Input(shape=(224, 224, 128), name=\"input_A\")\n",
        "  \n",
        "  # L1: Initial feature extraction with downsampling using residual block\n",
        "  layers = Block_3(inputs_2, 64)  # Block A: Residual block with spatial downsampling\n",
        "  \n",
        "  # L2: Basic feature processing without downsampling\n",
        "  layers = Block_1(layers, 64)    # Block B: Basic convolutional block\n",
        "  \n",
        "  # L3: Residual learning with identity mapping\n",
        "  layers = Block_2(layers, 64)    # Block C: Residual block with identity shortcut\n",
        "  \n",
        "  # L4 - L6: Progressive feature abstraction with increasing channel depth\n",
        "  # Each block reduces spatial dimensions while increasing feature complexity\n",
        "  for i in [64, 128, 256]:\n",
        "    layers = Block_3(layers, i)  # Block A: Downsampling residual blocks\n",
        "  \n",
        "  # L7: Final high-level feature extraction before transformer\n",
        "  layers = Block_4(layers, 512)   # Prepare features for patch extraction\n",
        "  \n",
        "  # EEG features ready for transformer processing\n",
        "  print(f'EEG branch output shape: {layers.shape}')  # Expected: (None, height, width, 512)\n",
        "  \n",
        "  #---------------------------------------------------Cross-Attention Transformer------------------------------------------------------------------------#\n",
        "  # Apply Bi-CVT transformer with cross-attention mechanism\n",
        "  # This fuses clinical data (Dropout_1) with EEG features (layers)\n",
        "  # Returns concatenated multimodal representation\n",
        "  ViT = Transformer(layers, Dropout_1)\n",
        "  print(f'Transformer output shape: {ViT.shape}')\n",
        "  \n",
        "  # Post-transformer normalization and global pooling\n",
        "  representation = tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS_1)(ViT)\n",
        "  representation = tf.keras.layers.GlobalAvgPool1D()(representation)  # Convert to fixed-size vector\n",
        "  \n",
        "  #---------------------------------------------------Classification Head---------------------------------------------------------------------------\n",
        "  # Multi-layer dense network for final classification\n",
        "  \n",
        "  # First dense layer: Initial feature compression\n",
        "  layers = Dense(128, activation=\"gelu\", kernel_initializer='glorot_normal',\n",
        "           kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
        "           bias_regularizer=tf.keras.regularizers.l2(0.0001))(representation)\n",
        "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)  # Leaky ReLU activation\n",
        "  layers = BatchNormalization()(layers)  # Normalize for stable training\n",
        "  \n",
        "  # Second dense layer: Further feature refinement\n",
        "  layers = Dense(64, activation=\"gelu\", kernel_initializer='glorot_normal',\n",
        "           kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
        "           bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)  # Leaky ReLU activation\n",
        "  layers = BatchNormalization()(layers)  # Batch normalization\n",
        "  \n",
        "  # Third dense layer: Final feature abstraction before classification\n",
        "  layers = Dense(32, activation=\"gelu\", kernel_initializer='glorot_normal',\n",
        "           kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
        "           bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)  # Leaky ReLU activation\n",
        "  layers = BatchNormalization()(layers)  # Final normalization\n",
        "  \n",
        "  # Output layer: 3-class classification (AD, HC, bvFTD)\n",
        "  # Softmax activation for probability distribution over classes\n",
        "  predictions = Dense(3, activation=\"softmax\", name=\"output_12\")(layers)\n",
        "  \n",
        "  # Create the complete Bi-CVT model\n",
        "  # Inputs: [clinical_data, eeg_spectrograms]\n",
        "  # Output: 3-class probability distribution\n",
        "  model = tf.keras.Model(inputs=[inputs_1, inputs_2], outputs=predictions)\n",
        "  \n",
        "  # Compile model with optimizer, loss function, and metrics\n",
        "  if compile:  # Note: 'compile' variable should be defined elsewhere\n",
        "    model.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # Adam optimizer with fixed learning rate\n",
        "      # Alternative: model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "      loss='sparse_categorical_crossentropy',  # Multi-class classification loss\n",
        "      metrics=['accuracy']  # Track accuracy during training\n",
        "    )\n",
        "    print(\"Bi-CVT Transformer model created and compiled successfully\")\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qJsUy2u7vFK",
        "outputId": "53b3bf71-fa22-47f5-cc0f-f08e993138c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n"
          ]
        }
      ],
      "source": [
        "model = new_arch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbib5oP_RE2C"
      },
      "outputs": [],
      "source": [
        "import time as tm\n",
        "path_log_base = '/content/logs'\n",
        "path_img_base = '/content/images'\n",
        "\n",
        "if not os.path.exists(path_log_base):\n",
        "    os.makedirs(path_log_base)\n",
        "if not os.path.exists(path_img_base):\n",
        "    os.makedirs(path_img_base)\n",
        "\n",
        "\n",
        "def train(model, X_train1, X_train, y_train, X_valid1,X_valid, y_valid, X_test1,X_test, y_test, batch_size, epochs, model_name=\"\"):\n",
        "    start_time = tm.time()\n",
        "    # log_dir=path_log_base+\"/\"+model_name+\"_\"+str(datetime.datetime.now().isoformat()[:19].replace(\"T\", \"_\").replace(\":\",\"-\"))\n",
        "    log_dir=path_log_base+\"/\"+model_name\n",
        "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir, histogram_freq=1)\n",
        "    filepath = log_dir+\"/saved-model-{epoch:03d}-{val_accuracy:.4f}.hdf5\"\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "    model.reset_states()\n",
        "\n",
        "    global lossTEST\n",
        "    global accuracyTEST\n",
        "    global lossTRAIN\n",
        "    global accuracyTRAIN\n",
        "    global lossVALID\n",
        "    global accuracyVALID\n",
        "    lossTEST,accuracyTEST   = model.evaluate([X_test1,X_test], y_test,verbose=None)\n",
        "    lossTRAIN,accuracyTRAIN = model.evaluate([X_train1,X_train], y_train,verbose=None)\n",
        "    lossVALID,accuracyVALID = model.evaluate([X_valid1,X_valid], y_valid,verbose=None)\n",
        "\n",
        "    global history\n",
        "    global model_Name\n",
        "    global log_Dir\n",
        "    model_Name = model_name\n",
        "    log_Dir = log_dir\n",
        "    print(\"Starting the training...\")\n",
        "    history=model.fit([X_train1,X_train], y_train, epochs=epochs,\n",
        "                      callbacks=[tensorboard,checkpoint],\n",
        "                      batch_size=batch_size,validation_data=([X_valid1,X_valid], y_valid),verbose=2)\n",
        "\n",
        "    metrics = model.evaluate([X_test1, X_test], y_test, verbose=0)\n",
        "\n",
        "    TIME = tm.time() - start_time\n",
        "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(log_dir)\n",
        "    Final_Results_Test(log_dir, X_test1, X_test, y_test)\n",
        "\n",
        "    return {k:v for k,v in zip (model.metrics_names, metrics)}\n",
        "\n",
        "\n",
        "def Final_Results_Test(PATH_trained_models, X_test1, X_test, y_test):  # Added parameters\n",
        "    global AccTest\n",
        "    global LossTest\n",
        "    AccTest = []\n",
        "    LossTest = []\n",
        "    B_accuracy = 0  # B --> Best\n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            model = tf.keras.models.load_model(PATH_trained_models + '/' + filename)\n",
        "            # Now X_test1 and X_test are available here\n",
        "            loss, accuracy = model.evaluate([X_test1, X_test], y_test, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}' + '\\n')\n",
        "            BandAccTest = accuracy\n",
        "            BandLossTest = loss\n",
        "            AccTest.append(BandAccTest)\n",
        "            LossTest.append(BandLossTest)\n",
        "\n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "\n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5fOUFlVfqYR"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title lr 0.0001\n",
        "# =============================================================================\n",
        "# TRAINING CONFIGURATION FOR BI-CVT MODEL\n",
        "# =============================================================================\n",
        "\n",
        "# Training hyperparameters\n",
        "batch_size = 128    # Number of samples per training batch\n",
        "epochs = 500        # Maximum number of training epochs\n",
        "model_name = \"Bimodal_EEG+Data\"  # Model identifier for logging and saving\n",
        "\n",
        "# =============================================================================\n",
        "# MODEL TRAINING EXECUTION\n",
        "# =============================================================================\n",
        "# Train the Bi-CVT model with multimodal data (clinical + EEG spectrograms)\n",
        "# Uses stratified train-test split with same data for validation and testing\n",
        "\n",
        "results = train(\n",
        "    model=model,                                                    # Bi-CVT model instance\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,   # Training data: clinical features + EEG spectrograms + labels\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,      # Validation data: using test set for monitoring (same as test)\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,         # Test data: clinical features + EEG spectrograms + labels\n",
        "    batch_size=batch_size, epochs=epochs,                          # Training configuration parameters\n",
        "    model_name=model_name                                           # Model name for checkpoint saving and logging\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnETGSaefp1M"
      },
      "outputs": [],
      "source": [
        "model=load_model(\"/content/drive/MyDrive/BrainLat/Bimodal/Experimentos/saved-model-clean-seed_45-3C-128-1.0000.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opWdfx98QRa5",
        "outputId": "684daa79-2afc-4184-8f8a-606ac79efb49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_A (InputLayer)        [(None, 224, 224, 128)]      0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 64)         73792     ['input_A[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 112, 112, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 112, 112, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 64)         36928     ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 112, 112, 64)         256       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 64)                   0         ['batch_normalization_2[0][0]'\n",
            " GlobalAveragePooling2D)                                            ]                             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1)                    65        ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   128       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 112, 112, 64)         8256      ['input_A[0][0]']             \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 112, 112, 64)         0         ['dense_1[0][0]',             \n",
            "                                                                     'batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 112, 112, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 112, 112, 64)         0         ['multiply[0][0]',            \n",
            "                                                                     'batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 64)         36928     ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 112, 112, 64)         256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 112, 112, 64)         0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 112, 112, 64)         36928     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 112, 112, 64)         256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 112, 112, 64)         0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 112, 112, 64)         36928     ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 112, 112, 64)         256       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 64)                   0         ['batch_normalization_5[0][0]'\n",
            "  (GlobalAveragePooling2D)                                          ]                             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    65        ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 64)                   128       ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)       (None, 112, 112, 64)         0         ['dense_3[0][0]',             \n",
            "                                                                     'batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 112, 112, 64)         0         ['multiply_1[0][0]',          \n",
            "                                                                     're_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 56, 56, 64)           36928     ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 56, 56, 64)           256       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 56, 56, 64)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 56, 56, 64)           36928     ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 56, 56, 64)           256       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 64)                   0         ['batch_normalization_8[0][0]'\n",
            "  (GlobalAveragePooling2D)                                          ]                             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 1)                    65        ['global_average_pooling2d_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 64)                   128       ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 64)           4160      ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)       (None, 56, 56, 64)           0         ['dense_5[0][0]',             \n",
            "                                                                     'batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 56, 56, 64)           256       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 56, 56, 64)           0         ['multiply_2[0][0]',          \n",
            "                                                                     'batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 128)          73856     ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 28, 28, 128)          512       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 28, 28, 128)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 128)          147584    ['re_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 28, 28, 128)          512       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 128)                  0         ['batch_normalization_11[0][0]\n",
            "  (GlobalAveragePooling2D)                                          ']                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 1)                    129       ['global_average_pooling2d_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  256       ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 128)          8320      ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)       (None, 28, 28, 128)          0         ['dense_7[0][0]',             \n",
            "                                                                     'batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 28, 28, 128)          512       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 28, 28, 128)          0         ['multiply_3[0][0]',          \n",
            "                                                                     'batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 14, 14, 256)          295168    ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 14, 14, 256)          1024      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 14, 14, 256)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 14, 14, 256)          590080    ['re_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 14, 14, 256)          1024      ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4  (None, 256)                  0         ['batch_normalization_14[0][0]\n",
            "  (GlobalAveragePooling2D)                                          ']                            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1)                    257       ['global_average_pooling2d_4[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 256)                  512       ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 256)          33024     ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)       (None, 14, 14, 256)          0         ['dense_9[0][0]',             \n",
            "                                                                     'batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 14, 14, 256)          1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 14, 14, 256)          0         ['multiply_4[0][0]',          \n",
            "                                                                     'batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 14, 14, 512)          1180160   ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 14, 14, 512)          2048      ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " input_B (InputLayer)        [(None, 21, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_5  (None, 512)                  0         ['batch_normalization_16[0][0]\n",
            "  (GlobalAveragePooling2D)                                          ']                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 21, 8)                32        ['input_B[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 16)                   8208      ['global_average_pooling2d_5[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 21, 16)               400       ['conv1d[0][0]']              \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 512)                  8704      ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 10, 16)               0         ['conv1d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)     (None, 1, 1, 512)            0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 10, 32)               1568      ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)       (None, 14, 14, 512)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'tf.reshape[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 10, 32)               0         ['conv1d_2[0][0]']            \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 14, 14, 512)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'multiply_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 10, 64)               6208      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 1, 1, 128)            7929984   ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 10, 64)               0         ['conv1d_3[0][0]']            \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1, 128)               0         ['conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 10, 128)              24704     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 1, 128)               0         ['reshape[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 10, 128)              0         ['conv1d_4[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 1, 128)               0         ['tf.__operators__.add[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 10, 128)              256       ['dropout_2[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 1, 128)               256       ['dropout_3[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 10, 128)              1054848   ['layer_normalization_1[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 1, 128)               1054848   ['layer_normalization_3[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 10, 128)              0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 1, 128)               0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 10, 128)              256       ['add_7[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 1, 128)               256       ['add_9[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 10, 256)              33024     ['layer_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 1, 256)               33024     ['layer_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 10, 256)              0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 1, 256)               0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 10, 128)              32896     ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 1, 128)               32896     ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 10, 128)              0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 1, 128)               0         ['dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 10, 128)              0         ['dropout_5[0][0]',           \n",
            "                                                                     'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 1, 128)               0         ['dropout_7[0][0]',           \n",
            "                                                                     'add_9[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 10, 128)              256       ['add_8[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_7 (Lay  (None, 1, 128)               256       ['add_10[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 10, 128)              1054848   ['layer_normalization_5[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (Mu  (None, 1, 128)               1054848   ['layer_normalization_7[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_7[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 10, 128)              0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_8[0][0]']               \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 1, 128)               0         ['multi_head_attention_4[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_10[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, 10, 128)              256       ['add_11[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_8 (Lay  (None, 1, 128)               256       ['add_13[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 10, 256)              33024     ['layer_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 1, 256)               33024     ['layer_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 10, 256)              0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 1, 256)               0         ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 10, 128)              32896     ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 1, 128)               32896     ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 10, 128)              0         ['dense_17[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 1, 128)               0         ['dense_19[0][0]']            \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 10, 128)              0         ['dropout_9[0][0]',           \n",
            "                                                                     'add_11[0][0]']              \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 1, 128)               0         ['dropout_11[0][0]',          \n",
            "                                                                     'add_13[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_9 (Lay  (None, 10, 128)              256       ['add_12[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_11 (La  (None, 1, 128)               256       ['add_14[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (Mu  (None, 10, 128)              1054848   ['layer_normalization_9[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_9[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (Mu  (None, 1, 128)               1054848   ['layer_normalization_11[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_15 (Add)                (None, 10, 128)              0         ['multi_head_attention_5[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_12[0][0]']              \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 1, 128)               0         ['multi_head_attention_6[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_14[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_10 (La  (None, 10, 128)              256       ['add_15[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_12 (La  (None, 1, 128)               256       ['add_17[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 10, 256)              33024     ['layer_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_22 (Dense)            (None, 1, 256)               33024     ['layer_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 10, 256)              0         ['dense_20[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 1, 256)               0         ['dense_22[0][0]']            \n",
            "                                                                                                  \n",
            " dense_21 (Dense)            (None, 10, 128)              32896     ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " dense_23 (Dense)            (None, 1, 128)               32896     ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 10, 128)              0         ['dense_21[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 1, 128)               0         ['dense_23[0][0]']            \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 10, 128)              0         ['dropout_13[0][0]',          \n",
            "                                                                     'add_15[0][0]']              \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 1, 128)               0         ['dropout_15[0][0]',          \n",
            "                                                                     'add_17[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_13 (La  (None, 10, 128)              256       ['add_16[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_15 (La  (None, 1, 128)               256       ['add_18[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (Mu  (None, 10, 128)              1054848   ['layer_normalization_13[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (Mu  (None, 1, 128)               1054848   ['layer_normalization_15[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_19 (Add)                (None, 10, 128)              0         ['multi_head_attention_7[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_16[0][0]']              \n",
            "                                                                                                  \n",
            " add_21 (Add)                (None, 1, 128)               0         ['multi_head_attention_8[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_18[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_14 (La  (None, 10, 128)              256       ['add_19[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_16 (La  (None, 1, 128)               256       ['add_21[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 10, 256)              33024     ['layer_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_26 (Dense)            (None, 1, 256)               33024     ['layer_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 10, 256)              0         ['dense_24[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)        (None, 1, 256)               0         ['dense_26[0][0]']            \n",
            "                                                                                                  \n",
            " dense_25 (Dense)            (None, 10, 128)              32896     ['dropout_16[0][0]']          \n",
            "                                                                                                  \n",
            " dense_27 (Dense)            (None, 1, 128)               32896     ['dropout_18[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)        (None, 10, 128)              0         ['dense_25[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)        (None, 1, 128)               0         ['dense_27[0][0]']            \n",
            "                                                                                                  \n",
            " add_20 (Add)                (None, 10, 128)              0         ['dropout_17[0][0]',          \n",
            "                                                                     'add_19[0][0]']              \n",
            "                                                                                                  \n",
            " add_22 (Add)                (None, 1, 128)               0         ['dropout_19[0][0]',          \n",
            "                                                                     'add_21[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_17 (La  (None, 10, 128)              256       ['add_20[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_19 (La  (None, 1, 128)               256       ['add_22[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_9 (Mu  (None, 10, 128)              1054848   ['layer_normalization_17[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_10 (M  (None, 1, 128)               1054848   ['layer_normalization_19[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_23 (Add)                (None, 10, 128)              0         ['multi_head_attention_9[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_20[0][0]']              \n",
            "                                                                                                  \n",
            " add_25 (Add)                (None, 1, 128)               0         ['multi_head_attention_10[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_22[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_18 (La  (None, 10, 128)              256       ['add_23[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_20 (La  (None, 1, 128)               256       ['add_25[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_28 (Dense)            (None, 10, 256)              33024     ['layer_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_30 (Dense)            (None, 1, 256)               33024     ['layer_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)        (None, 10, 256)              0         ['dense_28[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)        (None, 1, 256)               0         ['dense_30[0][0]']            \n",
            "                                                                                                  \n",
            " dense_29 (Dense)            (None, 10, 128)              32896     ['dropout_20[0][0]']          \n",
            "                                                                                                  \n",
            " dense_31 (Dense)            (None, 1, 128)               32896     ['dropout_22[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)        (None, 10, 128)              0         ['dense_29[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)        (None, 1, 128)               0         ['dense_31[0][0]']            \n",
            "                                                                                                  \n",
            " add_24 (Add)                (None, 10, 128)              0         ['dropout_21[0][0]',          \n",
            "                                                                     'add_23[0][0]']              \n",
            "                                                                                                  \n",
            " add_26 (Add)                (None, 1, 128)               0         ['dropout_23[0][0]',          \n",
            "                                                                     'add_25[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_21 (La  (None, 10, 128)              256       ['add_24[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_23 (La  (None, 1, 128)               256       ['add_26[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_11 (M  (None, 10, 128)              1054848   ['layer_normalization_21[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_12 (M  (None, 1, 128)               1054848   ['layer_normalization_23[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_27 (Add)                (None, 10, 128)              0         ['multi_head_attention_11[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_24[0][0]']              \n",
            "                                                                                                  \n",
            " add_29 (Add)                (None, 1, 128)               0         ['multi_head_attention_12[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_26[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_22 (La  (None, 10, 128)              256       ['add_27[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_24 (La  (None, 1, 128)               256       ['add_29[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_32 (Dense)            (None, 10, 256)              33024     ['layer_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_34 (Dense)            (None, 1, 256)               33024     ['layer_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_24 (Dropout)        (None, 10, 256)              0         ['dense_32[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_26 (Dropout)        (None, 1, 256)               0         ['dense_34[0][0]']            \n",
            "                                                                                                  \n",
            " dense_33 (Dense)            (None, 10, 128)              32896     ['dropout_24[0][0]']          \n",
            "                                                                                                  \n",
            " dense_35 (Dense)            (None, 1, 128)               32896     ['dropout_26[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_25 (Dropout)        (None, 10, 128)              0         ['dense_33[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_27 (Dropout)        (None, 1, 128)               0         ['dense_35[0][0]']            \n",
            "                                                                                                  \n",
            " add_28 (Add)                (None, 10, 128)              0         ['dropout_25[0][0]',          \n",
            "                                                                     'add_27[0][0]']              \n",
            "                                                                                                  \n",
            " add_30 (Add)                (None, 1, 128)               0         ['dropout_27[0][0]',          \n",
            "                                                                     'add_29[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_25 (La  (None, 10, 128)              256       ['add_28[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_27 (La  (None, 1, 128)               256       ['add_30[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_13 (M  (None, 10, 128)              1054848   ['layer_normalization_25[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_14 (M  (None, 1, 128)               1054848   ['layer_normalization_27[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_31 (Add)                (None, 10, 128)              0         ['multi_head_attention_13[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_28[0][0]']              \n",
            "                                                                                                  \n",
            " add_33 (Add)                (None, 1, 128)               0         ['multi_head_attention_14[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_30[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_26 (La  (None, 10, 128)              256       ['add_31[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_28 (La  (None, 1, 128)               256       ['add_33[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_36 (Dense)            (None, 10, 256)              33024     ['layer_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_38 (Dense)            (None, 1, 256)               33024     ['layer_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_28 (Dropout)        (None, 10, 256)              0         ['dense_36[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)        (None, 1, 256)               0         ['dense_38[0][0]']            \n",
            "                                                                                                  \n",
            " dense_37 (Dense)            (None, 10, 128)              32896     ['dropout_28[0][0]']          \n",
            "                                                                                                  \n",
            " dense_39 (Dense)            (None, 1, 128)               32896     ['dropout_30[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_29 (Dropout)        (None, 10, 128)              0         ['dense_37[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_31 (Dropout)        (None, 1, 128)               0         ['dense_39[0][0]']            \n",
            "                                                                                                  \n",
            " add_32 (Add)                (None, 10, 128)              0         ['dropout_29[0][0]',          \n",
            "                                                                     'add_31[0][0]']              \n",
            "                                                                                                  \n",
            " add_34 (Add)                (None, 1, 128)               0         ['dropout_31[0][0]',          \n",
            "                                                                     'add_33[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_29 (La  (None, 10, 128)              256       ['add_32[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_31 (La  (None, 1, 128)               256       ['add_34[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_15 (M  (None, 10, 128)              1054848   ['layer_normalization_29[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_16 (M  (None, 1, 128)               1054848   ['layer_normalization_31[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_35 (Add)                (None, 10, 128)              0         ['multi_head_attention_15[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_32[0][0]']              \n",
            "                                                                                                  \n",
            " add_37 (Add)                (None, 1, 128)               0         ['multi_head_attention_16[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_34[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_30 (La  (None, 10, 128)              256       ['add_35[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_32 (La  (None, 1, 128)               256       ['add_37[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_40 (Dense)            (None, 10, 256)              33024     ['layer_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_42 (Dense)            (None, 1, 256)               33024     ['layer_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)        (None, 10, 256)              0         ['dense_40[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)        (None, 1, 256)               0         ['dense_42[0][0]']            \n",
            "                                                                                                  \n",
            " dense_41 (Dense)            (None, 10, 128)              32896     ['dropout_32[0][0]']          \n",
            "                                                                                                  \n",
            " dense_43 (Dense)            (None, 1, 128)               32896     ['dropout_34[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)        (None, 10, 128)              0         ['dense_41[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)        (None, 1, 128)               0         ['dense_43[0][0]']            \n",
            "                                                                                                  \n",
            " add_36 (Add)                (None, 10, 128)              0         ['dropout_33[0][0]',          \n",
            "                                                                     'add_35[0][0]']              \n",
            "                                                                                                  \n",
            " add_38 (Add)                (None, 1, 128)               0         ['dropout_35[0][0]',          \n",
            "                                                                     'add_37[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_33 (La  (None, 10, 128)              256       ['add_36[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_35 (La  (None, 1, 128)               256       ['add_38[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_17 (M  (None, 10, 128)              1054848   ['layer_normalization_33[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_18 (M  (None, 1, 128)               1054848   ['layer_normalization_35[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_39 (Add)                (None, 10, 128)              0         ['multi_head_attention_17[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_36[0][0]']              \n",
            "                                                                                                  \n",
            " add_41 (Add)                (None, 1, 128)               0         ['multi_head_attention_18[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_38[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_34 (La  (None, 10, 128)              256       ['add_39[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_36 (La  (None, 1, 128)               256       ['add_41[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_44 (Dense)            (None, 10, 256)              33024     ['layer_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_46 (Dense)            (None, 1, 256)               33024     ['layer_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_36 (Dropout)        (None, 10, 256)              0         ['dense_44[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)        (None, 1, 256)               0         ['dense_46[0][0]']            \n",
            "                                                                                                  \n",
            " dense_45 (Dense)            (None, 10, 128)              32896     ['dropout_36[0][0]']          \n",
            "                                                                                                  \n",
            " dense_47 (Dense)            (None, 1, 128)               32896     ['dropout_38[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)        (None, 10, 128)              0         ['dense_45[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_39 (Dropout)        (None, 1, 128)               0         ['dense_47[0][0]']            \n",
            "                                                                                                  \n",
            " add_40 (Add)                (None, 10, 128)              0         ['dropout_37[0][0]',          \n",
            "                                                                     'add_39[0][0]']              \n",
            "                                                                                                  \n",
            " add_42 (Add)                (None, 1, 128)               0         ['dropout_39[0][0]',          \n",
            "                                                                     'add_41[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_37 (La  (None, 10, 128)              256       ['add_40[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_39 (La  (None, 1, 128)               256       ['add_42[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_19 (M  (None, 10, 128)              1054848   ['layer_normalization_37[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_20 (M  (None, 1, 128)               1054848   ['layer_normalization_39[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_43 (Add)                (None, 10, 128)              0         ['multi_head_attention_19[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_40[0][0]']              \n",
            "                                                                                                  \n",
            " add_45 (Add)                (None, 1, 128)               0         ['multi_head_attention_20[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_42[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_38 (La  (None, 10, 128)              256       ['add_43[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_40 (La  (None, 1, 128)               256       ['add_45[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_48 (Dense)            (None, 10, 256)              33024     ['layer_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_50 (Dense)            (None, 1, 256)               33024     ['layer_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_40 (Dropout)        (None, 10, 256)              0         ['dense_48[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_42 (Dropout)        (None, 1, 256)               0         ['dense_50[0][0]']            \n",
            "                                                                                                  \n",
            " dense_49 (Dense)            (None, 10, 128)              32896     ['dropout_40[0][0]']          \n",
            "                                                                                                  \n",
            " dense_51 (Dense)            (None, 1, 128)               32896     ['dropout_42[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_41 (Dropout)        (None, 10, 128)              0         ['dense_49[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_43 (Dropout)        (None, 1, 128)               0         ['dense_51[0][0]']            \n",
            "                                                                                                  \n",
            " add_44 (Add)                (None, 10, 128)              0         ['dropout_41[0][0]',          \n",
            "                                                                     'add_43[0][0]']              \n",
            "                                                                                                  \n",
            " add_46 (Add)                (None, 1, 128)               0         ['dropout_43[0][0]',          \n",
            "                                                                     'add_45[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_41 (La  (None, 10, 128)              256       ['add_44[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_43 (La  (None, 1, 128)               256       ['add_46[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_21 (M  (None, 10, 128)              1054848   ['layer_normalization_41[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_22 (M  (None, 1, 128)               1054848   ['layer_normalization_43[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_47 (Add)                (None, 10, 128)              0         ['multi_head_attention_21[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_44[0][0]']              \n",
            "                                                                                                  \n",
            " add_49 (Add)                (None, 1, 128)               0         ['multi_head_attention_22[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_46[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_42 (La  (None, 10, 128)              256       ['add_47[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_44 (La  (None, 1, 128)               256       ['add_49[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_52 (Dense)            (None, 10, 256)              33024     ['layer_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_54 (Dense)            (None, 1, 256)               33024     ['layer_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_44 (Dropout)        (None, 10, 256)              0         ['dense_52[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_46 (Dropout)        (None, 1, 256)               0         ['dense_54[0][0]']            \n",
            "                                                                                                  \n",
            " dense_53 (Dense)            (None, 10, 128)              32896     ['dropout_44[0][0]']          \n",
            "                                                                                                  \n",
            " dense_55 (Dense)            (None, 1, 128)               32896     ['dropout_46[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_45 (Dropout)        (None, 10, 128)              0         ['dense_53[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_47 (Dropout)        (None, 1, 128)               0         ['dense_55[0][0]']            \n",
            "                                                                                                  \n",
            " add_48 (Add)                (None, 10, 128)              0         ['dropout_45[0][0]',          \n",
            "                                                                     'add_47[0][0]']              \n",
            "                                                                                                  \n",
            " add_50 (Add)                (None, 1, 128)               0         ['dropout_47[0][0]',          \n",
            "                                                                     'add_49[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_45 (La  (None, 10, 128)              256       ['add_48[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_47 (La  (None, 1, 128)               256       ['add_50[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_23 (M  (None, 10, 128)              1054848   ['layer_normalization_45[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_24 (M  (None, 1, 128)               1054848   ['layer_normalization_47[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_51 (Add)                (None, 10, 128)              0         ['multi_head_attention_23[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_48[0][0]']              \n",
            "                                                                                                  \n",
            " add_53 (Add)                (None, 1, 128)               0         ['multi_head_attention_24[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_50[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_46 (La  (None, 10, 128)              256       ['add_51[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_48 (La  (None, 1, 128)               256       ['add_53[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_56 (Dense)            (None, 10, 256)              33024     ['layer_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_58 (Dense)            (None, 1, 256)               33024     ['layer_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_48 (Dropout)        (None, 10, 256)              0         ['dense_56[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_50 (Dropout)        (None, 1, 256)               0         ['dense_58[0][0]']            \n",
            "                                                                                                  \n",
            " dense_57 (Dense)            (None, 10, 128)              32896     ['dropout_48[0][0]']          \n",
            "                                                                                                  \n",
            " dense_59 (Dense)            (None, 1, 128)               32896     ['dropout_50[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_49 (Dropout)        (None, 10, 128)              0         ['dense_57[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_51 (Dropout)        (None, 1, 128)               0         ['dense_59[0][0]']            \n",
            "                                                                                                  \n",
            " add_52 (Add)                (None, 10, 128)              0         ['dropout_49[0][0]',          \n",
            "                                                                     'add_51[0][0]']              \n",
            "                                                                                                  \n",
            " add_54 (Add)                (None, 1, 128)               0         ['dropout_51[0][0]',          \n",
            "                                                                     'add_53[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_49 (La  (None, 10, 128)              256       ['add_52[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_51 (La  (None, 1, 128)               256       ['add_54[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_25 (M  (None, 10, 128)              1054848   ['layer_normalization_49[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_26 (M  (None, 1, 128)               1054848   ['layer_normalization_51[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_55 (Add)                (None, 10, 128)              0         ['multi_head_attention_25[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_52[0][0]']              \n",
            "                                                                                                  \n",
            " add_57 (Add)                (None, 1, 128)               0         ['multi_head_attention_26[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_54[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_50 (La  (None, 10, 128)              256       ['add_55[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_52 (La  (None, 1, 128)               256       ['add_57[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_60 (Dense)            (None, 10, 256)              33024     ['layer_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_62 (Dense)            (None, 1, 256)               33024     ['layer_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_52 (Dropout)        (None, 10, 256)              0         ['dense_60[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_54 (Dropout)        (None, 1, 256)               0         ['dense_62[0][0]']            \n",
            "                                                                                                  \n",
            " dense_61 (Dense)            (None, 10, 128)              32896     ['dropout_52[0][0]']          \n",
            "                                                                                                  \n",
            " dense_63 (Dense)            (None, 1, 128)               32896     ['dropout_54[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_53 (Dropout)        (None, 10, 128)              0         ['dense_61[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_55 (Dropout)        (None, 1, 128)               0         ['dense_63[0][0]']            \n",
            "                                                                                                  \n",
            " add_56 (Add)                (None, 10, 128)              0         ['dropout_53[0][0]',          \n",
            "                                                                     'add_55[0][0]']              \n",
            "                                                                                                  \n",
            " add_58 (Add)                (None, 1, 128)               0         ['dropout_55[0][0]',          \n",
            "                                                                     'add_57[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_53 (La  (None, 10, 128)              256       ['add_56[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_55 (La  (None, 1, 128)               256       ['add_58[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_27 (M  (None, 10, 128)              1054848   ['layer_normalization_53[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_28 (M  (None, 1, 128)               1054848   ['layer_normalization_55[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_59 (Add)                (None, 10, 128)              0         ['multi_head_attention_27[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_56[0][0]']              \n",
            "                                                                                                  \n",
            " add_61 (Add)                (None, 1, 128)               0         ['multi_head_attention_28[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_58[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_54 (La  (None, 10, 128)              256       ['add_59[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_56 (La  (None, 1, 128)               256       ['add_61[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_64 (Dense)            (None, 10, 256)              33024     ['layer_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_66 (Dense)            (None, 1, 256)               33024     ['layer_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_56 (Dropout)        (None, 10, 256)              0         ['dense_64[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_58 (Dropout)        (None, 1, 256)               0         ['dense_66[0][0]']            \n",
            "                                                                                                  \n",
            " dense_65 (Dense)            (None, 10, 128)              32896     ['dropout_56[0][0]']          \n",
            "                                                                                                  \n",
            " dense_67 (Dense)            (None, 1, 128)               32896     ['dropout_58[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_57 (Dropout)        (None, 10, 128)              0         ['dense_65[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_59 (Dropout)        (None, 1, 128)               0         ['dense_67[0][0]']            \n",
            "                                                                                                  \n",
            " add_60 (Add)                (None, 10, 128)              0         ['dropout_57[0][0]',          \n",
            "                                                                     'add_59[0][0]']              \n",
            "                                                                                                  \n",
            " add_62 (Add)                (None, 1, 128)               0         ['dropout_59[0][0]',          \n",
            "                                                                     'add_61[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_57 (La  (None, 10, 128)              256       ['add_60[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_59 (La  (None, 1, 128)               256       ['add_62[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_29 (M  (None, 10, 128)              1054848   ['layer_normalization_57[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_30 (M  (None, 1, 128)               1054848   ['layer_normalization_59[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_63 (Add)                (None, 10, 128)              0         ['multi_head_attention_29[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_60[0][0]']              \n",
            "                                                                                                  \n",
            " add_65 (Add)                (None, 1, 128)               0         ['multi_head_attention_30[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_62[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_58 (La  (None, 10, 128)              256       ['add_63[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_60 (La  (None, 1, 128)               256       ['add_65[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_68 (Dense)            (None, 10, 256)              33024     ['layer_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_70 (Dense)            (None, 1, 256)               33024     ['layer_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_60 (Dropout)        (None, 10, 256)              0         ['dense_68[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_62 (Dropout)        (None, 1, 256)               0         ['dense_70[0][0]']            \n",
            "                                                                                                  \n",
            " dense_69 (Dense)            (None, 10, 128)              32896     ['dropout_60[0][0]']          \n",
            "                                                                                                  \n",
            " dense_71 (Dense)            (None, 1, 128)               32896     ['dropout_62[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_61 (Dropout)        (None, 10, 128)              0         ['dense_69[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_63 (Dropout)        (None, 1, 128)               0         ['dense_71[0][0]']            \n",
            "                                                                                                  \n",
            " add_64 (Add)                (None, 10, 128)              0         ['dropout_61[0][0]',          \n",
            "                                                                     'add_63[0][0]']              \n",
            "                                                                                                  \n",
            " add_66 (Add)                (None, 1, 128)               0         ['dropout_63[0][0]',          \n",
            "                                                                     'add_65[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_61 (La  (None, 10, 128)              256       ['add_64[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_63 (La  (None, 1, 128)               256       ['add_66[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_31 (M  (None, 10, 128)              1054848   ['layer_normalization_61[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_32 (M  (None, 1, 128)               1054848   ['layer_normalization_63[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_67 (Add)                (None, 10, 128)              0         ['multi_head_attention_31[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_64[0][0]']              \n",
            "                                                                                                  \n",
            " add_69 (Add)                (None, 1, 128)               0         ['multi_head_attention_32[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_66[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_62 (La  (None, 10, 128)              256       ['add_67[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_64 (La  (None, 1, 128)               256       ['add_69[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_72 (Dense)            (None, 10, 256)              33024     ['layer_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_74 (Dense)            (None, 1, 256)               33024     ['layer_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_64 (Dropout)        (None, 10, 256)              0         ['dense_72[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_66 (Dropout)        (None, 1, 256)               0         ['dense_74[0][0]']            \n",
            "                                                                                                  \n",
            " dense_73 (Dense)            (None, 10, 128)              32896     ['dropout_64[0][0]']          \n",
            "                                                                                                  \n",
            " dense_75 (Dense)            (None, 1, 128)               32896     ['dropout_66[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_65 (Dropout)        (None, 10, 128)              0         ['dense_73[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_67 (Dropout)        (None, 1, 128)               0         ['dense_75[0][0]']            \n",
            "                                                                                                  \n",
            " add_68 (Add)                (None, 10, 128)              0         ['dropout_65[0][0]',          \n",
            "                                                                     'add_67[0][0]']              \n",
            "                                                                                                  \n",
            " add_70 (Add)                (None, 1, 128)               0         ['dropout_67[0][0]',          \n",
            "                                                                     'add_69[0][0]']              \n",
            "                                                                                                  \n",
            " cross_attention_1 (CrossAt  multiple                     1055104   ['add_68[0][0]',              \n",
            " tention)                                                            'add_70[0][0]',              \n",
            "                                                                     'add_70[0][0]',              \n",
            "                                                                     'add_68[0][0]']              \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)      (None, 11, 128)              0         ['cross_attention_1[0][0]',   \n",
            "                                                                     'cross_attention_1[1][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_65 (La  (None, 11, 128)              256       ['tf.concat[0][0]']           \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 128)                  0         ['layer_normalization_65[0][0]\n",
            " GlobalAveragePooling1D)                                            ']                            \n",
            "                                                                                                  \n",
            " dense_76 (Dense)            (None, 128)                  16512     ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 128)                  0         ['dense_76[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 128)                  512       ['re_lu_7[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_77 (Dense)            (None, 64)                   8256      ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 64)                   0         ['dense_77[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 64)                   256       ['re_lu_8[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_78 (Dense)            (None, 32)                   2080      ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 32)                   0         ['dense_78[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 32)                   128       ['re_lu_9[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " output_12 (Dense)           (None, 3)                    99        ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47590632 (181.54 MB)\n",
            "Trainable params: 47585704 (181.53 MB)\n",
            "Non-trainable params: 4928 (19.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Ver la cantidad de parametros del modelo\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxfVYh9sk68W",
        "outputId": "eeef272a-e37f-4e54-9942-9b7848d0613a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 2, 1])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_data['diagnosis_x'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEXC8qH4kiLt",
        "outputId": "ec00413b-2e39-47f8-f70a-33cf3dda82bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 710ms/step\n"
          ]
        }
      ],
      "source": [
        "classes=[\"AD\",\"bvFTD\",\"HC\"]\n",
        "#Calculo del a matriz de confusion\n",
        "y_pred = model.predict([X_test_flat,X_test_img])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convertir las predicciones de categorías one-hot a etiquetas de clase\n",
        "y_true = y_test\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "91SmKKKy8dZH",
        "outputId": "488f33a8-f477-4184-ce51-4d0302e3e7be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "conf_matrix_percent = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Grafica la matriz de confusión con porcentajes\n",
        "sns.heatmap(conf_matrix_percent, annot=True, fmt='.1f', cmap='Blues', cbar=True,\n",
        "            xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predictions')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Percentages of the confusion matrix')\n",
        "plt.savefig('Matriz_Confusion_Porcentajes.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBkkYT4GVaut",
        "outputId": "10451838-197e-415e-be2f-f8de6c7ee00e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AD       1.00      1.00      1.00         6\n",
            "       bvFTD       1.00      1.00      1.00         3\n",
            "          HC       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00        12\n",
            "   macro avg       1.00      1.00      1.00        12\n",
            "weighted avg       1.00      1.00      1.00        12\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generar el informe de clasificación\n",
        "report = classification_report(y_true, y_pred_classes, target_names=classes)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "8YOZTvSTVaut",
        "outputId": "c35f56ec-dddb-4dc3-f244-554dcb879434"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "report = classification_report(y_true, y_pred_classes, output_dict=True, target_names=classes)\n",
        "# Eliminar 'accuracy', 'macro avg' y 'weighted avg' para centrarnos en las clases y micro avg\n",
        "del  report['macro avg'], report['weighted avg']\n",
        "\n",
        "# Convertir el reporte en DataFrame de Pandas\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Crear el mapa de calor para la cuadrícula\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(df_report.iloc[:-1, :-1], annot=True, fmt=\".2f\", cmap='Blues', linewidths=.5, vmin=0, vmax=1)\n",
        "plt.title('Bimodal clasification report')\n",
        "plt.xlabel('Metrics')\n",
        "plt.savefig('heatmap_reportimg.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "glan0fiuVaut",
        "outputId": "176aac3d-9ccc-4cad-ce5f-07335d56bf6e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "report = classification_report(y_true, y_pred_classes, digits=4, output_dict=True, zero_division=0, target_names=classes)\n",
        "\n",
        "# Eliminar 'accuracy' y 'macro avg' para centrarnos en las clases y micro avg\n",
        "del report['macro avg'], report['weighted avg']\n",
        "\n",
        "# Extraer datos para la gráfica\n",
        "labels = classes\n",
        "precision = [report[label]['precision'] for label in labels]\n",
        "recall = [report[label]['recall'] for label in labels]\n",
        "f1_score = [report[label]['f1-score'] for label in labels]\n",
        "support = [report[label]['support'] for label in labels]\n",
        "\n",
        "# Tamaño de la gráfica\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Índices para las barras\n",
        "index = np.arange(len(labels))\n",
        "bar_width = 0.25\n",
        "\n",
        "# Crear barras para precision, recall y f1-score\n",
        "rects1 = ax.bar(index, precision, bar_width, label='Precision', color='skyblue')\n",
        "rects2 = ax.bar(index + bar_width, recall, bar_width, label='Recall', color='deepskyblue')\n",
        "rects3 = ax.bar(index + 2 * bar_width, f1_score, bar_width, label='F1-Score', color='midnightblue')\n",
        "\n",
        "\n",
        "# Añadir etiquetas, leyenda, título y ejes\n",
        "ax.set_xlabel('Clases')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Bimodal classification report')\n",
        "ax.set_xticks(index + bar_width)\n",
        "ax.set_xticklabels(labels)\n",
        "\n",
        "# Colocar la leyenda debajo del gráfico\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=3)\n",
        "\n",
        "# Función para añadir etiquetas de texto a las barras\n",
        "def add_labels(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.3f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "# Añadir etiquetas a cada barra\n",
        "add_labels(rects1)\n",
        "add_labels(rects2)\n",
        "add_labels(rects3)\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.savefig('classification_reportimg.pdf')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "12Kq1luXELUX",
        "9k6kPNDhFJS_",
        "kyE04oUjFOIq",
        "VD13NMM1FwOi",
        "4dmWVW-bF22N",
        "KbWdIqMHGXc9",
        "yNKHllLbMl-D",
        "3ad1-ZVaGZ2o",
        "EToG6mrvs9zr",
        "9HOwLcJxkDTu"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
