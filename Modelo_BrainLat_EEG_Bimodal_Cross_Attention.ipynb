{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Kq1luXELUX"
      },
      "source": [
        "# Libreria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwmyiK0Ex71H"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow==2.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7ubk3qVEs3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c7ed63-76ef-49c2-ee1b-4e4dbc9c0d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-348850448.py:38: DeprecationWarning: scipy.misc is deprecated and will be removed in 2.0.0\n",
            "  from scipy import ndimage, misc, signal\n"
          ]
        }
      ],
      "source": [
        "# Librerías esenciales\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "# Visualización\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# TensorFlow y Keras (usa solo tensorflow.keras, NO importes keras separado)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, ReLU,\n",
        "    AveragePooling2D, GlobalAveragePooling2D, UpSampling2D, Lambda, Add, Concatenate\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers, regularizers\n",
        "from tensorflow.keras import layers # Import the layers module\n",
        "import keras\n",
        "# Machine Learning y métricas\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,\n",
        "    classification_report, roc_curve, auc, cohen_kappa_score, hamming_loss,\n",
        "    log_loss, zero_one_loss, matthews_corrcoef\n",
        ")\n",
        "\n",
        "# Procesamiento de imágenes\n",
        "import cv2\n",
        "from skimage.util.shape import view_as_blocks\n",
        "from scipy import ndimage, misc, signal\n",
        "\n",
        "# Yellowbrick (visualización de métricas)\n",
        "from yellowbrick.classifier import ClassificationReport\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kcUbYkAi1kr",
        "outputId": "78ef0883-6ae6-4da6-8aa8-11466671997f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4UgQUmSnwo8",
        "outputId": "c09c87a6-0ebe-4957-c734-ce0cc096832e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85R-L_pXHM3C",
        "outputId": "0bcb004d-847d-4a9e-ed8a-61e2c58e6516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k6kPNDhFJS_"
      },
      "source": [
        "# Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBRHX3lgllXN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "#Cargar los datos planos desde el archivo CSV\n",
        "# flat_data_path = \"/content/drive/MyDrive/BrainLat/Brainlat_Prueba/data_xgb_Prueba.csv\"\n",
        "flat_data_path = \"/content/drive/MyDrive/BrainLat/Brainlat_Prueba/brainlat_EEG_Clean_Prueba.csv\"\n",
        "flat_data = pd.read_csv(flat_data_path)  # Ajustar el delimitador según corresponda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_data.columns\n",
        "# Codificar las etiquetas y seleccionar las características\n",
        "flat_data['diagnosis_x'] = LabelEncoder().fit_transform(flat_data['diagnosis_x'])\n",
        "labels = flat_data['diagnosis_x'].to_numpy()\n",
        "features = flat_data.drop(['id EEG', 'diagnosis_x'], axis=1)  # Excluir columnas irrelevantes"
      ],
      "metadata": {
        "id": "ojzz1FGTuLeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(features.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA6-pBj1Tj9x",
        "outputId": "ca1c319b-8d58-441e-e17f-fd72519bdbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqtNSITSl4vN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb5e805-945f-4fd4-a325-f8d469a0d94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30001.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30002.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30004.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30008.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30009.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30011.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30012.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30013.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30015.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30018.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30020.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30022.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30026.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30029.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30031.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30003.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30006.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30016.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30021.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30023.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30019.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30024.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30025.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30027.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30028.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30033.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30035.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/1_AD/sub-30034.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20001.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20003.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20006.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20009.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20010.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20012.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20014.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20015.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20016.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20017.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20018.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20019.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/2_bvFTD/sub-20002.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10002.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10003.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10004.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10006.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10007.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-10009.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100012.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100015.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100018.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100020.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100022.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100024.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100026.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100031.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100033.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100035.npy\n",
            "/content/drive/MyDrive/BrainLat/Vectores/sfft/5_HC/sub-100010.npy\n"
          ]
        }
      ],
      "source": [
        "# Ruta base para las STFT\n",
        "stft_folder = \"/content/drive/MyDrive/BrainLat/Vectores/sfft\"\n",
        "\n",
        "# Inicializar listas para almacenar datos\n",
        "eeg_data = []\n",
        "labels_stft = []\n",
        "flat_features = []\n",
        "\n",
        "# Recorrer los registros para cargar STFT y emparejar con los datos planos\n",
        "for index, row in flat_data.iterrows():\n",
        "    participant_id = row['id EEG']\n",
        "    label_folder = None\n",
        "\n",
        "    # Determinar la subcarpeta basada en el diagnóstico\n",
        "    if row['diagnosis_x'] == 0:  # Cambiar el mapeo según corresponda\n",
        "        label_folder = \"1_AD\"\n",
        "    elif row['diagnosis_x'] == 2:\n",
        "        label_folder = \"2_bvFTD\"\n",
        "    elif row['diagnosis_x'] == 1:\n",
        "        label_folder = \"5_HC\"\n",
        "\n",
        "    if label_folder:\n",
        "        file_path = os.path.join(stft_folder, label_folder, f\"{participant_id}.npy\")\n",
        "        print(file_path)\n",
        "        if os.path.exists(file_path):\n",
        "            #eeg_array = np.load(file_path)\n",
        "            #eeg_data.append(eeg_array)\n",
        "            labels_stft.append(row['diagnosis_x'])\n",
        "            flat_features.append(features.loc[index].to_numpy())\n",
        "        else:\n",
        "            print(f\"Archivo {file_path} no encontrado. Ignorando este participante.\")\n",
        "\n",
        "# Convertir las listas a numpy arrays\n",
        "#eeg_data = np.array(eeg_data)  # STFT\n",
        "flat_features = np.array(flat_features)  # Datos planos\n",
        "labels_stft = np.array(labels_stft)  # Etiquetas\n",
        "\n",
        "# # Combinar los datos planos y las STFT en una estructura conjunta\n",
        "# combined_data = list(zip(flat_features, eeg_data, labels_stft))\n",
        "\n",
        "# # Dividir en conjuntos de entrenamiento y prueba\n",
        "# train_data, test_data = train_test_split(combined_data, test_size=0.2, random_state=45, stratify=labels_stft)\n",
        "\n",
        "# # Separar datos en componentes individuales\n",
        "# X_train_flat, X_train_img, y_train = zip(*train_data)\n",
        "# X_test_flat, X_test_img, y_test = zip(*test_data)\n",
        "\n",
        "# # Convertir de nuevo a numpy arrays\n",
        "# X_train_flat = np.array(X_train_flat)\n",
        "# X_train_img = np.array(X_train_img)\n",
        "# y_train = np.array(y_train)\n",
        "\n",
        "# X_test_flat = np.array(X_test_flat)\n",
        "# X_test_img = np.array(X_test_img)\n",
        "# y_test = np.array(y_test)\n",
        "\n",
        "# scaler = StandardScaler().fit(X_train_flat)\n",
        "# X_train_flat = scaler.transform(X_train_flat)\n",
        "# X_test_flat = scaler.transform(X_test_flat)\n",
        "# # from sklearn import decomposition\n",
        "# # pca = decomposition.PCA(n_components=0.96,svd_solver='full',tol=1e-4)\n",
        "# # pca.fit(X_train_flat)\n",
        "# # X_train_flat = pca.transform(X_train_flat)\n",
        "# # X_test_flat=pca.transform(X_test_flat)\n",
        "# # Imprimir tamaños de los conjuntos\n",
        "# print(\"Datos planos:\")\n",
        "# print(f\"X_train_flat shape: {X_train_flat.shape}, y_train shape: {y_train.shape}\")\n",
        "# print(f\"X_test_flat shape: {X_test_flat.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "# print(\"\\nImágenes STFT:\")\n",
        "# print(f\"X_train_img shape: {X_train_img.shape}\")\n",
        "# print(f\"X_test_img shape: {X_test_img.shape}\")\n",
        "\n",
        "# # Preparar los datos para el modelo\n",
        "# train_data = [X_train_flat, X_train_img]  # Datos planos y STFT para entrenamiento\n",
        "# test_data = [X_test_flat, X_test_img]    # Datos planos y STFT para prueba/validación"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_features.shape"
      ],
      "metadata": {
        "id": "GQmoVTciUF9g",
        "outputId": "d6947d66-59f0-44cf-b934-db973da316c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyE04oUjFOIq"
      },
      "source": [
        "# Funciones e hiperFunciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa4I_2yVFluG"
      },
      "outputs": [],
      "source": [
        "def squeeze_excitation_layer(input_layer, out_dim, ratio, conv):\n",
        "  squeeze = tf.keras.layers.GlobalAveragePooling2D()(input_layer)\n",
        "  excitation = tf.keras.layers.Dense(units=out_dim / ratio, activation='relu')(squeeze)\n",
        "  excitation = tf.keras.layers.Dense(out_dim,activation='sigmoid')(excitation)\n",
        "  excitation = tf.reshape(excitation, [-1,1,1,out_dim])\n",
        "  scale = tf.keras.layers.multiply([input_layer, excitation])\n",
        "  if conv:\n",
        "    shortcut = tf.keras.layers.Conv2D(out_dim,kernel_size=1,strides=1,\n",
        "                                      padding='same',kernel_initializer='he_normal')(input_layer)\n",
        "    shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  else:\n",
        "    shortcut = input_layer\n",
        "  out = tf.keras.layers.add([shortcut, scale])\n",
        "  return out\n",
        "\n",
        "def sreLu (input):\n",
        "  return ReLU(negative_slope=0.1, threshold=0)(input)\n",
        "\n",
        "def sConv(input,parameters,size,nstrides):\n",
        "  return Conv2D(parameters, (size,size), strides=(nstrides,nstrides),padding=\"same\", kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(input)\n",
        "\n",
        "def sBN (input):\n",
        "  return tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(input)\n",
        "\n",
        "def sGlobal_Avg_Pooling (input):\n",
        "  return tf.keras.layers.GlobalAveragePooling2D()(input)\n",
        "\n",
        "def sDense (input, n_units, activate_c):\n",
        "  return tf.keras.layers.Dense(n_units,activation=activate_c)(input)\n",
        "\n",
        "def smultiply (input_1, input_2):\n",
        "  return tf.keras.layers.multiply([input_1, input_2])\n",
        "\n",
        "def sadd (input_1, input_2):\n",
        "  return tf.keras.layers.add([input_1, input_2])\n",
        "\n",
        "\n",
        "initial_learning_rate = 0.001\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
        ") #A la medida\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD13NMM1FwOi"
      },
      "source": [
        "# Bloques TF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL2Kn8dJFrw-"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.python.ops.gen_array_ops import shape\n",
        "\n",
        "def Block_3 (input, parameter): # A\n",
        "  addition = sConv(input, parameter, 1, 2)\n",
        "  addition = sBN(addition)\n",
        "  output = sConv(input, parameter, 3, 2)\n",
        "  output = sBN(output)\n",
        "  output = sreLu(output)\n",
        "  output = sConv(output, parameter, 3, 1)\n",
        "  output = sBN(output)\n",
        "  multiplier = SE_Block(output,  parameter, parameter)\n",
        "  output = smultiply(multiplier, output)\n",
        "  output = sadd(output, addition)\n",
        "  return output\n",
        "\n",
        "def Block_1 (input, parameter): #B\n",
        "  output = sConv(input, parameter, 3, 1)\n",
        "  output = sBN(output)\n",
        "  output = sreLu(output)\n",
        "  return output\n",
        "\n",
        "\n",
        "def Block_2 (input, parameter): #C\n",
        "  output = Block_1(input, parameter)\n",
        "  output = sConv(output, parameter, 3, 1)\n",
        "  output = sBN(output)\n",
        "  multiplier = SE_Block(output,  parameter, parameter)\n",
        "  # output = smultiply(output, output)\n",
        "  output = smultiply(multiplier, output)\n",
        "  output = sadd(output, input)\n",
        "  return output\n",
        "\n",
        "def SE_Block(input, out_dim, ratio):\n",
        "  output = sGlobal_Avg_Pooling(input)\n",
        "  output = sDense(output, out_dim/ratio, 'relu')\n",
        "  output = sDense(output, out_dim, 'sigmoid')\n",
        "  return output\n",
        "\n",
        "\n",
        "\n",
        "def Block_4 (input, parameter):\n",
        "  output = Block_1(input, parameter)\n",
        "  output = sConv(input, parameter, 3, 1)\n",
        "  output = sBN(output)\n",
        "  return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dmWVW-bF22N"
      },
      "source": [
        "# Hiperparametros TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLgmYditGDLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09c4567b-4ea3-48fc-871a-7d0617442b39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "NUM_LAYERS = 16\n",
        "#------------Projected_Patches-----------------\n",
        "IMAGE_SIZE_2 =  13# We will resize input images to this size.\n",
        "PATCH_SIZE_2 = 11  # Size of the patches to be extracted from the input images.\n",
        "NUM_PATCHES_2 = (IMAGE_SIZE_2 // PATCH_SIZE_2) ** 2\n",
        "print(NUM_PATCHES_2)\n",
        "#------------Attention_Data----------------------\n",
        "LAYER_NORM_EPS_1 = 1e-6\n",
        "PROJECTION_DIM_1 = 128 # No se puede modificar\n",
        "NUM_HEADS_1 = 16\n",
        "MLP_UNITS_1 = [\n",
        "    PROJECTION_DIM_1 * 2,\n",
        "    PROJECTION_DIM_1\n",
        "]\n",
        "#------------Attention_Images------------------\n",
        "LAYER_NORM_EPS_2 = 1e-6\n",
        "PROJECTION_DIM_2 = 128\n",
        "NUM_HEADS_2 = 16\n",
        "MLP_UNITS_2 = [\n",
        "    PROJECTION_DIM_2 * 2,\n",
        "    PROJECTION_DIM_2\n",
        "]\n",
        "#---------Cross_Attention\n",
        "NUM_HEADS_3 = 16\n",
        "PROJECTION_DIM_3 = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbWdIqMHGXc9"
      },
      "source": [
        "# TF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0ifUQvpZ2Os"
      },
      "outputs": [],
      "source": [
        "def position_embedding(projected_patches, num_patches=NUM_PATCHES_2, projection_dim=PROJECTION_DIM_2):\n",
        "    # Build the positions.\n",
        "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "    # Encode the positions with an Embedding layer.\n",
        "    encoded_positions = layers.Embedding(\n",
        "        input_dim=num_patches, output_dim=projection_dim\n",
        "    )(positions)\n",
        "    # Add encoded positions to the projected patches.\n",
        "    return projected_patches + encoded_positions\n",
        "\n",
        "def mlp(x, dropout_rate, hidden_units):\n",
        "    # Iterate over the hidden units and\n",
        "    # add Dense => Dropout.\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self,**kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x, y, **kwargs):\n",
        "    attn, attention_scores = self.mha(\n",
        "             query=x, value=y,\n",
        "             return_attention_scores=True)\n",
        "\n",
        "    self.last_attention_scores = attention_scores\n",
        "\n",
        "    x = self.add([x, attn])\n",
        "    return self.layernorm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt5IcLMLGWLw"
      },
      "outputs": [],
      "source": [
        "def Attention_Data(encoded_patches):\n",
        "    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS_1)(encoded_patches)\n",
        "    # Multi Head Self Attention layer 1.\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS_1, key_dim=PROJECTION_DIM_1, dropout=0.1\n",
        "    )(x1, x1)\n",
        "    # Skip connection 1.\n",
        "    x2 = layers.Add()([attention_output, encoded_patches])\n",
        "    # Layer normalization 2.\n",
        "    x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS_1)(x2)\n",
        "    # MLP layer 1.\n",
        "    x4 = mlp(x3, hidden_units=MLP_UNITS_1, dropout_rate=0.1)\n",
        "    # Skip connection 2.\n",
        "    encoded_patches_1 = layers.Add()([x4, x2])\n",
        "    return encoded_patches_1\n",
        "\n",
        "def Attention_Images(encoded_patches):\n",
        "    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS_2)(encoded_patches)\n",
        "    # Multi Head Self Attention layer 1.\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS_2, key_dim=PROJECTION_DIM_2, dropout=0.1\n",
        "    )(x1, x1) #Dos atenciones, de datos planos y de imagenes\n",
        "    #Seguida el cross atencion\n",
        "    # Skip connection 1.\n",
        "    x2 = layers.Add()([attention_output, encoded_patches])\n",
        "    # Layer normalization 2.\n",
        "    x3 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS_2)(x2)\n",
        "    # MLP layer 1.\n",
        "    x4 = mlp(x3, hidden_units=MLP_UNITS_2, dropout_rate=0.1)\n",
        "    # Skip connection 2.\n",
        "    encoded_patches = layers.Add()([x4, x2])\n",
        "    return encoded_patches #Despues de esto ahi si se manda al cross atention de cada una, un encoded patches de datos y un encoded patches de imagenes\n",
        "\n",
        "def Transformer(inputs,layer): #layers,Dropout_1---imagen,datos\n",
        "    # atencion al canal\n",
        "    input = squeeze_excitation_layer(inputs, out_dim=512, ratio=32.0, conv=False)\n",
        "    print(input.shape)\n",
        "    projected_patches = layers.Conv2D(\n",
        "          filters=PROJECTION_DIM_2,\n",
        "          kernel_size=(PATCH_SIZE_2, PATCH_SIZE_2),\n",
        "          strides=(PATCH_SIZE_2, PATCH_SIZE_2),\n",
        "          padding=\"VALID\",\n",
        "      )(input)\n",
        "    _, h, w, c = projected_patches.shape\n",
        "    projected_patches = layers.Reshape((h * w, c))(\n",
        "          projected_patches\n",
        "      )  # (B, number_patches, projection_dim)\n",
        "      # Add positional embeddings to the projected patches.\n",
        "    encoded_patches = position_embedding(\n",
        "          projected_patches\n",
        "      )\n",
        "    print(f'layer: {layer.shape}')\n",
        "    print(f'encoded_patches: {encoded_patches.shape}')\n",
        "\n",
        "    encoded_patches_2 = layers.Dropout(0.1)(encoded_patches)\n",
        "    # Iterate over the number of layers and stack up blocks of\n",
        "    # Transformer.\n",
        "    encoded_patches_1 = layer\n",
        "    # Atención cruzada\n",
        "    cross_attention_layer = CrossAttention(num_heads=NUM_HEADS_3, key_dim=PROJECTION_DIM_3)\n",
        "    for i in range(NUM_LAYERS):\n",
        "          # Add a Attention block.\n",
        "        encoded_patches_1 = Attention_Data(encoded_patches_1)\n",
        "        encoded_patches_2 = Attention_Images(encoded_patches_2)\n",
        "        attn_1_to_2 = cross_attention_layer(encoded_patches_1, encoded_patches_2) #Query--Datos, Key--Imagenes\n",
        "        attn_2_to_1 = cross_attention_layer(encoded_patches_2, encoded_patches_1) #Query--Imagenes, Key--Datos\n",
        "    print(f'attn_1_to_2: {attn_1_to_2.shape}')\n",
        "    print(f'attn_2_to_1: {attn_2_to_1.shape}')\n",
        "    # Concatenar las salidas\n",
        "    return tf.concat([attn_1_to_2, attn_2_to_1], axis=1) #2,128--1,256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ad1-ZVaGZ2o"
      },
      "source": [
        "# Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPcBjrya7vFK"
      },
      "outputs": [],
      "source": [
        "def new_arch():\n",
        "  tf.keras.backend.clear_session()\n",
        "#---------------------------------------------------Conv-Datos------------------------------------------------------------------------#\n",
        "  # inputs_1 = Input(shape=(flat_features.shape[1],1), name=\"input_B\")\n",
        "  inputs_1 = Input(shape=(20,1), name=\"input_B\")\n",
        "  # Bloque 1\n",
        "  Layer_1 = tf.keras.layers.Conv1D(8, 3, activation=\"selu\", padding=\"same\")(inputs_1)\n",
        "  # Bloque 2\n",
        "  Layer_1 = tf.keras.layers.Conv1D(16, 3, activation=\"selu\", padding=\"same\")(Layer_1)\n",
        "  Pool_1 = tf.keras.layers.MaxPool1D(2)(Layer_1)\n",
        "  # Bloque 3\n",
        "  Layer_1 = tf.keras.layers.Conv1D(32, 3, activation=\"selu\", padding=\"same\")(Pool_1)\n",
        "  Dropout_1 = tf.keras.layers.Dropout(rate=0.5)(Layer_1)\n",
        "  # Bloque 4\n",
        "  Layer_1 = tf.keras.layers.Conv1D(64, 3, activation=\"selu\", padding=\"same\")(Dropout_1)\n",
        "  Dropout_1 = tf.keras.layers.Dropout(rate=0.5)(Layer_1)\n",
        "  # Bloque 5\n",
        "  Layer_1 = tf.keras.layers.Conv1D(128, 3, activation=\"selu\", padding=\"same\")(Dropout_1)\n",
        "  Dropout_1 = tf.keras.layers.Dropout(rate=0.5)(Layer_1)\n",
        "  #Dropout_1 va a la atencion\n",
        "  print(f'Ultima capa input b{Dropout_1.shape}') #(None, 1, 256)\n",
        "#---------------------------------------------------Conv-Wavelets------------------------------------------------------------------------#\n",
        "  inputs_2 = tf.keras.Input(shape=(224, 224, 128), name=\"input_A\")\n",
        "  # L1\n",
        "  layers = Block_3(inputs_2,64)#A\n",
        "  #residual\n",
        "  # L2\n",
        "  layers = Block_1(layers,64) #B\n",
        "  #residual\n",
        "  # L3\n",
        "  layers = Block_2(layers,64) #C\n",
        "  #residual\n",
        "  # L4 - L6\n",
        "  for i in [ 64, 128, 256]:\n",
        "    layers = Block_3(layers,i) #A\n",
        "  #residual\n",
        "  # L7\n",
        "  layers = Block_4(layers,512)\n",
        "  #Layers va a la atencion\n",
        "  print(f'Ultima capa input a{layers.shape}')#(None, 14, 14, 512)\n",
        "  #---------------------------------------------------Transformer------------------------------------------------------------------------#\n",
        "  ViT=Transformer(layers,Dropout_1)\n",
        "  print(ViT.shape)\n",
        "  representation = tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS_1)(ViT)\n",
        "  representation = tf.keras.layers.GlobalAvgPool1D()(representation)\n",
        "  #---------------------------------------------------------CapsNet------------------------------------------------------------------------------\n",
        "  # squashed_output = tf.keras.layers.Lambda(squash)(representation)\n",
        "  # digit_caps = DigitCapsuleLayer()(squashed_output)\n",
        "  # Acont = safe_norm(digit_caps)\n",
        "  # mast = tf.reshape(Acont, (-1, Acont.shape[2], Acont.shape[3]))\n",
        "  # cnoutputs = tf.keras.layers.Lambda(output_layer)(mast)\n",
        "  # model =tf.keras.Model(inputs = [inputs_1,inputs_2] ,outputs=cnoutputs)\n",
        "  #---------------------------------------------------Fully Connected---------------------------------------------------------------------------\n",
        "  layers = Dense(128,activation=\"gelu\",kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
        "                 bias_regularizer=tf.keras.regularizers.l2(0.0001))(representation)\n",
        "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "  layers = BatchNormalization()(layers)\n",
        "\n",
        "  layers = Dense(64,activation=\"gelu\",kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
        "                 bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "  layers = BatchNormalization()(layers)\n",
        "\n",
        "  layers = Dense(32,activation=\"gelu\",kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),\n",
        "                 bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "  layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "  layers = BatchNormalization()(layers)\n",
        "\n",
        "  #Softmax\n",
        "  predictions = Dense(3, activation=\"softmax\", name=\"output_12\")(layers)\n",
        "  model =tf.keras.Model(inputs = [inputs_1,inputs_2] ,outputs=predictions)\n",
        "  if compile:\n",
        "      model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
        "      #model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "      print (\"Transformer_create\")\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qJsUy2u7vFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b3bf71-fa22-47f5-cc0f-f08e993138c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n"
          ]
        }
      ],
      "source": [
        "model = new_arch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbib5oP_RE2C"
      },
      "outputs": [],
      "source": [
        "path_log_base = '/content/logs'\n",
        "path_img_base = '/content/images'\n",
        "\n",
        "if not os.path.exists(path_log_base):\n",
        "    os.makedirs(path_log_base)\n",
        "if not os.path.exists(path_img_base):\n",
        "    os.makedirs(path_img_base)\n",
        "\n",
        "\n",
        "def train(model, X_train1, X_train, y_train, X_valid1,X_valid, y_valid, X_test1,X_test, y_test, batch_size, epochs, model_name=\"\"):\n",
        "    start_time = tm.time()\n",
        "    # log_dir=path_log_base+\"/\"+model_name+\"_\"+str(datetime.datetime.now().isoformat()[:19].replace(\"T\", \"_\").replace(\":\",\"-\"))\n",
        "    log_dir=path_log_base+\"/\"+model_name\n",
        "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir, histogram_freq=1)\n",
        "    filepath = log_dir+\"/saved-model-{epoch:03d}-{val_accuracy:.4f}.hdf5\"\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "    model.reset_states()\n",
        "\n",
        "    global lossTEST\n",
        "    global accuracyTEST\n",
        "    global lossTRAIN\n",
        "    global accuracyTRAIN\n",
        "    global lossVALID\n",
        "    global accuracyVALID\n",
        "    lossTEST,accuracyTEST   = model.evaluate([X_test1,X_test], y_test,verbose=None)\n",
        "    lossTRAIN,accuracyTRAIN = model.evaluate([X_train1,X_train], y_train,verbose=None)\n",
        "    lossVALID,accuracyVALID = model.evaluate([X_valid1,X_valid], y_valid,verbose=None)\n",
        "\n",
        "    global history\n",
        "    global model_Name\n",
        "    global log_Dir\n",
        "    model_Name = model_name\n",
        "    log_Dir = log_dir\n",
        "    print(\"Starting the training...\")\n",
        "    history=model.fit([X_train1,X_train], y_train, epochs=epochs,\n",
        "                      callbacks=[tensorboard,checkpoint],\n",
        "                      batch_size=batch_size,validation_data=([X_valid1,X_valid], y_valid),verbose=2)\n",
        "\n",
        "    metrics = model.evaluate([X_test1, X_test], y_test, verbose=0)\n",
        "\n",
        "    TIME = tm.time() - start_time\n",
        "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(log_dir)\n",
        "    Final_Results_Test(log_dir, X_test1, X_test, y_test)\n",
        "\n",
        "    return {k:v for k,v in zip (model.metrics_names, metrics)}\n",
        "\n",
        "\n",
        "def Final_Results_Test(PATH_trained_models, X_test1, X_test, y_test):  # Added parameters\n",
        "    global AccTest\n",
        "    global LossTest\n",
        "    AccTest = []\n",
        "    LossTest = []\n",
        "    B_accuracy = 0  # B --> Best\n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            model = tf.keras.models.load_model(PATH_trained_models + '/' + filename)\n",
        "            # Now X_test1 and X_test are available here\n",
        "            loss, accuracy = model.evaluate([X_test1, X_test], y_test, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}' + '\\n')\n",
        "            BandAccTest = accuracy\n",
        "            BandLossTest = loss\n",
        "            AccTest.append(BandAccTest)\n",
        "            LossTest.append(BandLossTest)\n",
        "\n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "\n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "Z5fOUFlVfqYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model(\"/content/drive/MyDrive/BrainLat/Bimodal/Experimentos/saved-model-clean-seed_45-3C-128-1.0000.hdf5\")"
      ],
      "metadata": {
        "id": "LnETGSaefp1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ver la cantidad de parametros del modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opWdfx98QRa5",
        "outputId": "684daa79-2afc-4184-8f8a-606ac79efb49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_A (InputLayer)        [(None, 224, 224, 128)]      0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 64)         73792     ['input_A[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 112, 112, 64)         256       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 112, 112, 64)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 64)         36928     ['re_lu[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 112, 112, 64)         256       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 64)                   0         ['batch_normalization_2[0][0]'\n",
            " GlobalAveragePooling2D)                                            ]                             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 1)                    65        ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   128       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 112, 112, 64)         8256      ['input_A[0][0]']             \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 112, 112, 64)         0         ['dense_1[0][0]',             \n",
            "                                                                     'batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 112, 112, 64)         256       ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 112, 112, 64)         0         ['multiply[0][0]',            \n",
            "                                                                     'batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 64)         36928     ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 112, 112, 64)         256       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 112, 112, 64)         0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 112, 112, 64)         36928     ['re_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 112, 112, 64)         256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 112, 112, 64)         0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 112, 112, 64)         36928     ['re_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 112, 112, 64)         256       ['conv2d_5[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1  (None, 64)                   0         ['batch_normalization_5[0][0]'\n",
            "  (GlobalAveragePooling2D)                                          ]                             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    65        ['global_average_pooling2d_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 64)                   128       ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)       (None, 112, 112, 64)         0         ['dense_3[0][0]',             \n",
            "                                                                     'batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 112, 112, 64)         0         ['multiply_1[0][0]',          \n",
            "                                                                     're_lu_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 56, 56, 64)           36928     ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 56, 56, 64)           256       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 56, 56, 64)           0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 56, 56, 64)           36928     ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 56, 56, 64)           256       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 64)                   0         ['batch_normalization_8[0][0]'\n",
            "  (GlobalAveragePooling2D)                                          ]                             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 1)                    65        ['global_average_pooling2d_2[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 64)                   128       ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 64)           4160      ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)       (None, 56, 56, 64)           0         ['dense_5[0][0]',             \n",
            "                                                                     'batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 56, 56, 64)           256       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 56, 56, 64)           0         ['multiply_2[0][0]',          \n",
            "                                                                     'batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 128)          73856     ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 28, 28, 128)          512       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 28, 28, 128)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 128)          147584    ['re_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 28, 28, 128)          512       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 128)                  0         ['batch_normalization_11[0][0]\n",
            "  (GlobalAveragePooling2D)                                          ']                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 1)                    129       ['global_average_pooling2d_3[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  256       ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 128)          8320      ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)       (None, 28, 28, 128)          0         ['dense_7[0][0]',             \n",
            "                                                                     'batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 28, 28, 128)          512       ['conv2d_9[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 28, 28, 128)          0         ['multiply_3[0][0]',          \n",
            "                                                                     'batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 14, 14, 256)          295168    ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 14, 14, 256)          1024      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 14, 14, 256)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 14, 14, 256)          590080    ['re_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 14, 14, 256)          1024      ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_4  (None, 256)                  0         ['batch_normalization_14[0][0]\n",
            "  (GlobalAveragePooling2D)                                          ']                            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1)                    257       ['global_average_pooling2d_4[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 256)                  512       ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 256)          33024     ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)       (None, 14, 14, 256)          0         ['dense_9[0][0]',             \n",
            "                                                                     'batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 14, 14, 256)          1024      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 14, 14, 256)          0         ['multiply_4[0][0]',          \n",
            "                                                                     'batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 14, 14, 512)          1180160   ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 14, 14, 512)          2048      ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " input_B (InputLayer)        [(None, 21, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " global_average_pooling2d_5  (None, 512)                  0         ['batch_normalization_16[0][0]\n",
            "  (GlobalAveragePooling2D)                                          ']                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 21, 8)                32        ['input_B[0][0]']             \n",
            "                                                                                                  \n",
            " dense_10 (Dense)            (None, 16)                   8208      ['global_average_pooling2d_5[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 21, 16)               400       ['conv1d[0][0]']              \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 512)                  8704      ['dense_10[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 10, 16)               0         ['conv1d_1[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)     (None, 1, 1, 512)            0         ['dense_11[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 10, 32)               1568      ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " multiply_5 (Multiply)       (None, 14, 14, 512)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'tf.reshape[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 10, 32)               0         ['conv1d_2[0][0]']            \n",
            "                                                                                                  \n",
            " add_5 (Add)                 (None, 14, 14, 512)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'multiply_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 10, 64)               6208      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 1, 1, 128)            7929984   ['add_5[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 10, 64)               0         ['conv1d_3[0][0]']            \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1, 128)               0         ['conv2d_17[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 10, 128)              24704     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 1, 128)               0         ['reshape[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 10, 128)              0         ['conv1d_4[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 1, 128)               0         ['tf.__operators__.add[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 10, 128)              256       ['dropout_2[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_3 (Lay  (None, 1, 128)               256       ['dropout_3[0][0]']           \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (Mu  (None, 10, 128)              1054848   ['layer_normalization_1[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (Mu  (None, 1, 128)               1054848   ['layer_normalization_3[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_3[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_7 (Add)                 (None, 10, 128)              0         ['multi_head_attention_1[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " add_9 (Add)                 (None, 1, 128)               0         ['multi_head_attention_2[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 10, 128)              256       ['add_7[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_4 (Lay  (None, 1, 128)               256       ['add_9[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 10, 256)              33024     ['layer_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 1, 256)               33024     ['layer_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 10, 256)              0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, 1, 256)               0         ['dense_14[0][0]']            \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 10, 128)              32896     ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 1, 128)               32896     ['dropout_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 10, 128)              0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)         (None, 1, 128)               0         ['dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " add_8 (Add)                 (None, 10, 128)              0         ['dropout_5[0][0]',           \n",
            "                                                                     'add_7[0][0]']               \n",
            "                                                                                                  \n",
            " add_10 (Add)                (None, 1, 128)               0         ['dropout_7[0][0]',           \n",
            "                                                                     'add_9[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_5 (Lay  (None, 10, 128)              256       ['add_8[0][0]']               \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_7 (Lay  (None, 1, 128)               256       ['add_10[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (Mu  (None, 10, 128)              1054848   ['layer_normalization_5[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_5[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (Mu  (None, 1, 128)               1054848   ['layer_normalization_7[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_7[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_11 (Add)                (None, 10, 128)              0         ['multi_head_attention_3[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_8[0][0]']               \n",
            "                                                                                                  \n",
            " add_13 (Add)                (None, 1, 128)               0         ['multi_head_attention_4[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_10[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_6 (Lay  (None, 10, 128)              256       ['add_11[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_8 (Lay  (None, 1, 128)               256       ['add_13[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 10, 256)              33024     ['layer_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 1, 256)               33024     ['layer_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 10, 256)              0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)        (None, 1, 256)               0         ['dense_18[0][0]']            \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 10, 128)              32896     ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            " dense_19 (Dense)            (None, 1, 128)               32896     ['dropout_10[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)         (None, 10, 128)              0         ['dense_17[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)        (None, 1, 128)               0         ['dense_19[0][0]']            \n",
            "                                                                                                  \n",
            " add_12 (Add)                (None, 10, 128)              0         ['dropout_9[0][0]',           \n",
            "                                                                     'add_11[0][0]']              \n",
            "                                                                                                  \n",
            " add_14 (Add)                (None, 1, 128)               0         ['dropout_11[0][0]',          \n",
            "                                                                     'add_13[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_9 (Lay  (None, 10, 128)              256       ['add_12[0][0]']              \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " layer_normalization_11 (La  (None, 1, 128)               256       ['add_14[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (Mu  (None, 10, 128)              1054848   ['layer_normalization_9[0][0]'\n",
            " ltiHeadAttention)                                                  , 'layer_normalization_9[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (Mu  (None, 1, 128)               1054848   ['layer_normalization_11[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_15 (Add)                (None, 10, 128)              0         ['multi_head_attention_5[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_12[0][0]']              \n",
            "                                                                                                  \n",
            " add_17 (Add)                (None, 1, 128)               0         ['multi_head_attention_6[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_14[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_10 (La  (None, 10, 128)              256       ['add_15[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_12 (La  (None, 1, 128)               256       ['add_17[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_20 (Dense)            (None, 10, 256)              33024     ['layer_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_22 (Dense)            (None, 1, 256)               33024     ['layer_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 10, 256)              0         ['dense_20[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 1, 256)               0         ['dense_22[0][0]']            \n",
            "                                                                                                  \n",
            " dense_21 (Dense)            (None, 10, 128)              32896     ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " dense_23 (Dense)            (None, 1, 128)               32896     ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 10, 128)              0         ['dense_21[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 1, 128)               0         ['dense_23[0][0]']            \n",
            "                                                                                                  \n",
            " add_16 (Add)                (None, 10, 128)              0         ['dropout_13[0][0]',          \n",
            "                                                                     'add_15[0][0]']              \n",
            "                                                                                                  \n",
            " add_18 (Add)                (None, 1, 128)               0         ['dropout_15[0][0]',          \n",
            "                                                                     'add_17[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_13 (La  (None, 10, 128)              256       ['add_16[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_15 (La  (None, 1, 128)               256       ['add_18[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (Mu  (None, 10, 128)              1054848   ['layer_normalization_13[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (Mu  (None, 1, 128)               1054848   ['layer_normalization_15[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_19 (Add)                (None, 10, 128)              0         ['multi_head_attention_7[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_16[0][0]']              \n",
            "                                                                                                  \n",
            " add_21 (Add)                (None, 1, 128)               0         ['multi_head_attention_8[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_18[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_14 (La  (None, 10, 128)              256       ['add_19[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_16 (La  (None, 1, 128)               256       ['add_21[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 10, 256)              33024     ['layer_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_26 (Dense)            (None, 1, 256)               33024     ['layer_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 10, 256)              0         ['dense_24[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)        (None, 1, 256)               0         ['dense_26[0][0]']            \n",
            "                                                                                                  \n",
            " dense_25 (Dense)            (None, 10, 128)              32896     ['dropout_16[0][0]']          \n",
            "                                                                                                  \n",
            " dense_27 (Dense)            (None, 1, 128)               32896     ['dropout_18[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)        (None, 10, 128)              0         ['dense_25[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)        (None, 1, 128)               0         ['dense_27[0][0]']            \n",
            "                                                                                                  \n",
            " add_20 (Add)                (None, 10, 128)              0         ['dropout_17[0][0]',          \n",
            "                                                                     'add_19[0][0]']              \n",
            "                                                                                                  \n",
            " add_22 (Add)                (None, 1, 128)               0         ['dropout_19[0][0]',          \n",
            "                                                                     'add_21[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_17 (La  (None, 10, 128)              256       ['add_20[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_19 (La  (None, 1, 128)               256       ['add_22[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_9 (Mu  (None, 10, 128)              1054848   ['layer_normalization_17[0][0]\n",
            " ltiHeadAttention)                                                  ',                            \n",
            "                                                                     'layer_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_10 (M  (None, 1, 128)               1054848   ['layer_normalization_19[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_23 (Add)                (None, 10, 128)              0         ['multi_head_attention_9[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'add_20[0][0]']              \n",
            "                                                                                                  \n",
            " add_25 (Add)                (None, 1, 128)               0         ['multi_head_attention_10[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_22[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_18 (La  (None, 10, 128)              256       ['add_23[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_20 (La  (None, 1, 128)               256       ['add_25[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_28 (Dense)            (None, 10, 256)              33024     ['layer_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_30 (Dense)            (None, 1, 256)               33024     ['layer_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)        (None, 10, 256)              0         ['dense_28[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_22 (Dropout)        (None, 1, 256)               0         ['dense_30[0][0]']            \n",
            "                                                                                                  \n",
            " dense_29 (Dense)            (None, 10, 128)              32896     ['dropout_20[0][0]']          \n",
            "                                                                                                  \n",
            " dense_31 (Dense)            (None, 1, 128)               32896     ['dropout_22[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)        (None, 10, 128)              0         ['dense_29[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_23 (Dropout)        (None, 1, 128)               0         ['dense_31[0][0]']            \n",
            "                                                                                                  \n",
            " add_24 (Add)                (None, 10, 128)              0         ['dropout_21[0][0]',          \n",
            "                                                                     'add_23[0][0]']              \n",
            "                                                                                                  \n",
            " add_26 (Add)                (None, 1, 128)               0         ['dropout_23[0][0]',          \n",
            "                                                                     'add_25[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_21 (La  (None, 10, 128)              256       ['add_24[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_23 (La  (None, 1, 128)               256       ['add_26[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_11 (M  (None, 10, 128)              1054848   ['layer_normalization_21[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_12 (M  (None, 1, 128)               1054848   ['layer_normalization_23[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_27 (Add)                (None, 10, 128)              0         ['multi_head_attention_11[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_24[0][0]']              \n",
            "                                                                                                  \n",
            " add_29 (Add)                (None, 1, 128)               0         ['multi_head_attention_12[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_26[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_22 (La  (None, 10, 128)              256       ['add_27[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_24 (La  (None, 1, 128)               256       ['add_29[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_32 (Dense)            (None, 10, 256)              33024     ['layer_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_34 (Dense)            (None, 1, 256)               33024     ['layer_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_24 (Dropout)        (None, 10, 256)              0         ['dense_32[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_26 (Dropout)        (None, 1, 256)               0         ['dense_34[0][0]']            \n",
            "                                                                                                  \n",
            " dense_33 (Dense)            (None, 10, 128)              32896     ['dropout_24[0][0]']          \n",
            "                                                                                                  \n",
            " dense_35 (Dense)            (None, 1, 128)               32896     ['dropout_26[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_25 (Dropout)        (None, 10, 128)              0         ['dense_33[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_27 (Dropout)        (None, 1, 128)               0         ['dense_35[0][0]']            \n",
            "                                                                                                  \n",
            " add_28 (Add)                (None, 10, 128)              0         ['dropout_25[0][0]',          \n",
            "                                                                     'add_27[0][0]']              \n",
            "                                                                                                  \n",
            " add_30 (Add)                (None, 1, 128)               0         ['dropout_27[0][0]',          \n",
            "                                                                     'add_29[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_25 (La  (None, 10, 128)              256       ['add_28[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_27 (La  (None, 1, 128)               256       ['add_30[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_13 (M  (None, 10, 128)              1054848   ['layer_normalization_25[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_14 (M  (None, 1, 128)               1054848   ['layer_normalization_27[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_31 (Add)                (None, 10, 128)              0         ['multi_head_attention_13[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_28[0][0]']              \n",
            "                                                                                                  \n",
            " add_33 (Add)                (None, 1, 128)               0         ['multi_head_attention_14[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_30[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_26 (La  (None, 10, 128)              256       ['add_31[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_28 (La  (None, 1, 128)               256       ['add_33[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_36 (Dense)            (None, 10, 256)              33024     ['layer_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_38 (Dense)            (None, 1, 256)               33024     ['layer_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_28 (Dropout)        (None, 10, 256)              0         ['dense_36[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_30 (Dropout)        (None, 1, 256)               0         ['dense_38[0][0]']            \n",
            "                                                                                                  \n",
            " dense_37 (Dense)            (None, 10, 128)              32896     ['dropout_28[0][0]']          \n",
            "                                                                                                  \n",
            " dense_39 (Dense)            (None, 1, 128)               32896     ['dropout_30[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_29 (Dropout)        (None, 10, 128)              0         ['dense_37[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_31 (Dropout)        (None, 1, 128)               0         ['dense_39[0][0]']            \n",
            "                                                                                                  \n",
            " add_32 (Add)                (None, 10, 128)              0         ['dropout_29[0][0]',          \n",
            "                                                                     'add_31[0][0]']              \n",
            "                                                                                                  \n",
            " add_34 (Add)                (None, 1, 128)               0         ['dropout_31[0][0]',          \n",
            "                                                                     'add_33[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_29 (La  (None, 10, 128)              256       ['add_32[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_31 (La  (None, 1, 128)               256       ['add_34[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_15 (M  (None, 10, 128)              1054848   ['layer_normalization_29[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_16 (M  (None, 1, 128)               1054848   ['layer_normalization_31[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_35 (Add)                (None, 10, 128)              0         ['multi_head_attention_15[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_32[0][0]']              \n",
            "                                                                                                  \n",
            " add_37 (Add)                (None, 1, 128)               0         ['multi_head_attention_16[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_34[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_30 (La  (None, 10, 128)              256       ['add_35[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_32 (La  (None, 1, 128)               256       ['add_37[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_40 (Dense)            (None, 10, 256)              33024     ['layer_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_42 (Dense)            (None, 1, 256)               33024     ['layer_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_32 (Dropout)        (None, 10, 256)              0         ['dense_40[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_34 (Dropout)        (None, 1, 256)               0         ['dense_42[0][0]']            \n",
            "                                                                                                  \n",
            " dense_41 (Dense)            (None, 10, 128)              32896     ['dropout_32[0][0]']          \n",
            "                                                                                                  \n",
            " dense_43 (Dense)            (None, 1, 128)               32896     ['dropout_34[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_33 (Dropout)        (None, 10, 128)              0         ['dense_41[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_35 (Dropout)        (None, 1, 128)               0         ['dense_43[0][0]']            \n",
            "                                                                                                  \n",
            " add_36 (Add)                (None, 10, 128)              0         ['dropout_33[0][0]',          \n",
            "                                                                     'add_35[0][0]']              \n",
            "                                                                                                  \n",
            " add_38 (Add)                (None, 1, 128)               0         ['dropout_35[0][0]',          \n",
            "                                                                     'add_37[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_33 (La  (None, 10, 128)              256       ['add_36[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_35 (La  (None, 1, 128)               256       ['add_38[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_17 (M  (None, 10, 128)              1054848   ['layer_normalization_33[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_18 (M  (None, 1, 128)               1054848   ['layer_normalization_35[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_39 (Add)                (None, 10, 128)              0         ['multi_head_attention_17[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_36[0][0]']              \n",
            "                                                                                                  \n",
            " add_41 (Add)                (None, 1, 128)               0         ['multi_head_attention_18[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_38[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_34 (La  (None, 10, 128)              256       ['add_39[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_36 (La  (None, 1, 128)               256       ['add_41[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_44 (Dense)            (None, 10, 256)              33024     ['layer_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_46 (Dense)            (None, 1, 256)               33024     ['layer_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_36 (Dropout)        (None, 10, 256)              0         ['dense_44[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)        (None, 1, 256)               0         ['dense_46[0][0]']            \n",
            "                                                                                                  \n",
            " dense_45 (Dense)            (None, 10, 128)              32896     ['dropout_36[0][0]']          \n",
            "                                                                                                  \n",
            " dense_47 (Dense)            (None, 1, 128)               32896     ['dropout_38[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)        (None, 10, 128)              0         ['dense_45[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_39 (Dropout)        (None, 1, 128)               0         ['dense_47[0][0]']            \n",
            "                                                                                                  \n",
            " add_40 (Add)                (None, 10, 128)              0         ['dropout_37[0][0]',          \n",
            "                                                                     'add_39[0][0]']              \n",
            "                                                                                                  \n",
            " add_42 (Add)                (None, 1, 128)               0         ['dropout_39[0][0]',          \n",
            "                                                                     'add_41[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_37 (La  (None, 10, 128)              256       ['add_40[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_39 (La  (None, 1, 128)               256       ['add_42[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_19 (M  (None, 10, 128)              1054848   ['layer_normalization_37[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_20 (M  (None, 1, 128)               1054848   ['layer_normalization_39[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_43 (Add)                (None, 10, 128)              0         ['multi_head_attention_19[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_40[0][0]']              \n",
            "                                                                                                  \n",
            " add_45 (Add)                (None, 1, 128)               0         ['multi_head_attention_20[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_42[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_38 (La  (None, 10, 128)              256       ['add_43[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_40 (La  (None, 1, 128)               256       ['add_45[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_48 (Dense)            (None, 10, 256)              33024     ['layer_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_50 (Dense)            (None, 1, 256)               33024     ['layer_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_40 (Dropout)        (None, 10, 256)              0         ['dense_48[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_42 (Dropout)        (None, 1, 256)               0         ['dense_50[0][0]']            \n",
            "                                                                                                  \n",
            " dense_49 (Dense)            (None, 10, 128)              32896     ['dropout_40[0][0]']          \n",
            "                                                                                                  \n",
            " dense_51 (Dense)            (None, 1, 128)               32896     ['dropout_42[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_41 (Dropout)        (None, 10, 128)              0         ['dense_49[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_43 (Dropout)        (None, 1, 128)               0         ['dense_51[0][0]']            \n",
            "                                                                                                  \n",
            " add_44 (Add)                (None, 10, 128)              0         ['dropout_41[0][0]',          \n",
            "                                                                     'add_43[0][0]']              \n",
            "                                                                                                  \n",
            " add_46 (Add)                (None, 1, 128)               0         ['dropout_43[0][0]',          \n",
            "                                                                     'add_45[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_41 (La  (None, 10, 128)              256       ['add_44[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_43 (La  (None, 1, 128)               256       ['add_46[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_21 (M  (None, 10, 128)              1054848   ['layer_normalization_41[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_22 (M  (None, 1, 128)               1054848   ['layer_normalization_43[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_47 (Add)                (None, 10, 128)              0         ['multi_head_attention_21[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_44[0][0]']              \n",
            "                                                                                                  \n",
            " add_49 (Add)                (None, 1, 128)               0         ['multi_head_attention_22[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_46[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_42 (La  (None, 10, 128)              256       ['add_47[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_44 (La  (None, 1, 128)               256       ['add_49[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_52 (Dense)            (None, 10, 256)              33024     ['layer_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_54 (Dense)            (None, 1, 256)               33024     ['layer_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_44 (Dropout)        (None, 10, 256)              0         ['dense_52[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_46 (Dropout)        (None, 1, 256)               0         ['dense_54[0][0]']            \n",
            "                                                                                                  \n",
            " dense_53 (Dense)            (None, 10, 128)              32896     ['dropout_44[0][0]']          \n",
            "                                                                                                  \n",
            " dense_55 (Dense)            (None, 1, 128)               32896     ['dropout_46[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_45 (Dropout)        (None, 10, 128)              0         ['dense_53[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_47 (Dropout)        (None, 1, 128)               0         ['dense_55[0][0]']            \n",
            "                                                                                                  \n",
            " add_48 (Add)                (None, 10, 128)              0         ['dropout_45[0][0]',          \n",
            "                                                                     'add_47[0][0]']              \n",
            "                                                                                                  \n",
            " add_50 (Add)                (None, 1, 128)               0         ['dropout_47[0][0]',          \n",
            "                                                                     'add_49[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_45 (La  (None, 10, 128)              256       ['add_48[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_47 (La  (None, 1, 128)               256       ['add_50[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_23 (M  (None, 10, 128)              1054848   ['layer_normalization_45[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_24 (M  (None, 1, 128)               1054848   ['layer_normalization_47[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_51 (Add)                (None, 10, 128)              0         ['multi_head_attention_23[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_48[0][0]']              \n",
            "                                                                                                  \n",
            " add_53 (Add)                (None, 1, 128)               0         ['multi_head_attention_24[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_50[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_46 (La  (None, 10, 128)              256       ['add_51[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_48 (La  (None, 1, 128)               256       ['add_53[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_56 (Dense)            (None, 10, 256)              33024     ['layer_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_58 (Dense)            (None, 1, 256)               33024     ['layer_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_48 (Dropout)        (None, 10, 256)              0         ['dense_56[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_50 (Dropout)        (None, 1, 256)               0         ['dense_58[0][0]']            \n",
            "                                                                                                  \n",
            " dense_57 (Dense)            (None, 10, 128)              32896     ['dropout_48[0][0]']          \n",
            "                                                                                                  \n",
            " dense_59 (Dense)            (None, 1, 128)               32896     ['dropout_50[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_49 (Dropout)        (None, 10, 128)              0         ['dense_57[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_51 (Dropout)        (None, 1, 128)               0         ['dense_59[0][0]']            \n",
            "                                                                                                  \n",
            " add_52 (Add)                (None, 10, 128)              0         ['dropout_49[0][0]',          \n",
            "                                                                     'add_51[0][0]']              \n",
            "                                                                                                  \n",
            " add_54 (Add)                (None, 1, 128)               0         ['dropout_51[0][0]',          \n",
            "                                                                     'add_53[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_49 (La  (None, 10, 128)              256       ['add_52[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_51 (La  (None, 1, 128)               256       ['add_54[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_25 (M  (None, 10, 128)              1054848   ['layer_normalization_49[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_26 (M  (None, 1, 128)               1054848   ['layer_normalization_51[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_55 (Add)                (None, 10, 128)              0         ['multi_head_attention_25[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_52[0][0]']              \n",
            "                                                                                                  \n",
            " add_57 (Add)                (None, 1, 128)               0         ['multi_head_attention_26[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_54[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_50 (La  (None, 10, 128)              256       ['add_55[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_52 (La  (None, 1, 128)               256       ['add_57[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_60 (Dense)            (None, 10, 256)              33024     ['layer_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_62 (Dense)            (None, 1, 256)               33024     ['layer_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_52 (Dropout)        (None, 10, 256)              0         ['dense_60[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_54 (Dropout)        (None, 1, 256)               0         ['dense_62[0][0]']            \n",
            "                                                                                                  \n",
            " dense_61 (Dense)            (None, 10, 128)              32896     ['dropout_52[0][0]']          \n",
            "                                                                                                  \n",
            " dense_63 (Dense)            (None, 1, 128)               32896     ['dropout_54[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_53 (Dropout)        (None, 10, 128)              0         ['dense_61[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_55 (Dropout)        (None, 1, 128)               0         ['dense_63[0][0]']            \n",
            "                                                                                                  \n",
            " add_56 (Add)                (None, 10, 128)              0         ['dropout_53[0][0]',          \n",
            "                                                                     'add_55[0][0]']              \n",
            "                                                                                                  \n",
            " add_58 (Add)                (None, 1, 128)               0         ['dropout_55[0][0]',          \n",
            "                                                                     'add_57[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_53 (La  (None, 10, 128)              256       ['add_56[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_55 (La  (None, 1, 128)               256       ['add_58[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_27 (M  (None, 10, 128)              1054848   ['layer_normalization_53[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_28 (M  (None, 1, 128)               1054848   ['layer_normalization_55[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_59 (Add)                (None, 10, 128)              0         ['multi_head_attention_27[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_56[0][0]']              \n",
            "                                                                                                  \n",
            " add_61 (Add)                (None, 1, 128)               0         ['multi_head_attention_28[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_58[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_54 (La  (None, 10, 128)              256       ['add_59[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_56 (La  (None, 1, 128)               256       ['add_61[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_64 (Dense)            (None, 10, 256)              33024     ['layer_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_66 (Dense)            (None, 1, 256)               33024     ['layer_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_56 (Dropout)        (None, 10, 256)              0         ['dense_64[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_58 (Dropout)        (None, 1, 256)               0         ['dense_66[0][0]']            \n",
            "                                                                                                  \n",
            " dense_65 (Dense)            (None, 10, 128)              32896     ['dropout_56[0][0]']          \n",
            "                                                                                                  \n",
            " dense_67 (Dense)            (None, 1, 128)               32896     ['dropout_58[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_57 (Dropout)        (None, 10, 128)              0         ['dense_65[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_59 (Dropout)        (None, 1, 128)               0         ['dense_67[0][0]']            \n",
            "                                                                                                  \n",
            " add_60 (Add)                (None, 10, 128)              0         ['dropout_57[0][0]',          \n",
            "                                                                     'add_59[0][0]']              \n",
            "                                                                                                  \n",
            " add_62 (Add)                (None, 1, 128)               0         ['dropout_59[0][0]',          \n",
            "                                                                     'add_61[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_57 (La  (None, 10, 128)              256       ['add_60[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_59 (La  (None, 1, 128)               256       ['add_62[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_29 (M  (None, 10, 128)              1054848   ['layer_normalization_57[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_30 (M  (None, 1, 128)               1054848   ['layer_normalization_59[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_63 (Add)                (None, 10, 128)              0         ['multi_head_attention_29[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_60[0][0]']              \n",
            "                                                                                                  \n",
            " add_65 (Add)                (None, 1, 128)               0         ['multi_head_attention_30[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_62[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_58 (La  (None, 10, 128)              256       ['add_63[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_60 (La  (None, 1, 128)               256       ['add_65[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_68 (Dense)            (None, 10, 256)              33024     ['layer_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_70 (Dense)            (None, 1, 256)               33024     ['layer_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_60 (Dropout)        (None, 10, 256)              0         ['dense_68[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_62 (Dropout)        (None, 1, 256)               0         ['dense_70[0][0]']            \n",
            "                                                                                                  \n",
            " dense_69 (Dense)            (None, 10, 128)              32896     ['dropout_60[0][0]']          \n",
            "                                                                                                  \n",
            " dense_71 (Dense)            (None, 1, 128)               32896     ['dropout_62[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_61 (Dropout)        (None, 10, 128)              0         ['dense_69[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_63 (Dropout)        (None, 1, 128)               0         ['dense_71[0][0]']            \n",
            "                                                                                                  \n",
            " add_64 (Add)                (None, 10, 128)              0         ['dropout_61[0][0]',          \n",
            "                                                                     'add_63[0][0]']              \n",
            "                                                                                                  \n",
            " add_66 (Add)                (None, 1, 128)               0         ['dropout_63[0][0]',          \n",
            "                                                                     'add_65[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_61 (La  (None, 10, 128)              256       ['add_64[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_63 (La  (None, 1, 128)               256       ['add_66[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " multi_head_attention_31 (M  (None, 10, 128)              1054848   ['layer_normalization_61[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " multi_head_attention_32 (M  (None, 1, 128)               1054848   ['layer_normalization_63[0][0]\n",
            " ultiHeadAttention)                                                 ',                            \n",
            "                                                                     'layer_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " add_67 (Add)                (None, 10, 128)              0         ['multi_head_attention_31[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_64[0][0]']              \n",
            "                                                                                                  \n",
            " add_69 (Add)                (None, 1, 128)               0         ['multi_head_attention_32[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_66[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_62 (La  (None, 10, 128)              256       ['add_67[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " layer_normalization_64 (La  (None, 1, 128)               256       ['add_69[0][0]']              \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_72 (Dense)            (None, 10, 256)              33024     ['layer_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_74 (Dense)            (None, 1, 256)               33024     ['layer_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dropout_64 (Dropout)        (None, 10, 256)              0         ['dense_72[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_66 (Dropout)        (None, 1, 256)               0         ['dense_74[0][0]']            \n",
            "                                                                                                  \n",
            " dense_73 (Dense)            (None, 10, 128)              32896     ['dropout_64[0][0]']          \n",
            "                                                                                                  \n",
            " dense_75 (Dense)            (None, 1, 128)               32896     ['dropout_66[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_65 (Dropout)        (None, 10, 128)              0         ['dense_73[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_67 (Dropout)        (None, 1, 128)               0         ['dense_75[0][0]']            \n",
            "                                                                                                  \n",
            " add_68 (Add)                (None, 10, 128)              0         ['dropout_65[0][0]',          \n",
            "                                                                     'add_67[0][0]']              \n",
            "                                                                                                  \n",
            " add_70 (Add)                (None, 1, 128)               0         ['dropout_67[0][0]',          \n",
            "                                                                     'add_69[0][0]']              \n",
            "                                                                                                  \n",
            " cross_attention_1 (CrossAt  multiple                     1055104   ['add_68[0][0]',              \n",
            " tention)                                                            'add_70[0][0]',              \n",
            "                                                                     'add_70[0][0]',              \n",
            "                                                                     'add_68[0][0]']              \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)      (None, 11, 128)              0         ['cross_attention_1[0][0]',   \n",
            "                                                                     'cross_attention_1[1][0]']   \n",
            "                                                                                                  \n",
            " layer_normalization_65 (La  (None, 11, 128)              256       ['tf.concat[0][0]']           \n",
            " yerNormalization)                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling1d (  (None, 128)                  0         ['layer_normalization_65[0][0]\n",
            " GlobalAveragePooling1D)                                            ']                            \n",
            "                                                                                                  \n",
            " dense_76 (Dense)            (None, 128)                  16512     ['global_average_pooling1d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 128)                  0         ['dense_76[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 128)                  512       ['re_lu_7[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_77 (Dense)            (None, 64)                   8256      ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 64)                   0         ['dense_77[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 64)                   256       ['re_lu_8[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " dense_78 (Dense)            (None, 32)                   2080      ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 32)                   0         ['dense_78[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 32)                   128       ['re_lu_9[0][0]']             \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " output_12 (Dense)           (None, 3)                    99        ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47590632 (181.54 MB)\n",
            "Trainable params: 47585704 (181.53 MB)\n",
            "Non-trainable params: 4928 (19.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_data['diagnosis_x'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxfVYh9sk68W",
        "outputId": "eeef272a-e37f-4e54-9942-9b7848d0613a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=[\"AD\",\"bvFTD\",\"HC\"]\n",
        "#Calculo del a matriz de confusion\n",
        "y_pred = model.predict([X_test_flat,X_test_img])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convertir las predicciones de categorías one-hot a etiquetas de clase\n",
        "y_true = y_test\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEXC8qH4kiLt",
        "outputId": "ec00413b-2e39-47f8-f70a-33cf3dda82bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 710ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix_percent = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis] * 100\n",
        "sns.set(font_scale=1.2)\n",
        "plt.figure(figsize=(8, 6))\n",
        "# Grafica la matriz de confusión con porcentajes\n",
        "sns.heatmap(conf_matrix_percent, annot=True, fmt='.1f', cmap='Blues', cbar=True,\n",
        "            xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predictions')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Percentages of the confusion matrix')\n",
        "plt.savefig('Matriz_Confusion_Porcentajes.pdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "91SmKKKy8dZH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "488f33a8-f477-4184-ce51-4d0302e3e7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generar el informe de clasificación\n",
        "report = classification_report(y_true, y_pred_classes, target_names=classes)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "WBkkYT4GVaut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10451838-197e-415e-be2f-f8de6c7ee00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          AD       1.00      1.00      1.00         6\n",
            "       bvFTD       1.00      1.00      1.00         3\n",
            "          HC       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00        12\n",
            "   macro avg       1.00      1.00      1.00        12\n",
            "weighted avg       1.00      1.00      1.00        12\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_true, y_pred_classes, output_dict=True, target_names=classes)\n",
        "# Eliminar 'accuracy', 'macro avg' y 'weighted avg' para centrarnos en las clases y micro avg\n",
        "del  report['macro avg'], report['weighted avg']\n",
        "\n",
        "# Convertir el reporte en DataFrame de Pandas\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Crear el mapa de calor para la cuadrícula\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(df_report.iloc[:-1, :-1], annot=True, fmt=\".2f\", cmap='Blues', linewidths=.5, vmin=0, vmax=1)\n",
        "plt.title('Bimodal clasification report')\n",
        "plt.xlabel('Metrics')\n",
        "plt.savefig('heatmap_reportimg.pdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8YOZTvSTVaut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "c35f56ec-dddb-4dc3-f244-554dcb879434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_true, y_pred_classes, digits=4, output_dict=True, zero_division=0, target_names=classes)\n",
        "\n",
        "# Eliminar 'accuracy' y 'macro avg' para centrarnos en las clases y micro avg\n",
        "del report['macro avg'], report['weighted avg']\n",
        "\n",
        "# Extraer datos para la gráfica\n",
        "labels = classes\n",
        "precision = [report[label]['precision'] for label in labels]\n",
        "recall = [report[label]['recall'] for label in labels]\n",
        "f1_score = [report[label]['f1-score'] for label in labels]\n",
        "support = [report[label]['support'] for label in labels]\n",
        "\n",
        "# Tamaño de la gráfica\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Índices para las barras\n",
        "index = np.arange(len(labels))\n",
        "bar_width = 0.25\n",
        "\n",
        "# Crear barras para precision, recall y f1-score\n",
        "rects1 = ax.bar(index, precision, bar_width, label='Precision', color='skyblue')\n",
        "rects2 = ax.bar(index + bar_width, recall, bar_width, label='Recall', color='deepskyblue')\n",
        "rects3 = ax.bar(index + 2 * bar_width, f1_score, bar_width, label='F1-Score', color='midnightblue')\n",
        "\n",
        "\n",
        "# Añadir etiquetas, leyenda, título y ejes\n",
        "ax.set_xlabel('Clases')\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Bimodal classification report')\n",
        "ax.set_xticks(index + bar_width)\n",
        "ax.set_xticklabels(labels)\n",
        "\n",
        "# Colocar la leyenda debajo del gráfico\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=True, ncol=3)\n",
        "\n",
        "# Función para añadir etiquetas de texto a las barras\n",
        "def add_labels(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.3f}',\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "# Añadir etiquetas a cada barra\n",
        "add_labels(rects1)\n",
        "add_labels(rects2)\n",
        "add_labels(rects3)\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.savefig('classification_reportimg.pdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "176aac3d-9ccc-4cad-ce5f-07335d56bf6e",
        "id": "glan0fiuVaut"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validacion cruzada"
      ],
      "metadata": {
        "id": "EToG6mrvs9zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title STFT AvCvF\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Configuración\n",
        "n_splits = 5  # Número de folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Parámetros del entrenamiento\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name_template = \"exp_cmex_3class_model_fold_{}\"\n",
        "\n",
        "# Ruta base para los logs\n",
        "path_log_base = '/content/logs'\n",
        "os.makedirs(path_log_base, exist_ok=True)\n",
        "\n",
        "# Listas para almacenar los resultados de cada fold\n",
        "metrics_summary = []\n",
        "\n",
        "# Realizar Cross-Validation\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(flat_features, labels_stft)):\n",
        "    print(f\"--- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train1_fold, X_test1_fold = flat_features[train_idx], flat_features[test_idx]\n",
        "    X_train_fold, X_test_fold = eeg_data[train_idx], eeg_data[test_idx]\n",
        "    y_train_fold, y_test_fold = labels_stft[train_idx], labels_stft[test_idx]\n",
        "    #standar scaler a los datos planos\n",
        "    scaler = StandardScaler()\n",
        "    X_train1_fold = scaler.fit_transform(X_train1_fold)\n",
        "    X_test1_fold = scaler.transform(X_test1_fold)\n",
        "    print(f'X_train1_fold: {X_train1_fold.shape}')\n",
        "    print(f'X_test1_fold: {X_test1_fold.shape}')\n",
        "    # Crear un nuevo modelo para este fold\n",
        "    model = new_arch()\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    log_dir = f\"{path_log_base}/{model_name_template.format(fold + 1)}\"\n",
        "    train(\n",
        "        model=model,\n",
        "        X_train1=X_train1_fold, X_train=X_train_fold, y_train=y_train_fold,\n",
        "        X_valid1=X_test1_fold, X_valid=X_test_fold, y_valid=y_test_fold,\n",
        "        X_test1=X_test1_fold, X_test=X_test_fold, y_test=y_test_fold,\n",
        "        batch_size=batch_size, epochs=epochs,\n",
        "        model_name=model_name_template.format(fold + 1)\n",
        "    )\n",
        "\n",
        "    # Evaluar el mejor modelo guardado en el fold\n",
        "    print(f\"Evaluating the best model from fold {fold + 1}...\")\n",
        "    model_files = [f for f in os.listdir(log_dir) if f.endswith(\".hdf5\")]\n",
        "    best_model_filename = sorted(\n",
        "        model_files,\n",
        "        key=lambda x: float(x.split('-')[-1].replace('.hdf5', '')),\n",
        "        reverse=True\n",
        "    )[0]  # Seleccionar el modelo con la mejor val_accuracy\n",
        "    best_model = load_model(f\"{log_dir}/{best_model_filename}\")\n",
        "\n",
        "    # Predecir en el conjunto de prueba\n",
        "    y_pred_test = best_model.predict([X_test1_fold, X_test_fold])\n",
        "    y_pred_test = np.argmax(y_pred_test, axis=1)  # Convertir a etiquetas categóricas\n",
        "    y_test_true = y_test_fold  # Etiquetas verdaderas\n",
        "\n",
        "    # Calcular métricas\n",
        "    fold_metrics = {\n",
        "        \"Fold\": fold + 1,\n",
        "        \"Accuracy\": accuracy_score(y_test_true, y_pred_test),\n",
        "        \"Precision\": precision_score(y_test_true, y_pred_test, average='weighted'),\n",
        "        \"Recall\": recall_score(y_test_true, y_pred_test, average='weighted'),\n",
        "        \"F1-Score\": f1_score(y_test_true, y_pred_test, average='weighted')\n",
        "    }\n",
        "\n",
        "    # Mostrar reporte de clasificación\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test_true, y_pred_test, target_names=[\"Class_A\", \"Class_C\",\"Class_F\"]))\n",
        "\n",
        "    # Guardar métricas del fold\n",
        "    metrics_summary.append(fold_metrics)\n",
        "    print(f\"Fold {fold + 1} - Metrics: {fold_metrics}\")\n",
        "\n",
        "# Mostrar resultados finales\n",
        "print(\"\\n--- Cross-Validation Results ---\")\n",
        "metrics_df = pd.DataFrame(metrics_summary)\n",
        "print(metrics_df)\n",
        "\n",
        "# Calcular promedios y desviaciones estándar\n",
        "mean_metrics = metrics_df.mean(axis=0)\n",
        "std_metrics = metrics_df.std(axis=0)\n",
        "\n",
        "print(\"\\nMean Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation Metrics:\")\n",
        "print(std_metrics)\n",
        "\n",
        "# Guardar métricas en un archivo CSV\n",
        "metrics_df.to_csv(f\"{path_log_base}/cross_validation_metrics.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNB9u_i7s9X3",
        "outputId": "d6fd75e4-18db-43c6-884d-ebdfd7f5f1eb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Fold 1/5 ---\n",
            "X_train1_fold: (46, 21)\n",
            "X_test1_fold: (12, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 143s - loss: 1.9307 - accuracy: 0.2609 - val_loss: 1.2335 - val_accuracy: 0.6667 - 143s/epoch - 143s/step\n",
            "Epoch 2/500\n",
            "1/1 - 8s - loss: 1.0668 - accuracy: 0.6957 - val_loss: 1.2360 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 3/500\n",
            "1/1 - 8s - loss: 0.8054 - accuracy: 0.7609 - val_loss: 1.2127 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 4/500\n",
            "1/1 - 10s - loss: 0.6651 - accuracy: 0.8261 - val_loss: 1.2912 - val_accuracy: 0.7500 - 10s/epoch - 10s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.5210 - accuracy: 0.8913 - val_loss: 1.2951 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.5865 - accuracy: 0.8478 - val_loss: 1.2866 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.4288 - accuracy: 0.9565 - val_loss: 1.2761 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.4535 - accuracy: 0.9130 - val_loss: 1.2745 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.4169 - accuracy: 1.0000 - val_loss: 1.2605 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 8s - loss: 0.3901 - accuracy: 0.9348 - val_loss: 1.2714 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.3427 - accuracy: 0.9783 - val_loss: 1.2754 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.2950 - accuracy: 1.0000 - val_loss: 1.2909 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.2991 - accuracy: 1.0000 - val_loss: 1.3127 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3024 - accuracy: 0.9783 - val_loss: 1.2976 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.2756 - accuracy: 1.0000 - val_loss: 1.2578 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.2625 - accuracy: 1.0000 - val_loss: 1.2453 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.2629 - accuracy: 1.0000 - val_loss: 1.2394 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.2768 - accuracy: 1.0000 - val_loss: 1.2483 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.2725 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.2631 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.2636 - accuracy: 1.0000 - val_loss: 1.2499 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.2585 - accuracy: 1.0000 - val_loss: 1.2325 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.2582 - accuracy: 1.0000 - val_loss: 1.2532 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2490 - accuracy: 1.0000 - val_loss: 1.2664 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2563 - accuracy: 1.0000 - val_loss: 1.2590 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2442 - accuracy: 1.0000 - val_loss: 1.2060 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2423 - accuracy: 1.0000 - val_loss: 1.2324 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2445 - accuracy: 1.0000 - val_loss: 1.2953 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2442 - accuracy: 1.0000 - val_loss: 1.3619 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2418 - accuracy: 1.0000 - val_loss: 1.5273 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2336 - accuracy: 1.0000 - val_loss: 1.5885 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2388 - accuracy: 1.0000 - val_loss: 1.9218 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 8s - loss: 0.2366 - accuracy: 1.0000 - val_loss: 2.0756 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 2.1263 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2346 - accuracy: 1.0000 - val_loss: 2.3014 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2360 - accuracy: 1.0000 - val_loss: 2.1517 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 8s - loss: 0.2356 - accuracy: 1.0000 - val_loss: 2.1837 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 2.2744 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 8s - loss: 0.2294 - accuracy: 1.0000 - val_loss: 2.2397 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 2.2488 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2316 - accuracy: 1.0000 - val_loss: 2.2100 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2291 - accuracy: 1.0000 - val_loss: 2.1781 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 8s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 44/500\n",
            "1/1 - 8s - loss: 0.2299 - accuracy: 1.0000 - val_loss: 1.8187 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 45/500\n",
            "1/1 - 8s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 1.7273 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 46/500\n",
            "1/1 - 8s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 1.3424 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 47/500\n",
            "1/1 - 8s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2274 - accuracy: 1.0000 - val_loss: 1.1064 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 8s - loss: 0.2260 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 50/500\n",
            "1/1 - 8s - loss: 0.2260 - accuracy: 1.0000 - val_loss: 1.1879 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 51/500\n",
            "1/1 - 8s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 1.1817 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 52/500\n",
            "1/1 - 8s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 53/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 54/500\n",
            "1/1 - 8s - loss: 0.2253 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 55/500\n",
            "1/1 - 8s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.7383 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 56/500\n",
            "1/1 - 8s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.4750 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 57/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.4667 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 58/500\n",
            "1/1 - 8s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 59/500\n",
            "1/1 - 8s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 1.8196 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 60/500\n",
            "1/1 - 8s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 2.0611 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 61/500\n",
            "1/1 - 8s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 2.0982 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 62/500\n",
            "1/1 - 8s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.6650 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 63/500\n",
            "1/1 - 8s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.7621 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 64/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.6541 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 65/500\n",
            "1/1 - 8s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 1.5764 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 66/500\n",
            "1/1 - 8s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 1.4388 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 67/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.2893 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 10s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.8333 - 10s/epoch - 10s/step\n",
            "Epoch 70/500\n",
            "1/1 - 8s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.7791 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 71/500\n",
            "1/1 - 8s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 72/500\n",
            "1/1 - 10s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.9167 - 10s/epoch - 10s/step\n",
            "Epoch 73/500\n",
            "1/1 - 8s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 74/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.8583 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 75/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.8648 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 76/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.8356 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 0.8325 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 80/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 81/500\n",
            "1/1 - 8s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 82/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.7754 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 83/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.7428 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 86/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 8s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 89/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 8s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 93/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.7803 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 8s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 96/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 99/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.6222 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 100/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 108/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 109/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.7670 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 112/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.7417 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 115/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.7427 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.7659 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.7788 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 125/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.7409 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.8421 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.9013 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.6497 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 144/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.7448 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.7731 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 147/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.8554 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.2155 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.7469 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.2022 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.4130 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.6127 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.7190 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.6562 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.5208 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.4311 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 169/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.1435 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 170/500\n",
            "1/1 - 9s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 2.5896 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 2.5497 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.9187 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.2537 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.7510 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.6807 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.3460 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.0737 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.5713 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.7794 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.2185 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.2088 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.2066 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.1085 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.2371 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1640 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.2381 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.2677 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.1736 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.5250 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.6387 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3045 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.3243 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.8682 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.4987 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.7548 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 216/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.9608 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.0715 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.2928 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 2.2488 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.8650 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.5182 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.3694 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.5503 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.5750 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.7552 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.2037 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 232/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.8088 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.6492 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 235/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.7832 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7831 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7899 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 256/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8220 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 257/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.7651 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 258/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.7872 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.8597 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8099 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.7859 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 0.7735 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 271/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8242 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8353 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 274/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.0464 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8119 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8567 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8547 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8344 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.8307 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.9412 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9094 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9774 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.0894 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.9727 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 304/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 305/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 306/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.8889 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.8905 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 309/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9263 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.0552 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8973 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 315/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8300 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.9275 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.7617 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9185 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9271 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.0311 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.1327 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4793 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.8457 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9770 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.4042 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 335/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.2516 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 336/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.9991 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 337/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.1921 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.0662 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9870 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 340/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.1001 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.1777 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.0785 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.0937 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.7124 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.3961 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.5384 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.4158 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.1696 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 353/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.9997 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.1257 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.2560 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 356/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1363 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.9014 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.8585 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.8724 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.9927 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.0136 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.0082 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 370/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1030 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 371/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.1197 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 372/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1765 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.0875 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1785 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 379/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 382/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.0340 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.7756 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 385/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.8759 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.7796 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.4532 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 388/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.6483 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.6335 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0494 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.9747 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 395/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.0507 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9433 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9121 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.9443 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.9435 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9047 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.8662 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.4120 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.2642 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.8450 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9715 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 0.9862 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.9677 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.3862 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.4765 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.4474 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.3188 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8946 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.1289 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.0754 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.0103 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 442/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.9201 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.9357 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.8687 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 445/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.2327 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.3416 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.3123 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.9479 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 451/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 452/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 453/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 454/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 455/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.8589 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 456/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 457/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.8865 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 458/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.9585 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 461/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.8276 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.8533 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 468/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 471/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0848 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0963 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.0840 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.1011 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.1333 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.0704 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.0845 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.9677 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.0851 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 8s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 486/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 487/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.0780 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 490/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 491/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 492/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.9181 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 493/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 494/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9245 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 495/500\n",
            "1/1 - 8s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 496/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 497/500\n",
            "1/1 - 8s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 498/500\n",
            "1/1 - 8s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.0027 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 499/500\n",
            "1/1 - 8s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 500/500\n",
            "1/1 - 8s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Time exp_cmex_3class_model_fold_1 = 4182.789949417114 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_1\n",
            "saved-model-001-0.5000.hdf5\n",
            "Loss=1.3016 y Accuracy=0.5000\n",
            "\n",
            "saved-model-001-0.6667.hdf5\n",
            "Loss=1.2335 y Accuracy=0.6667\n",
            "\n",
            "saved-model-002-0.5833.hdf5\n",
            "Loss=1.2542 y Accuracy=0.5833\n",
            "\n",
            "saved-model-004-0.7500.hdf5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 509 calls to <function Model.make_test_function.<locals>.test_function at 0x790cd6c41b20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=1.2912 y Accuracy=0.7500\n",
            "\n",
            "saved-model-043-0.6667.hdf5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 510 calls to <function Model.make_test_function.<locals>.test_function at 0x790db9760220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=1.0459 y Accuracy=0.6667\n",
            "\n",
            "saved-model-044-0.7500.hdf5\n",
            "Loss=0.9957 y Accuracy=0.7500\n",
            "\n",
            "saved-model-052-0.8333.hdf5\n",
            "Loss=0.8513 y Accuracy=0.8333\n",
            "\n",
            "saved-model-069-0.8333.hdf5\n",
            "Loss=0.8191 y Accuracy=0.8333\n",
            "\n",
            "saved-model-072-0.9167.hdf5\n",
            "Loss=0.7425 y Accuracy=0.9167\n",
            "\n",
            "saved-model-077-0.9167.hdf5\n",
            "Loss=0.6048 y Accuracy=0.9167\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-072-0.9167.hdf5\n",
            "Loss=0.7425 y Accuracy=0.9167\n",
            "\n",
            "Evaluating the best model from fold 1...\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       0.86      1.00      0.92         6\n",
            "     Class_C       1.00      1.00      1.00         3\n",
            "     Class_F       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.92        12\n",
            "   macro avg       0.95      0.89      0.91        12\n",
            "weighted avg       0.93      0.92      0.91        12\n",
            "\n",
            "Fold 1 - Metrics: {'Fold': 1, 'Accuracy': 0.9166666666666666, 'Precision': 0.9285714285714285, 'Recall': 0.9166666666666666, 'F1-Score': 0.9115384615384615}\n",
            "--- Fold 2/5 ---\n",
            "X_train1_fold: (46, 21)\n",
            "X_test1_fold: (12, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 132s - loss: 1.7767 - accuracy: 0.3913 - val_loss: 1.2333 - val_accuracy: 0.4167 - 132s/epoch - 132s/step\n",
            "Epoch 2/500\n",
            "1/1 - 8s - loss: 0.9508 - accuracy: 0.7391 - val_loss: 1.2080 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 3/500\n",
            "1/1 - 10s - loss: 0.7565 - accuracy: 0.7826 - val_loss: 1.2033 - val_accuracy: 0.5000 - 10s/epoch - 10s/step\n",
            "Epoch 4/500\n",
            "1/1 - 8s - loss: 0.6992 - accuracy: 0.8043 - val_loss: 1.4004 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.5933 - accuracy: 0.9130 - val_loss: 1.4077 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.6277 - accuracy: 0.8043 - val_loss: 1.3879 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.5714 - accuracy: 0.8696 - val_loss: 1.4153 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.5477 - accuracy: 0.8478 - val_loss: 1.4290 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.4480 - accuracy: 0.9565 - val_loss: 1.4447 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 8s - loss: 0.4379 - accuracy: 0.9783 - val_loss: 1.4583 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.4123 - accuracy: 0.9565 - val_loss: 1.4583 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.4133 - accuracy: 0.9783 - val_loss: 1.4561 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.3735 - accuracy: 0.9565 - val_loss: 1.4243 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3641 - accuracy: 0.9783 - val_loss: 1.4244 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.3370 - accuracy: 0.9783 - val_loss: 1.4506 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.3644 - accuracy: 0.9565 - val_loss: 1.4948 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.3297 - accuracy: 1.0000 - val_loss: 1.5231 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.3310 - accuracy: 1.0000 - val_loss: 1.5565 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.2887 - accuracy: 1.0000 - val_loss: 1.5958 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.2986 - accuracy: 1.0000 - val_loss: 1.6604 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.2984 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.2789 - accuracy: 1.0000 - val_loss: 1.7334 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.2832 - accuracy: 1.0000 - val_loss: 1.7796 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2711 - accuracy: 1.0000 - val_loss: 1.7853 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2871 - accuracy: 1.0000 - val_loss: 1.7992 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2647 - accuracy: 1.0000 - val_loss: 1.8241 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2731 - accuracy: 1.0000 - val_loss: 1.7831 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2620 - accuracy: 1.0000 - val_loss: 1.8256 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2651 - accuracy: 1.0000 - val_loss: 1.8550 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2574 - accuracy: 1.0000 - val_loss: 1.9206 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2596 - accuracy: 1.0000 - val_loss: 1.9336 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2531 - accuracy: 1.0000 - val_loss: 1.8531 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 8s - loss: 0.2562 - accuracy: 1.0000 - val_loss: 1.7205 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2524 - accuracy: 1.0000 - val_loss: 1.7984 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2536 - accuracy: 1.0000 - val_loss: 1.6903 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2515 - accuracy: 1.0000 - val_loss: 1.7162 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 8s - loss: 0.2553 - accuracy: 1.0000 - val_loss: 1.7010 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2514 - accuracy: 1.0000 - val_loss: 1.7556 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 8s - loss: 0.2482 - accuracy: 1.0000 - val_loss: 1.8151 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2500 - accuracy: 1.0000 - val_loss: 1.8674 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2485 - accuracy: 1.0000 - val_loss: 1.6273 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2464 - accuracy: 1.0000 - val_loss: 1.1553 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 10s - loss: 0.2446 - accuracy: 1.0000 - val_loss: 1.1947 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 44/500\n",
            "1/1 - 10s - loss: 0.2449 - accuracy: 1.0000 - val_loss: 0.9090 - val_accuracy: 0.7500 - 10s/epoch - 10s/step\n",
            "Epoch 45/500\n",
            "1/1 - 9s - loss: 0.2460 - accuracy: 1.0000 - val_loss: 1.1417 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 46/500\n",
            "1/1 - 9s - loss: 0.2460 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 47/500\n",
            "1/1 - 11s - loss: 0.2423 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.8333 - 11s/epoch - 11s/step\n",
            "Epoch 48/500\n",
            "1/1 - 9s - loss: 0.2447 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 49/500\n",
            "1/1 - 9s - loss: 0.2408 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 50/500\n",
            "1/1 - 9s - loss: 0.2408 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 51/500\n",
            "1/1 - 9s - loss: 0.2413 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 52/500\n",
            "1/1 - 9s - loss: 0.2420 - accuracy: 1.0000 - val_loss: 1.1279 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 53/500\n",
            "1/1 - 9s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 54/500\n",
            "1/1 - 9s - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 55/500\n",
            "1/1 - 9s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 56/500\n",
            "1/1 - 9s - loss: 0.2390 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 57/500\n",
            "1/1 - 9s - loss: 0.2371 - accuracy: 1.0000 - val_loss: 1.0613 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 58/500\n",
            "1/1 - 9s - loss: 0.2375 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 59/500\n",
            "1/1 - 9s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 1.4989 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 60/500\n",
            "1/1 - 9s - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.9486 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 61/500\n",
            "1/1 - 9s - loss: 0.2356 - accuracy: 1.0000 - val_loss: 0.8533 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 62/500\n",
            "1/1 - 9s - loss: 0.2358 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 63/500\n",
            "1/1 - 9s - loss: 0.2365 - accuracy: 1.0000 - val_loss: 1.7689 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 64/500\n",
            "1/1 - 9s - loss: 0.2367 - accuracy: 1.0000 - val_loss: 1.5230 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 65/500\n",
            "1/1 - 9s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 66/500\n",
            "1/1 - 9s - loss: 0.2335 - accuracy: 1.0000 - val_loss: 1.5172 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 67/500\n",
            "1/1 - 9s - loss: 0.2350 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 68/500\n",
            "1/1 - 9s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 69/500\n",
            "1/1 - 9s - loss: 0.2326 - accuracy: 1.0000 - val_loss: 0.8199 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 70/500\n",
            "1/1 - 9s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 71/500\n",
            "1/1 - 9s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 72/500\n",
            "1/1 - 9s - loss: 0.2326 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 73/500\n",
            "1/1 - 9s - loss: 0.2334 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 74/500\n",
            "1/1 - 9s - loss: 0.2322 - accuracy: 1.0000 - val_loss: 0.8511 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 75/500\n",
            "1/1 - 9s - loss: 0.2324 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 76/500\n",
            "1/1 - 9s - loss: 0.2323 - accuracy: 1.0000 - val_loss: 0.8269 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 77/500\n",
            "1/1 - 9s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 78/500\n",
            "1/1 - 9s - loss: 0.2322 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 79/500\n",
            "1/1 - 9s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 0.7591 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 80/500\n",
            "1/1 - 9s - loss: 0.2311 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 81/500\n",
            "1/1 - 9s - loss: 0.2305 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 82/500\n",
            "1/1 - 9s - loss: 0.2318 - accuracy: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 83/500\n",
            "1/1 - 9s - loss: 0.2310 - accuracy: 1.0000 - val_loss: 0.9364 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 84/500\n",
            "1/1 - 9s - loss: 0.2315 - accuracy: 1.0000 - val_loss: 1.0185 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 85/500\n",
            "1/1 - 9s - loss: 0.2310 - accuracy: 1.0000 - val_loss: 0.8428 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 86/500\n",
            "1/1 - 9s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 87/500\n",
            "1/1 - 9s - loss: 0.2305 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 88/500\n",
            "1/1 - 9s - loss: 0.2307 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 89/500\n",
            "1/1 - 9s - loss: 0.2306 - accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 90/500\n",
            "1/1 - 9s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 91/500\n",
            "1/1 - 9s - loss: 0.2291 - accuracy: 1.0000 - val_loss: 0.9938 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 92/500\n",
            "1/1 - 9s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 93/500\n",
            "1/1 - 9s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 94/500\n",
            "1/1 - 9s - loss: 0.2301 - accuracy: 1.0000 - val_loss: 0.8500 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 95/500\n",
            "1/1 - 9s - loss: 0.2296 - accuracy: 1.0000 - val_loss: 1.0725 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 96/500\n",
            "1/1 - 9s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 1.0362 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 97/500\n",
            "1/1 - 9s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 0.8161 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 98/500\n",
            "1/1 - 9s - loss: 0.2295 - accuracy: 1.0000 - val_loss: 1.0586 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 99/500\n",
            "1/1 - 9s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 100/500\n",
            "1/1 - 9s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 101/500\n",
            "1/1 - 9s - loss: 0.2278 - accuracy: 1.0000 - val_loss: 1.1440 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 102/500\n",
            "1/1 - 9s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 103/500\n",
            "1/1 - 9s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 104/500\n",
            "1/1 - 9s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 105/500\n",
            "1/1 - 9s - loss: 0.2276 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 106/500\n",
            "1/1 - 9s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 107/500\n",
            "1/1 - 9s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 108/500\n",
            "1/1 - 9s - loss: 0.2274 - accuracy: 1.0000 - val_loss: 0.7312 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 109/500\n",
            "1/1 - 11s - loss: 0.2279 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.9167 - 11s/epoch - 11s/step\n",
            "Epoch 110/500\n",
            "1/1 - 10s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.6667 - 10s/epoch - 10s/step\n",
            "Epoch 111/500\n",
            "1/1 - 9s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 112/500\n",
            "1/1 - 9s - loss: 0.2277 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 113/500\n",
            "1/1 - 9s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 0.7357 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 114/500\n",
            "1/1 - 9s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 0.6656 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 115/500\n",
            "1/1 - 9s - loss: 0.2271 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 116/500\n",
            "1/1 - 9s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 117/500\n",
            "1/1 - 9s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 1.1401 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 118/500\n",
            "1/1 - 9s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.3838 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 119/500\n",
            "1/1 - 9s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 1.1767 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 120/500\n",
            "1/1 - 9s - loss: 0.2267 - accuracy: 1.0000 - val_loss: 1.2348 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 121/500\n",
            "1/1 - 9s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 122/500\n",
            "1/1 - 9s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 123/500\n",
            "1/1 - 9s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 0.7707 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 124/500\n",
            "1/1 - 9s - loss: 0.2267 - accuracy: 1.0000 - val_loss: 1.0562 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 125/500\n",
            "1/1 - 9s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 126/500\n",
            "1/1 - 9s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.8563 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 127/500\n",
            "1/1 - 9s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 128/500\n",
            "1/1 - 9s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 129/500\n",
            "1/1 - 9s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 130/500\n",
            "1/1 - 9s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 0.8578 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 131/500\n",
            "1/1 - 9s - loss: 0.2257 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 132/500\n",
            "1/1 - 9s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 133/500\n",
            "1/1 - 9s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 134/500\n",
            "1/1 - 9s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 135/500\n",
            "1/1 - 9s - loss: 0.2252 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 136/500\n",
            "1/1 - 9s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 137/500\n",
            "1/1 - 9s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 138/500\n",
            "1/1 - 9s - loss: 0.2240 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 139/500\n",
            "1/1 - 9s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 140/500\n",
            "1/1 - 9s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 141/500\n",
            "1/1 - 9s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 142/500\n",
            "1/1 - 9s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.2342 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 143/500\n",
            "1/1 - 9s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.4483 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 144/500\n",
            "1/1 - 9s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.3223 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 145/500\n",
            "1/1 - 9s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 146/500\n",
            "1/1 - 9s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 147/500\n",
            "1/1 - 9s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 0.5953 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 148/500\n",
            "1/1 - 9s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 149/500\n",
            "1/1 - 9s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 150/500\n",
            "1/1 - 9s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 0.6197 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 151/500\n",
            "1/1 - 9s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 152/500\n",
            "1/1 - 9s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 153/500\n",
            "1/1 - 9s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 154/500\n",
            "1/1 - 9s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 155/500\n",
            "1/1 - 9s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 156/500\n",
            "1/1 - 9s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 157/500\n",
            "1/1 - 10s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.9167 - 10s/epoch - 10s/step\n",
            "Epoch 158/500\n",
            "1/1 - 9s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 159/500\n",
            "1/1 - 9s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 160/500\n",
            "1/1 - 9s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.1325 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 161/500\n",
            "1/1 - 9s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.0901 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 162/500\n",
            "1/1 - 9s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 163/500\n",
            "1/1 - 9s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 164/500\n",
            "1/1 - 9s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.2040 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 165/500\n",
            "1/1 - 9s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 1.3260 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 166/500\n",
            "1/1 - 9s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3618 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 167/500\n",
            "1/1 - 9s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 1.4576 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 168/500\n",
            "1/1 - 9s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.5737 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 169/500\n",
            "1/1 - 9s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.6803 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 170/500\n",
            "1/1 - 9s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.5408 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 171/500\n",
            "1/1 - 9s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.4879 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 172/500\n",
            "1/1 - 9s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.4994 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 173/500\n",
            "1/1 - 9s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.5597 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 174/500\n",
            "1/1 - 9s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.0300 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 175/500\n",
            "1/1 - 9s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.0553 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 176/500\n",
            "1/1 - 9s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 177/500\n",
            "1/1 - 9s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.9362 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 178/500\n",
            "1/1 - 9s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 179/500\n",
            "1/1 - 9s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.8999 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 180/500\n",
            "1/1 - 9s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 181/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8274 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 182/500\n",
            "1/1 - 9s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 183/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8293 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 184/500\n",
            "1/1 - 9s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 185/500\n",
            "1/1 - 9s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 186/500\n",
            "1/1 - 9s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 187/500\n",
            "1/1 - 9s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 188/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 189/500\n",
            "1/1 - 10s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.9167 - 10s/epoch - 10s/step\n",
            "Epoch 190/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 191/500\n",
            "1/1 - 9s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 192/500\n",
            "1/1 - 9s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 193/500\n",
            "1/1 - 9s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 194/500\n",
            "1/1 - 9s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 195/500\n",
            "1/1 - 9s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 196/500\n",
            "1/1 - 9s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 197/500\n",
            "1/1 - 9s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 198/500\n",
            "1/1 - 9s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.0089 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 199/500\n",
            "1/1 - 9s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.8823 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 200/500\n",
            "1/1 - 9s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0707 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 201/500\n",
            "1/1 - 9s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.0394 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 202/500\n",
            "1/1 - 9s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 203/500\n",
            "1/1 - 9s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.1676 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 204/500\n",
            "1/1 - 9s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 2.0855 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 205/500\n",
            "1/1 - 9s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 2.6764 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 206/500\n",
            "1/1 - 9s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 207/500\n",
            "1/1 - 9s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.2620 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 208/500\n",
            "1/1 - 9s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.9540 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 209/500\n",
            "1/1 - 9s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 210/500\n",
            "1/1 - 9s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 211/500\n",
            "1/1 - 9s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 212/500\n",
            "1/1 - 9s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.4200 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 213/500\n",
            "1/1 - 9s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.7472 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 214/500\n",
            "1/1 - 9s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.4467 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 215/500\n",
            "1/1 - 9s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.3129 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 216/500\n",
            "1/1 - 9s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 217/500\n",
            "1/1 - 9s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 218/500\n",
            "1/1 - 9s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 219/500\n",
            "1/1 - 9s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.9545 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 220/500\n",
            "1/1 - 9s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.1719 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 221/500\n",
            "1/1 - 9s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 222/500\n",
            "1/1 - 9s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 223/500\n",
            "1/1 - 9s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 224/500\n",
            "1/1 - 9s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 225/500\n",
            "1/1 - 9s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 226/500\n",
            "1/1 - 9s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.2031 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 227/500\n",
            "1/1 - 9s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.9823 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 228/500\n",
            "1/1 - 9s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 2.3631 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 229/500\n",
            "1/1 - 9s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.7283 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 230/500\n",
            "1/1 - 9s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 231/500\n",
            "1/1 - 9s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.2196 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 232/500\n",
            "1/1 - 9s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 233/500\n",
            "1/1 - 9s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.1336 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 234/500\n",
            "1/1 - 9s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 235/500\n",
            "1/1 - 9s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 236/500\n",
            "1/1 - 9s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 237/500\n",
            "1/1 - 9s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 238/500\n",
            "1/1 - 9s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 239/500\n",
            "1/1 - 9s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 0.5775 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 240/500\n",
            "1/1 - 9s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.5774 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 241/500\n",
            "1/1 - 9s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 242/500\n",
            "1/1 - 9s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 243/500\n",
            "1/1 - 9s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 244/500\n",
            "1/1 - 9s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 245/500\n",
            "1/1 - 9s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 246/500\n",
            "1/1 - 9s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 247/500\n",
            "1/1 - 9s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.2725 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 248/500\n",
            "1/1 - 9s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.5891 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 249/500\n",
            "1/1 - 9s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 250/500\n",
            "1/1 - 9s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 251/500\n",
            "1/1 - 9s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 252/500\n",
            "1/1 - 9s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 253/500\n",
            "1/1 - 9s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 254/500\n",
            "1/1 - 9s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.5656 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 255/500\n",
            "1/1 - 9s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 256/500\n",
            "1/1 - 9s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 257/500\n",
            "1/1 - 9s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 258/500\n",
            "1/1 - 9s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.5868 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 259/500\n",
            "1/1 - 9s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.3530 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 260/500\n",
            "1/1 - 9s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.8508 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 261/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.2566 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 262/500\n",
            "1/1 - 9s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.5696 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 263/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 264/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.4697 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 265/500\n",
            "1/1 - 9s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.4841 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 266/500\n",
            "1/1 - 9s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.4412 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 267/500\n",
            "1/1 - 9s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.1588 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 268/500\n",
            "1/1 - 9s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 269/500\n",
            "1/1 - 9s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 270/500\n",
            "1/1 - 9s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 271/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.0299 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 272/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.4415 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 273/500\n",
            "1/1 - 9s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.1133 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 274/500\n",
            "1/1 - 9s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 275/500\n",
            "1/1 - 9s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 276/500\n",
            "1/1 - 9s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 277/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 278/500\n",
            "1/1 - 9s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 279/500\n",
            "1/1 - 9s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.2883 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 280/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.6432 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 281/500\n",
            "1/1 - 9s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 282/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 283/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 284/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 285/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 286/500\n",
            "1/1 - 9s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 287/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 288/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 289/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 290/500\n",
            "1/1 - 9s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.5671 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 291/500\n",
            "1/1 - 9s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 292/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.7144 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 293/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.2849 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 294/500\n",
            "1/1 - 9s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.5063 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 295/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.6088 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 296/500\n",
            "1/1 - 9s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.2861 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 297/500\n",
            "1/1 - 9s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.6853 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 298/500\n",
            "1/1 - 9s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.7583 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 299/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 2.6649 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 300/500\n",
            "1/1 - 9s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.5562 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 301/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.4580 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 302/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 303/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 304/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.3065 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 305/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.5068 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 306/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.5083 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 307/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.3008 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 308/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.1674 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 309/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.8910 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 310/500\n",
            "1/1 - 9s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.3084 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 311/500\n",
            "1/1 - 9s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.9535 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 312/500\n",
            "1/1 - 9s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 2.2461 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 313/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 314/500\n",
            "1/1 - 9s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 315/500\n",
            "1/1 - 9s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.2513 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 316/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 317/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.5978 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 318/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.5146 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 319/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.8663 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 320/500\n",
            "1/1 - 9s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.3121 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 321/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.7304 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 322/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 323/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.0372 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 324/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.5887 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 325/500\n",
            "1/1 - 9s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.8378 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 326/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.6785 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 327/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.0545 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 328/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.3045 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 329/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3314 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 330/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 331/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 332/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.1612 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 333/500\n",
            "1/1 - 9s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 334/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.3985 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 335/500\n",
            "1/1 - 9s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 336/500\n",
            "1/1 - 9s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.8308 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 337/500\n",
            "1/1 - 9s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 338/500\n",
            "1/1 - 9s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 339/500\n",
            "1/1 - 9s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 340/500\n",
            "1/1 - 9s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.8682 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 341/500\n",
            "1/1 - 9s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.6539 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 342/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.1771 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 343/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.9999 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 344/500\n",
            "1/1 - 9s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.6717 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 345/500\n",
            "1/1 - 9s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.3870 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 346/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.9383 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 347/500\n",
            "1/1 - 10s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 348/500\n",
            "1/1 - 9s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.2236 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 349/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.9061 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 350/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.4409 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 351/500\n",
            "1/1 - 9s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.6330 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 352/500\n",
            "1/1 - 9s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.6529 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 353/500\n",
            "1/1 - 9s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.1197 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 354/500\n",
            "1/1 - 9s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.8132 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 355/500\n",
            "1/1 - 9s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.2755 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 356/500\n",
            "1/1 - 9s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.2342 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 357/500\n",
            "1/1 - 9s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.1626 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 358/500\n",
            "1/1 - 9s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 359/500\n",
            "1/1 - 9s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 360/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.2404 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 361/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 362/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.5916 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 363/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.4250 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 364/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.1890 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 365/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 366/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.2460 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 367/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.1504 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 368/500\n",
            "1/1 - 9s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 369/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 370/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 371/500\n",
            "1/1 - 9s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 372/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.6054 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 373/500\n",
            "1/1 - 9s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 374/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 375/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 376/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 377/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.0119 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 378/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 379/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 380/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.6741 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 381/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.8924 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 382/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.4699 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 383/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 384/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 385/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.2220 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 386/500\n",
            "1/1 - 9s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.1094 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 387/500\n",
            "1/1 - 9s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.3435 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 388/500\n",
            "1/1 - 9s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.4345 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 389/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.6758 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 390/500\n",
            "1/1 - 9s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 391/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.5374 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 392/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 393/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.5672 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 394/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 395/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 396/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 397/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.5614 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 398/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.0189 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 399/500\n",
            "1/1 - 9s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.4825 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 400/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.2087 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 401/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 402/500\n",
            "1/1 - 9s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.1132 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 403/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 404/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 405/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 406/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 407/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.8270 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 408/500\n",
            "1/1 - 9s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9154 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 409/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 410/500\n",
            "1/1 - 9s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.1313 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 411/500\n",
            "1/1 - 9s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.1685 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 412/500\n",
            "1/1 - 9s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9471 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 413/500\n",
            "1/1 - 9s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 414/500\n",
            "1/1 - 9s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.2510 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 415/500\n",
            "1/1 - 9s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 416/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 417/500\n",
            "1/1 - 9s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.7501 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 418/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 419/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 420/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 421/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 422/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 423/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 424/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 425/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 426/500\n",
            "1/1 - 9s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 427/500\n",
            "1/1 - 9s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 428/500\n",
            "1/1 - 9s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 429/500\n",
            "1/1 - 9s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 430/500\n",
            "1/1 - 9s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 431/500\n",
            "1/1 - 9s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 432/500\n",
            "1/1 - 9s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 433/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.5868 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 434/500\n",
            "1/1 - 9s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 435/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 436/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 437/500\n",
            "1/1 - 9s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.5741 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 438/500\n",
            "1/1 - 9s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 439/500\n",
            "1/1 - 9s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.5920 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 440/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 441/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 442/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 443/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 444/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 445/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.0074 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 446/500\n",
            "1/1 - 9s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.4478 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 447/500\n",
            "1/1 - 9s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.8455 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 448/500\n",
            "1/1 - 9s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.4287 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 449/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.0472 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 450/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.5112 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 451/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.9663 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 452/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 2.4341 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 453/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.5254 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 454/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 2.7397 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 455/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.2215 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 456/500\n",
            "1/1 - 9s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.3358 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 457/500\n",
            "1/1 - 9s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.0366 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 458/500\n",
            "1/1 - 9s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.1089 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 459/500\n",
            "1/1 - 9s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.9167 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 460/500\n",
            "1/1 - 9s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.4328 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 461/500\n",
            "1/1 - 9s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 462/500\n",
            "1/1 - 9s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 463/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 464/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 465/500\n",
            "1/1 - 9s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 466/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 467/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 468/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 469/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 470/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 471/500\n",
            "1/1 - 10s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8333 - 10s/epoch - 10s/step\n",
            "Epoch 472/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 473/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.0646 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 474/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.9482 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 475/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.0811 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 476/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.8848 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 477/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.2595 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 478/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.5001 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 479/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.8346 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 480/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.1002 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 481/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.9233 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 482/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.3671 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 483/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.6583 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 484/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 485/500\n",
            "1/1 - 9s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 486/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9184 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 487/500\n",
            "1/1 - 9s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.5297 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 488/500\n",
            "1/1 - 9s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 489/500\n",
            "1/1 - 9s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 490/500\n",
            "1/1 - 9s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 491/500\n",
            "1/1 - 9s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 492/500\n",
            "1/1 - 9s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 493/500\n",
            "1/1 - 9s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 494/500\n",
            "1/1 - 9s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 495/500\n",
            "1/1 - 9s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.5436 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 496/500\n",
            "1/1 - 9s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.2612 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 497/500\n",
            "1/1 - 10s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.6182 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 498/500\n",
            "1/1 - 9s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.1588 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 499/500\n",
            "1/1 - 10s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.2124 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 500/500\n",
            "1/1 - 10s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.7129 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Time exp_cmex_3class_model_fold_2 = 4709.716437578201 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_2\n",
            "saved-model-001-0.4167.hdf5\n",
            "Loss=1.2333 y Accuracy=0.4167\n",
            "\n",
            "saved-model-001-0.5833.hdf5\n",
            "Loss=1.2252 y Accuracy=0.5833\n",
            "\n",
            "saved-model-002-0.6667.hdf5\n",
            "Loss=1.1465 y Accuracy=0.6667\n",
            "\n",
            "saved-model-003-0.5000.hdf5\n",
            "Loss=1.2033 y Accuracy=0.5000\n",
            "\n",
            "saved-model-043-0.5833.hdf5\n",
            "Loss=1.1947 y Accuracy=0.5833\n",
            "\n",
            "saved-model-044-0.7500.hdf5\n",
            "Loss=0.9090 y Accuracy=0.7500\n",
            "\n",
            "saved-model-047-0.8333.hdf5\n",
            "Loss=0.8237 y Accuracy=0.8333\n",
            "\n",
            "saved-model-086-0.7500.hdf5\n",
            "Loss=0.8598 y Accuracy=0.7500\n",
            "\n",
            "saved-model-105-0.8333.hdf5\n",
            "Loss=0.7661 y Accuracy=0.8333\n",
            "\n",
            "saved-model-109-0.9167.hdf5\n",
            "Loss=0.6002 y Accuracy=0.9167\n",
            "\n",
            "saved-model-111-0.9167.hdf5\n",
            "Loss=0.5948 y Accuracy=0.9167\n",
            "\n",
            "saved-model-277-1.0000.hdf5\n",
            "Loss=0.3260 y Accuracy=1.0000\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-277-1.0000.hdf5\n",
            "Loss=0.3260 y Accuracy=1.0000\n",
            "\n",
            "Evaluating the best model from fold 2...\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       1.00      1.00      1.00         6\n",
            "     Class_C       1.00      1.00      1.00         4\n",
            "     Class_F       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        12\n",
            "   macro avg       1.00      1.00      1.00        12\n",
            "weighted avg       1.00      1.00      1.00        12\n",
            "\n",
            "Fold 2 - Metrics: {'Fold': 2, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1-Score': 1.0}\n",
            "--- Fold 3/5 ---\n",
            "X_train1_fold: (46, 21)\n",
            "X_test1_fold: (12, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 142s - loss: 2.1822 - accuracy: 0.2174 - val_loss: 1.2683 - val_accuracy: 0.2500 - 142s/epoch - 142s/step\n",
            "Epoch 2/500\n",
            "1/1 - 8s - loss: 1.3541 - accuracy: 0.5435 - val_loss: 1.2524 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 3/500\n",
            "1/1 - 8s - loss: 0.8857 - accuracy: 0.7174 - val_loss: 1.3700 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 4/500\n",
            "1/1 - 9s - loss: 0.9129 - accuracy: 0.7174 - val_loss: 1.8712 - val_accuracy: 0.1667 - 9s/epoch - 9s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.8317 - accuracy: 0.7826 - val_loss: 1.8698 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.6675 - accuracy: 0.8261 - val_loss: 1.8427 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.5719 - accuracy: 0.8913 - val_loss: 1.8225 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.5115 - accuracy: 0.9348 - val_loss: 1.7240 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.5572 - accuracy: 0.9130 - val_loss: 1.6551 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 8s - loss: 0.4821 - accuracy: 0.9348 - val_loss: 1.6698 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.4771 - accuracy: 0.9348 - val_loss: 1.7017 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.4707 - accuracy: 0.9565 - val_loss: 1.6101 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.4222 - accuracy: 0.9565 - val_loss: 1.6650 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3712 - accuracy: 0.9783 - val_loss: 1.6802 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.3913 - accuracy: 0.9783 - val_loss: 1.6798 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.3577 - accuracy: 0.9783 - val_loss: 1.6734 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.3705 - accuracy: 0.9783 - val_loss: 1.6796 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.3608 - accuracy: 0.9783 - val_loss: 1.6836 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.3369 - accuracy: 0.9783 - val_loss: 1.7362 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.3147 - accuracy: 0.9783 - val_loss: 1.8032 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.3199 - accuracy: 1.0000 - val_loss: 1.8683 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.3000 - accuracy: 0.9783 - val_loss: 1.9774 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.3032 - accuracy: 1.0000 - val_loss: 2.0379 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2957 - accuracy: 1.0000 - val_loss: 2.1473 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2821 - accuracy: 1.0000 - val_loss: 2.2582 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2937 - accuracy: 0.9783 - val_loss: 2.3421 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2740 - accuracy: 1.0000 - val_loss: 2.3187 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2653 - accuracy: 1.0000 - val_loss: 2.3303 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2770 - accuracy: 1.0000 - val_loss: 2.3678 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2533 - accuracy: 1.0000 - val_loss: 2.3933 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2711 - accuracy: 0.9783 - val_loss: 2.4167 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2628 - accuracy: 1.0000 - val_loss: 2.4322 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 8s - loss: 0.2610 - accuracy: 1.0000 - val_loss: 2.4112 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2446 - accuracy: 1.0000 - val_loss: 2.3901 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2464 - accuracy: 1.0000 - val_loss: 2.4621 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2473 - accuracy: 1.0000 - val_loss: 2.5473 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 8s - loss: 0.2424 - accuracy: 1.0000 - val_loss: 2.6077 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2429 - accuracy: 1.0000 - val_loss: 2.6323 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 8s - loss: 0.2428 - accuracy: 1.0000 - val_loss: 2.6422 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2405 - accuracy: 1.0000 - val_loss: 2.5447 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2424 - accuracy: 1.0000 - val_loss: 2.4830 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2359 - accuracy: 1.0000 - val_loss: 2.1126 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 8s - loss: 0.2397 - accuracy: 1.0000 - val_loss: 2.1507 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 44/500\n",
            "1/1 - 8s - loss: 0.2391 - accuracy: 1.0000 - val_loss: 2.1468 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 45/500\n",
            "1/1 - 8s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 2.4596 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 46/500\n",
            "1/1 - 8s - loss: 0.2376 - accuracy: 1.0000 - val_loss: 2.7476 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 47/500\n",
            "1/1 - 8s - loss: 0.2338 - accuracy: 1.0000 - val_loss: 2.7862 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2423 - accuracy: 1.0000 - val_loss: 2.8707 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 8s - loss: 0.2332 - accuracy: 1.0000 - val_loss: 2.8237 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 50/500\n",
            "1/1 - 8s - loss: 0.2345 - accuracy: 1.0000 - val_loss: 2.7072 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 51/500\n",
            "1/1 - 8s - loss: 0.2334 - accuracy: 1.0000 - val_loss: 2.8376 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 52/500\n",
            "1/1 - 8s - loss: 0.2334 - accuracy: 1.0000 - val_loss: 2.7641 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 53/500\n",
            "1/1 - 8s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 2.6265 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 54/500\n",
            "1/1 - 8s - loss: 0.2297 - accuracy: 1.0000 - val_loss: 2.5327 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 55/500\n",
            "1/1 - 8s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 2.3882 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 56/500\n",
            "1/1 - 8s - loss: 0.2336 - accuracy: 1.0000 - val_loss: 2.5197 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 57/500\n",
            "1/1 - 8s - loss: 0.2324 - accuracy: 1.0000 - val_loss: 2.7232 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 58/500\n",
            "1/1 - 8s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 2.5748 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 59/500\n",
            "1/1 - 8s - loss: 0.2308 - accuracy: 1.0000 - val_loss: 2.4002 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 60/500\n",
            "1/1 - 8s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 2.0250 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 61/500\n",
            "1/1 - 8s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 1.5699 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 62/500\n",
            "1/1 - 8s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 2.0684 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 63/500\n",
            "1/1 - 8s - loss: 0.2279 - accuracy: 1.0000 - val_loss: 1.5009 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 64/500\n",
            "1/1 - 10s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.2867 - val_accuracy: 0.5000 - 10s/epoch - 10s/step\n",
            "Epoch 65/500\n",
            "1/1 - 8s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 1.6389 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 66/500\n",
            "1/1 - 8s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.5951 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 67/500\n",
            "1/1 - 8s - loss: 0.2274 - accuracy: 1.0000 - val_loss: 1.7359 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 1.7160 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 10s - loss: 0.2269 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.8333 - 10s/epoch - 10s/step\n",
            "Epoch 70/500\n",
            "1/1 - 8s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 1.0103 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 71/500\n",
            "1/1 - 8s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 72/500\n",
            "1/1 - 8s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 73/500\n",
            "1/1 - 8s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 74/500\n",
            "1/1 - 8s - loss: 0.2260 - accuracy: 1.0000 - val_loss: 1.7327 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 75/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 2.2026 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 76/500\n",
            "1/1 - 8s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 2.0546 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 1.2808 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.2830 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 80/500\n",
            "1/1 - 8s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 81/500\n",
            "1/1 - 8s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 82/500\n",
            "1/1 - 8s - loss: 0.2258 - accuracy: 1.0000 - val_loss: 1.7716 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 83/500\n",
            "1/1 - 8s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 8s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 86/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.4372 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.9979 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 10s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.9167 - 10s/epoch - 10s/step\n",
            "Epoch 89/500\n",
            "1/1 - 8s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 8s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.3621 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 93/500\n",
            "1/1 - 8s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 1.5502 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 8s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 96/500\n",
            "1/1 - 8s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 8s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 99/500\n",
            "1/1 - 8s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 100/500\n",
            "1/1 - 10s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 1.0000 - 10s/epoch - 10s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 0.8865 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 1.4173 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.9142 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 108/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 109/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 8s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 112/500\n",
            "1/1 - 8s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 115/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.6001 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 125/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.0220 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 1.2965 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.0705 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.0588 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.0747 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.3578 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 144/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9464 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 8s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 147/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.4204 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.3485 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.1500 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.1596 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.9515 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.2344 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.8473 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.8909 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 8s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9241 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.4028 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 169/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.3025 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 170/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.3063 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.2002 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.5874 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.7675 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.6473 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.3932 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.5863 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.8809 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.1565 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.9278 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.8352 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.8916 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 216/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.4176 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.3385 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.1769 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.0579 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 232/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 235/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.3891 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.5675 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.1768 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.5023 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.0467 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.3292 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.7957 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.2179 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.0234 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 256/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 257/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 258/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.2600 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.3218 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.1966 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1895 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 271/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.1698 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 274/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.7552 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.4169 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.2870 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.4312 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.9673 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 304/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.9837 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 305/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.8549 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 306/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.9078 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 2.2524 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.6365 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 309/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.9856 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.0147 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.7394 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.9301 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.0288 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.4969 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 315/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.8740 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.1707 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8726 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.8578 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.0689 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.6169 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.1995 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.9147 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.2254 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.3917 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.3793 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 335/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.3985 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 336/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.2390 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 337/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8287 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 340/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7374 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.1744 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 353/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 356/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.5930 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.6197 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.5503 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 370/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 371/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 372/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 379/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 382/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.7795 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.0395 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.5278 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 385/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.5068 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 388/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.6500 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.5816 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 395/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.1847 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.7783 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.9368 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.2368 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.9650 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.7755 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.3803 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.2333 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.1119 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 442/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 445/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 451/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 452/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 453/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 454/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 455/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 456/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 457/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 458/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 461/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 468/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 471/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 486/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 487/500\n",
            "1/1 - 9s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 490/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 491/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 492/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 493/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 494/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 495/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 496/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 497/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 498/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 499/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 500/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Time exp_cmex_3class_model_fold_3 = 4208.87186217308 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_3\n",
            "saved-model-001-0.2500.hdf5\n",
            "Loss=1.2683 y Accuracy=0.2500\n",
            "\n",
            "saved-model-001-0.5833.hdf5\n",
            "Loss=1.2250 y Accuracy=0.5833\n",
            "\n",
            "saved-model-002-0.7500.hdf5\n",
            "Loss=1.1575 y Accuracy=0.7500\n",
            "\n",
            "saved-model-032-0.8333.hdf5\n",
            "Loss=1.0994 y Accuracy=0.8333\n",
            "\n",
            "saved-model-054-0.9167.hdf5\n",
            "Loss=0.8174 y Accuracy=0.9167\n",
            "\n",
            "saved-model-064-0.5000.hdf5\n",
            "Loss=1.2867 y Accuracy=0.5000\n",
            "\n",
            "saved-model-069-0.8333.hdf5\n",
            "Loss=0.8574 y Accuracy=0.8333\n",
            "\n",
            "saved-model-088-0.9167.hdf5\n",
            "Loss=0.6047 y Accuracy=0.9167\n",
            "\n",
            "saved-model-088-1.0000.hdf5\n",
            "Loss=0.5568 y Accuracy=1.0000\n",
            "\n",
            "saved-model-100-1.0000.hdf5\n",
            "Loss=0.4951 y Accuracy=1.0000\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-088-1.0000.hdf5\n",
            "Loss=0.5568 y Accuracy=1.0000\n",
            "\n",
            "Evaluating the best model from fold 3...\n",
            "1/1 [==============================] - 10s 10s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       1.00      1.00      1.00         6\n",
            "     Class_C       1.00      1.00      1.00         4\n",
            "     Class_F       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        12\n",
            "   macro avg       1.00      1.00      1.00        12\n",
            "weighted avg       1.00      1.00      1.00        12\n",
            "\n",
            "Fold 3 - Metrics: {'Fold': 3, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1-Score': 1.0}\n",
            "--- Fold 4/5 ---\n",
            "X_train1_fold: (47, 21)\n",
            "X_test1_fold: (11, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 148s - loss: 2.0422 - accuracy: 0.2979 - val_loss: 1.2657 - val_accuracy: 0.4545 - 148s/epoch - 148s/step\n",
            "Epoch 2/500\n",
            "1/1 - 8s - loss: 1.1176 - accuracy: 0.6383 - val_loss: 1.2710 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 3/500\n",
            "1/1 - 8s - loss: 0.9372 - accuracy: 0.7234 - val_loss: 1.3127 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 4/500\n",
            "1/1 - 8s - loss: 0.7345 - accuracy: 0.8298 - val_loss: 1.2971 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.6433 - accuracy: 0.8085 - val_loss: 1.3163 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.5908 - accuracy: 0.8723 - val_loss: 1.3286 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.5375 - accuracy: 0.8936 - val_loss: 1.3347 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.4851 - accuracy: 0.9574 - val_loss: 1.3326 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.4642 - accuracy: 0.9149 - val_loss: 1.3320 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 9s - loss: 0.4461 - accuracy: 0.9574 - val_loss: 1.3423 - val_accuracy: 0.2727 - 9s/epoch - 9s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.4480 - accuracy: 0.9574 - val_loss: 1.3355 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.4163 - accuracy: 0.9787 - val_loss: 1.3293 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.3802 - accuracy: 0.9787 - val_loss: 1.3245 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3299 - accuracy: 1.0000 - val_loss: 1.3228 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.3763 - accuracy: 0.9787 - val_loss: 1.3232 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.3514 - accuracy: 0.9787 - val_loss: 1.3227 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.3107 - accuracy: 0.9787 - val_loss: 1.3223 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.3206 - accuracy: 0.9787 - val_loss: 1.3206 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.2976 - accuracy: 1.0000 - val_loss: 1.3193 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.2941 - accuracy: 1.0000 - val_loss: 1.3209 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.2932 - accuracy: 1.0000 - val_loss: 1.3176 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.2993 - accuracy: 1.0000 - val_loss: 1.3172 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.2895 - accuracy: 1.0000 - val_loss: 1.3179 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2761 - accuracy: 1.0000 - val_loss: 1.3205 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2871 - accuracy: 0.9787 - val_loss: 1.3172 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2969 - accuracy: 0.9787 - val_loss: 1.3215 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2606 - accuracy: 1.0000 - val_loss: 1.3205 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2580 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2667 - accuracy: 1.0000 - val_loss: 1.3139 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2623 - accuracy: 1.0000 - val_loss: 1.3066 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2569 - accuracy: 1.0000 - val_loss: 1.2973 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2538 - accuracy: 1.0000 - val_loss: 1.2850 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 11s - loss: 0.2518 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.5455 - 11s/epoch - 11s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2534 - accuracy: 1.0000 - val_loss: 1.2749 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2496 - accuracy: 1.0000 - val_loss: 1.2736 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2540 - accuracy: 1.0000 - val_loss: 1.2666 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 8s - loss: 0.2483 - accuracy: 1.0000 - val_loss: 1.2670 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2478 - accuracy: 1.0000 - val_loss: 1.2410 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 8s - loss: 0.2484 - accuracy: 1.0000 - val_loss: 1.1976 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2472 - accuracy: 1.0000 - val_loss: 1.1841 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2437 - accuracy: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2428 - accuracy: 1.0000 - val_loss: 1.2469 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 8s - loss: 0.2411 - accuracy: 1.0000 - val_loss: 1.2613 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 44/500\n",
            "1/1 - 8s - loss: 0.2411 - accuracy: 1.0000 - val_loss: 1.2163 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 45/500\n",
            "1/1 - 8s - loss: 0.2446 - accuracy: 1.0000 - val_loss: 1.2027 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 46/500\n",
            "1/1 - 8s - loss: 0.2383 - accuracy: 1.0000 - val_loss: 1.2244 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 47/500\n",
            "1/1 - 8s - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2401 - accuracy: 1.0000 - val_loss: 1.1406 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 8s - loss: 0.2356 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 50/500\n",
            "1/1 - 9s - loss: 0.2355 - accuracy: 1.0000 - val_loss: 1.0901 - val_accuracy: 0.4545 - 9s/epoch - 9s/step\n",
            "Epoch 51/500\n",
            "1/1 - 8s - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.0617 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 52/500\n",
            "1/1 - 8s - loss: 0.2365 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 53/500\n",
            "1/1 - 8s - loss: 0.2341 - accuracy: 1.0000 - val_loss: 1.1762 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 54/500\n",
            "1/1 - 10s - loss: 0.2363 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.7273 - 10s/epoch - 10s/step\n",
            "Epoch 55/500\n",
            "1/1 - 9s - loss: 0.2352 - accuracy: 1.0000 - val_loss: 1.1172 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 56/500\n",
            "1/1 - 8s - loss: 0.2332 - accuracy: 1.0000 - val_loss: 1.1213 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 57/500\n",
            "1/1 - 8s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 58/500\n",
            "1/1 - 8s - loss: 0.2339 - accuracy: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 59/500\n",
            "1/1 - 8s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 60/500\n",
            "1/1 - 8s - loss: 0.2335 - accuracy: 1.0000 - val_loss: 0.9723 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 61/500\n",
            "1/1 - 8s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 62/500\n",
            "1/1 - 8s - loss: 0.2322 - accuracy: 1.0000 - val_loss: 1.1155 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 63/500\n",
            "1/1 - 8s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 64/500\n",
            "1/1 - 10s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.0523 - val_accuracy: 0.8182 - 10s/epoch - 10s/step\n",
            "Epoch 65/500\n",
            "1/1 - 8s - loss: 0.2286 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 66/500\n",
            "1/1 - 8s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 67/500\n",
            "1/1 - 8s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.1002 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 8s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 1.0685 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 70/500\n",
            "1/1 - 8s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 1.1355 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 71/500\n",
            "1/1 - 8s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 72/500\n",
            "1/1 - 8s - loss: 0.2286 - accuracy: 1.0000 - val_loss: 1.0904 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 73/500\n",
            "1/1 - 8s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 74/500\n",
            "1/1 - 8s - loss: 0.2297 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 75/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.0579 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 76/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.1673 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2276 - accuracy: 1.0000 - val_loss: 1.3707 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.2728 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 80/500\n",
            "1/1 - 8s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 1.2299 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 81/500\n",
            "1/1 - 8s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 82/500\n",
            "1/1 - 8s - loss: 0.2267 - accuracy: 1.0000 - val_loss: 1.2848 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 83/500\n",
            "1/1 - 8s - loss: 0.2257 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 8s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 0.9972 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 86/500\n",
            "1/1 - 8s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 8s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 0.8943 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 89/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.0570 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 8s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.2668 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 93/500\n",
            "1/1 - 8s - loss: 0.2258 - accuracy: 1.0000 - val_loss: 1.1840 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2253 - accuracy: 1.0000 - val_loss: 1.1894 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.2325 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 96/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.0018 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.8698 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 8s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.1301 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 99/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 0.9452 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 100/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.0732 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 8s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.9270 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 8s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.8411 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.9138 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 108/500\n",
            "1/1 - 8s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 109/500\n",
            "1/1 - 8s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.0238 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.1497 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 8s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.2573 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 112/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.1708 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.0724 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 8s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 115/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.1260 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3388 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.1368 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 0.9500 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.8416 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.8917 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.7897 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 125/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.3520 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.8038 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.8528 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.8052 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.9622 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.8065 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.8373 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.7929 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.3179 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 1.1294 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.1367 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 11s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8158 - val_accuracy: 0.9091 - 11s/epoch - 11s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.8504 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 1.0250 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.9033 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 144/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.8828 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.1492 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 147/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.0951 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.4044 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.8084 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.5236 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.1699 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.1285 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.1891 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.3191 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.6345 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.9617 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 2.0311 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.8423 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.9612 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.5912 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.3275 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.6319 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.4658 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.3759 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 169/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.1221 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 170/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.1388 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.1602 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.0403 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 0.9401 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.2526 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.2182 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.3568 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.0891 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.4150 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.6407 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.9752 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 2.4250 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.4999 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.3155 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.1539 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0532 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.9153 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 0.9063 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.9139 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.9329 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.9469 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.5588 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.7462 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.9361 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 216/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.4906 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.7377 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.4185 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.2608 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.3533 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.1915 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.1157 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.0239 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.1331 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.0731 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.1993 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.5186 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 232/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.5344 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.2208 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.3199 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 235/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.3648 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.0234 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.2048 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.9355 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.3113 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.8227 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.0932 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 2.0269 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.6753 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.6340 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 9s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.9728 - val_accuracy: 0.6364 - 9s/epoch - 9s/step\n",
            "Epoch 256/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8408 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 257/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 258/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.8631 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.8722 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.7803 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.8019 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.8517 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.9712 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.2426 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.3898 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 271/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.4673 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.7280 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 274/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.6831 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.8347 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 9s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.3601 - val_accuracy: 0.6364 - 9s/epoch - 9s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.3176 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.2920 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.0877 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.1070 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.1993 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0596 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.9469 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.8832 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.8709 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.8223 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8526 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.8442 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 304/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 305/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 306/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.9118 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 309/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.1261 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.0102 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.0670 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7273 - 9s/epoch - 9s/step\n",
            "Epoch 315/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.7717 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.8727 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8285 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.0437 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.2555 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.9353 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.9285 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7806 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8301 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.9064 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.9861 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.3161 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.3806 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 335/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.3441 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 336/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.2029 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 337/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 340/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8421 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8545 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.1202 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4898 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.4560 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8404 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.8620 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.4809 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.7083 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 353/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.7186 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.8027 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.7717 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 356/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.7764 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.7385 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.0238 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.9397 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.2079 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.5683 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.2255 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.9461 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.5021 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.3179 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.7580 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.1941 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.8151 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.6300 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 370/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.3821 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 371/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 372/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.0677 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.3030 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3999 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.4861 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3746 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.2149 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 379/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 382/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 385/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.8580 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.9545 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 388/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.8673 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.8713 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.8668 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.8333 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 395/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.8858 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.0583 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0525 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1145 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.2314 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.3117 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.2393 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.8866 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.8542 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.1686 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.2571 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.8768 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.0330 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.2601 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.0773 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.9437 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.0760 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.8768 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.9085 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.4988 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.6502 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.7698 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.6910 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.8370 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.8049 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.5602 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.6881 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.8784 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.1416 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.1446 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.9415 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.2537 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.3666 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 442/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.3750 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.5336 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.0411 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 445/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.0467 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.0705 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.3724 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.6484 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.6613 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.6241 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 451/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.2673 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 452/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.2529 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 453/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.1479 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 454/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.2964 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 455/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.1054 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 456/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.1263 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 457/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.2233 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 458/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.0057 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.9827 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.4887 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 461/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.2387 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.0591 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9997 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9514 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 468/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.8701 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.8997 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.9739 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 471/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.1298 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.9976 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.9139 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.9853 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.2799 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4877 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.2972 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 486/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.2266 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 487/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4724 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.3642 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.5274 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 490/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.9084 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 491/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.8023 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 492/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.5763 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 493/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.2699 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 494/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 495/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.2740 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 496/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.6179 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 497/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 498/500\n",
            "1/1 - 9s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.0704 - val_accuracy: 0.7273 - 9s/epoch - 9s/step\n",
            "Epoch 499/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 500/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Time exp_cmex_3class_model_fold_4 = 4240.761803865433 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_4\n",
            "saved-model-001-0.4545.hdf5\n",
            "Loss=1.2657 y Accuracy=0.4545\n",
            "\n",
            "saved-model-033-0.5455.hdf5\n",
            "Loss=1.2780 y Accuracy=0.5455\n",
            "\n",
            "saved-model-054-0.7273.hdf5\n",
            "Loss=1.1049 y Accuracy=0.7273\n",
            "\n",
            "saved-model-064-0.8182.hdf5\n",
            "Loss=1.0523 y Accuracy=0.8182\n",
            "\n",
            "saved-model-137-0.9091.hdf5\n",
            "Loss=0.8158 y Accuracy=0.9091\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-137-0.9091.hdf5\n",
            "Loss=0.8158 y Accuracy=0.9091\n",
            "\n",
            "Evaluating the best model from fold 4...\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       1.00      0.80      0.89         5\n",
            "     Class_C       1.00      1.00      1.00         3\n",
            "     Class_F       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.91        11\n",
            "   macro avg       0.92      0.93      0.92        11\n",
            "weighted avg       0.93      0.91      0.91        11\n",
            "\n",
            "Fold 4 - Metrics: {'Fold': 4, 'Accuracy': 0.9090909090909091, 'Precision': 0.9318181818181818, 'Recall': 0.9090909090909091, 'F1-Score': 0.9105339105339105}\n",
            "--- Fold 5/5 ---\n",
            "X_train1_fold: (47, 21)\n",
            "X_test1_fold: (11, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 135s - loss: 1.8446 - accuracy: 0.4043 - val_loss: 1.2892 - val_accuracy: 0.4545 - 135s/epoch - 135s/step\n",
            "Epoch 2/500\n",
            "1/1 - 11s - loss: 1.1742 - accuracy: 0.5957 - val_loss: 1.2647 - val_accuracy: 0.5455 - 11s/epoch - 11s/step\n",
            "Epoch 3/500\n",
            "1/1 - 8s - loss: 0.9017 - accuracy: 0.7021 - val_loss: 1.2666 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 4/500\n",
            "1/1 - 8s - loss: 0.7793 - accuracy: 0.8085 - val_loss: 1.2967 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.6243 - accuracy: 0.8723 - val_loss: 1.3229 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.5188 - accuracy: 0.9149 - val_loss: 1.3116 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.4635 - accuracy: 0.9574 - val_loss: 1.3380 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.3923 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.4473 - accuracy: 0.9362 - val_loss: 1.4064 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 8s - loss: 0.3603 - accuracy: 0.9787 - val_loss: 1.3893 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.3928 - accuracy: 0.9574 - val_loss: 1.4193 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.3408 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.3199 - accuracy: 1.0000 - val_loss: 1.2890 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3061 - accuracy: 1.0000 - val_loss: 1.3737 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.3473 - accuracy: 0.9787 - val_loss: 1.4793 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.2857 - accuracy: 1.0000 - val_loss: 1.4914 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.2836 - accuracy: 1.0000 - val_loss: 1.5060 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.2857 - accuracy: 1.0000 - val_loss: 1.4926 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.2851 - accuracy: 1.0000 - val_loss: 1.5704 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.2851 - accuracy: 1.0000 - val_loss: 1.9978 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.2690 - accuracy: 1.0000 - val_loss: 2.1749 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.2819 - accuracy: 1.0000 - val_loss: 2.3006 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.2612 - accuracy: 1.0000 - val_loss: 2.4461 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2680 - accuracy: 1.0000 - val_loss: 2.3835 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2520 - accuracy: 1.0000 - val_loss: 2.3712 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2534 - accuracy: 1.0000 - val_loss: 2.4102 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2475 - accuracy: 1.0000 - val_loss: 2.4952 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2516 - accuracy: 1.0000 - val_loss: 2.4282 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2476 - accuracy: 1.0000 - val_loss: 2.5574 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2455 - accuracy: 1.0000 - val_loss: 2.3443 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2440 - accuracy: 1.0000 - val_loss: 2.3063 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2481 - accuracy: 1.0000 - val_loss: 1.8976 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 8s - loss: 0.2404 - accuracy: 1.0000 - val_loss: 1.5318 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2441 - accuracy: 1.0000 - val_loss: 1.2681 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2382 - accuracy: 1.0000 - val_loss: 1.0475 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 10s - loss: 0.2413 - accuracy: 1.0000 - val_loss: 0.9762 - val_accuracy: 0.6364 - 10s/epoch - 10s/step\n",
            "Epoch 37/500\n",
            "1/1 - 10s - loss: 0.2394 - accuracy: 1.0000 - val_loss: 0.9298 - val_accuracy: 0.7273 - 10s/epoch - 10s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 0.9256 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 10s - loss: 0.2361 - accuracy: 1.0000 - val_loss: 0.9127 - val_accuracy: 0.8182 - 10s/epoch - 10s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2344 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 0.9720 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 1.0008 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 8s - loss: 0.2315 - accuracy: 1.0000 - val_loss: 1.0546 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 44/500\n",
            "1/1 - 8s - loss: 0.2345 - accuracy: 1.0000 - val_loss: 0.9478 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 45/500\n",
            "1/1 - 8s - loss: 0.2311 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 46/500\n",
            "1/1 - 8s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 47/500\n",
            "1/1 - 8s - loss: 0.2352 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2331 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 8s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 0.8620 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 50/500\n",
            "1/1 - 8s - loss: 0.2318 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 51/500\n",
            "1/1 - 8s - loss: 0.2320 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 52/500\n",
            "1/1 - 8s - loss: 0.2328 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 53/500\n",
            "1/1 - 8s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 54/500\n",
            "1/1 - 8s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 0.8622 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 55/500\n",
            "1/1 - 8s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 56/500\n",
            "1/1 - 8s - loss: 0.2285 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 57/500\n",
            "1/1 - 8s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 58/500\n",
            "1/1 - 8s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 59/500\n",
            "1/1 - 8s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 60/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 61/500\n",
            "1/1 - 8s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 62/500\n",
            "1/1 - 8s - loss: 0.2269 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 63/500\n",
            "1/1 - 8s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 64/500\n",
            "1/1 - 8s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.9541 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 65/500\n",
            "1/1 - 8s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 66/500\n",
            "1/1 - 8s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 67/500\n",
            "1/1 - 8s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.0263 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.0275 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 8s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.0667 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 70/500\n",
            "1/1 - 8s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.1124 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 71/500\n",
            "1/1 - 8s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.1340 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 72/500\n",
            "1/1 - 8s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.0989 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 73/500\n",
            "1/1 - 8s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 74/500\n",
            "1/1 - 8s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 75/500\n",
            "1/1 - 8s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 76/500\n",
            "1/1 - 8s - loss: 0.2273 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 1.0417 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 8s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 1.1224 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 80/500\n",
            "1/1 - 8s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 1.0428 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 81/500\n",
            "1/1 - 8s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 82/500\n",
            "1/1 - 8s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.0796 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 83/500\n",
            "1/1 - 8s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 86/500\n",
            "1/1 - 8s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.2097 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.2415 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 8s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.1984 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 89/500\n",
            "1/1 - 8s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.1834 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.1512 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.1487 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 8s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.0919 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 93/500\n",
            "1/1 - 8s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.2486 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 96/500\n",
            "1/1 - 8s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 8s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.0808 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 99/500\n",
            "1/1 - 8s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 1.1875 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 100/500\n",
            "1/1 - 8s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.2140 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.2660 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.0280 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.0632 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.0530 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 8s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.0236 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 108/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.0222 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 109/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.0348 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.1748 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 112/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.0838 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.0445 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 115/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.1072 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.1243 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 8s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 1.2394 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3201 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.2928 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.2040 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.2231 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.1356 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.9874 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 125/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.0048 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.9067 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.8486 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.0608 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.1596 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 1.1775 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.2443 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.2122 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.1794 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.1450 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 144/500\n",
            "1/1 - 8s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.0589 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 147/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.0908 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0833 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9366 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.7692 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0432 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.0798 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.0440 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.0697 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.0451 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.1444 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.2264 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.2624 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.3099 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.2326 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 169/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 170/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.1312 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.0700 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.0568 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.2112 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.2539 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.2108 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.2134 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.2233 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.2409 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.1716 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.0011 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.9153 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.0313 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.0688 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0617 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.1034 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.1216 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.0480 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9865 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.0282 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.3906 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.5525 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.3561 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.1208 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.0784 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0010 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.9275 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9015 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.0603 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.0535 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 216/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.1741 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.1982 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.2293 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.1126 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.0886 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.1271 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.0819 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1953 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.2248 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.1709 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.0316 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 232/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1838 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 235/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.2573 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.0366 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.0973 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.9737 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.1722 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.1464 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.2294 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.3056 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.2800 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.3171 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.1800 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.9367 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.0738 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.1246 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.1351 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 256/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 257/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 258/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8605 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.9746 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.0114 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9403 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.8992 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.8554 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0273 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.1304 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 271/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.1385 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.0782 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 274/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0646 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.1550 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2282 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.2794 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.3462 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.3300 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.1204 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.2448 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.0233 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.0802 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2073 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2680 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.3204 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.3494 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.4397 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.3947 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.3078 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.2063 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.1704 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.1566 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.1389 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 304/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.1693 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 305/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.1758 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 306/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.1355 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 309/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.1279 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.0937 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 315/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.1059 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8853 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.9439 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.9879 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.1583 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.3430 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.4561 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.4335 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.4841 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.5472 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.4749 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.5154 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.4569 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4376 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.5578 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.4881 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.3235 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.3068 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 335/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9274 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 336/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.8384 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 337/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 10s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.9091 - 10s/epoch - 10s/step\n",
            "Epoch 340/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.9504 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.1636 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.2380 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 353/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.0353 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.0301 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.2847 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 356/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4621 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.5521 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.5378 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.4415 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4206 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3372 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4306 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.4279 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.4820 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.9832 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.7146 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3116 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3896 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 370/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 371/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.0782 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 372/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.5313 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 379/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.5033 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.4518 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.3395 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 382/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2206 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.2033 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 385/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2214 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.2319 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.2592 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 388/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.1273 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 395/500\n",
            "1/1 - 9s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.7273 - 9s/epoch - 9s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.1518 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.0756 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.1976 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.4145 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.5402 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.3407 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.2684 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.1986 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.2886 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2589 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.2856 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.3847 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.4409 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.3399 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.4086 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.3942 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.3956 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2500 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.2273 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.2397 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.3692 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.2628 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.0453 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.1788 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.7827 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.0795 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.0388 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.0715 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.5953 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.2139 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.3179 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.2614 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.4031 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.2540 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.2215 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.2216 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.2145 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 442/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9149 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.8751 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 445/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.8760 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.1356 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.1883 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 9s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.7273 - 9s/epoch - 9s/step\n",
            "Epoch 451/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.3459 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 452/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.5719 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 453/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.5071 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 454/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.4693 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 455/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 456/500\n",
            "1/1 - 9s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.4205 - val_accuracy: 0.6364 - 9s/epoch - 9s/step\n",
            "Epoch 457/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4484 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 458/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.4967 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.6130 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.5491 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 461/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.2798 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.0034 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.1682 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.1243 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 468/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.0877 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.1567 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.3126 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 471/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.3992 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.3765 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.3531 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.4454 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4553 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.4041 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.0654 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.3294 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.4302 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.4581 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.4864 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.3121 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 486/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 487/500\n",
            "1/1 - 8s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 490/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 491/500\n",
            "1/1 - 8s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 492/500\n",
            "1/1 - 8s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 493/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 494/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 495/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.9570 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 496/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 497/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.9714 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 498/500\n",
            "1/1 - 8s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 499/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 500/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.2242 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Time exp_cmex_3class_model_fold_5 = 4190.022245883942 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_5\n",
            "saved-model-001-0.4545.hdf5\n",
            "Loss=1.2892 y Accuracy=0.4545\n",
            "\n",
            "saved-model-002-0.5455.hdf5\n",
            "Loss=1.2647 y Accuracy=0.5455\n",
            "\n",
            "saved-model-036-0.6364.hdf5\n",
            "Loss=0.9762 y Accuracy=0.6364\n",
            "\n",
            "saved-model-037-0.7273.hdf5\n",
            "Loss=0.9298 y Accuracy=0.7273\n",
            "\n",
            "saved-model-039-0.8182.hdf5\n",
            "Loss=0.9127 y Accuracy=0.8182\n",
            "\n",
            "saved-model-339-0.9091.hdf5\n",
            "Loss=0.7016 y Accuracy=0.9091\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-339-0.9091.hdf5\n",
            "Loss=0.7016 y Accuracy=0.9091\n",
            "\n",
            "Evaluating the best model from fold 5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7905a33a4ae0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 11s 11s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       0.83      1.00      0.91         5\n",
            "     Class_C       1.00      1.00      1.00         3\n",
            "     Class_F       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.91        11\n",
            "   macro avg       0.94      0.89      0.90        11\n",
            "weighted avg       0.92      0.91      0.90        11\n",
            "\n",
            "Fold 5 - Metrics: {'Fold': 5, 'Accuracy': 0.9090909090909091, 'Precision': 0.9242424242424243, 'Recall': 0.9090909090909091, 'F1-Score': 0.9041322314049587}\n",
            "\n",
            "--- Cross-Validation Results ---\n",
            "   Fold  Accuracy  Precision    Recall  F1-Score\n",
            "0     1  0.916667   0.928571  0.916667  0.911538\n",
            "1     2  1.000000   1.000000  1.000000  1.000000\n",
            "2     3  1.000000   1.000000  1.000000  1.000000\n",
            "3     4  0.909091   0.931818  0.909091  0.910534\n",
            "4     5  0.909091   0.924242  0.909091  0.904132\n",
            "\n",
            "Mean Metrics:\n",
            "Fold         3.000000\n",
            "Accuracy     0.946970\n",
            "Precision    0.956926\n",
            "Recall       0.946970\n",
            "F1-Score     0.945241\n",
            "dtype: float64\n",
            "\n",
            "Standard Deviation Metrics:\n",
            "Fold         1.581139\n",
            "Accuracy     0.048509\n",
            "Precision    0.039412\n",
            "Recall       0.048509\n",
            "F1-Score     0.050069\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imputados"
      ],
      "metadata": {
        "id": "z4PFQasTu4oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title STFT AvCvF\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Configuración\n",
        "n_splits = 5  # Número de folds\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Parámetros del entrenamiento\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name_template = \"exp_cmex_3class_model_fold_{}\"\n",
        "\n",
        "# Ruta base para los logs\n",
        "path_log_base = '/content/logs'\n",
        "os.makedirs(path_log_base, exist_ok=True)\n",
        "\n",
        "# Listas para almacenar los resultados de cada fold\n",
        "metrics_summary = []\n",
        "\n",
        "# Realizar Cross-Validation\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(flat_features, labels_stft)):\n",
        "    print(f\"--- Fold {fold + 1}/{n_splits} ---\")\n",
        "\n",
        "    # Dividir los datos en entrenamiento y prueba\n",
        "    X_train1_fold, X_test1_fold = flat_features[train_idx], flat_features[test_idx]\n",
        "    X_train_fold, X_test_fold = eeg_data[train_idx], eeg_data[test_idx]\n",
        "    y_train_fold, y_test_fold = labels_stft[train_idx], labels_stft[test_idx]\n",
        "    #standar scaler a los datos planos\n",
        "    scaler = StandardScaler()\n",
        "    X_train1_fold = scaler.fit_transform(X_train1_fold)\n",
        "    X_test1_fold = scaler.transform(X_test1_fold)\n",
        "    print(f'X_train1_fold: {X_train1_fold.shape}')\n",
        "    print(f'X_test1_fold: {X_test1_fold.shape}')\n",
        "    # Crear un nuevo modelo para este fold\n",
        "    model = new_arch()\n",
        "\n",
        "    # Entrenar el modelo\n",
        "    log_dir = f\"{path_log_base}/{model_name_template.format(fold + 1)}\"\n",
        "    train(\n",
        "        model=model,\n",
        "        X_train1=X_train1_fold, X_train=X_train_fold, y_train=y_train_fold,\n",
        "        X_valid1=X_test1_fold, X_valid=X_test_fold, y_valid=y_test_fold,\n",
        "        X_test1=X_test1_fold, X_test=X_test_fold, y_test=y_test_fold,\n",
        "        batch_size=batch_size, epochs=epochs,\n",
        "        model_name=model_name_template.format(fold + 1)\n",
        "    )\n",
        "\n",
        "    # Evaluar el mejor modelo guardado en el fold\n",
        "    print(f\"Evaluating the best model from fold {fold + 1}...\")\n",
        "    model_files = [f for f in os.listdir(log_dir) if f.endswith(\".hdf5\")]\n",
        "    best_model_filename = sorted(\n",
        "        model_files,\n",
        "        key=lambda x: float(x.split('-')[-1].replace('.hdf5', '')),\n",
        "        reverse=True\n",
        "    )[0]  # Seleccionar el modelo con la mejor val_accuracy\n",
        "    best_model = load_model(f\"{log_dir}/{best_model_filename}\")\n",
        "\n",
        "    # Predecir en el conjunto de prueba\n",
        "    y_pred_test = best_model.predict([X_test1_fold, X_test_fold])\n",
        "    y_pred_test = np.argmax(y_pred_test, axis=1)  # Convertir a etiquetas categóricas\n",
        "    y_test_true = y_test_fold  # Etiquetas verdaderas\n",
        "\n",
        "    # Calcular métricas\n",
        "    fold_metrics = {\n",
        "        \"Fold\": fold + 1,\n",
        "        \"Accuracy\": accuracy_score(y_test_true, y_pred_test),\n",
        "        \"Precision\": precision_score(y_test_true, y_pred_test, average='weighted'),\n",
        "        \"Recall\": recall_score(y_test_true, y_pred_test, average='weighted'),\n",
        "        \"F1-Score\": f1_score(y_test_true, y_pred_test, average='weighted')\n",
        "    }\n",
        "\n",
        "    # Mostrar reporte de clasificación\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test_true, y_pred_test, target_names=[\"Class_A\", \"Class_C\",\"Class_F\"]))\n",
        "\n",
        "    # Guardar métricas del fold\n",
        "    metrics_summary.append(fold_metrics)\n",
        "    print(f\"Fold {fold + 1} - Metrics: {fold_metrics}\")\n",
        "\n",
        "# Mostrar resultados finales\n",
        "print(\"\\n--- Cross-Validation Results ---\")\n",
        "metrics_df = pd.DataFrame(metrics_summary)\n",
        "print(metrics_df)\n",
        "\n",
        "# Calcular promedios y desviaciones estándar\n",
        "mean_metrics = metrics_df.mean(axis=0)\n",
        "std_metrics = metrics_df.std(axis=0)\n",
        "\n",
        "print(\"\\nMean Metrics:\")\n",
        "print(mean_metrics)\n",
        "print(\"\\nStandard Deviation Metrics:\")\n",
        "print(std_metrics)\n",
        "\n",
        "# Guardar métricas en un archivo CSV\n",
        "metrics_df.to_csv(f\"{path_log_base}/cross_validation_metrics.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6fd75e4-18db-43c6-884d-ebdfd7f5f1eb",
        "cellView": "form",
        "id": "7DLJJhjiu59Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Fold 1/5 ---\n",
            "X_train1_fold: (46, 21)\n",
            "X_test1_fold: (12, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 143s - loss: 1.9307 - accuracy: 0.2609 - val_loss: 1.2335 - val_accuracy: 0.6667 - 143s/epoch - 143s/step\n",
            "Epoch 2/500\n",
            "1/1 - 8s - loss: 1.0668 - accuracy: 0.6957 - val_loss: 1.2360 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 3/500\n",
            "1/1 - 8s - loss: 0.8054 - accuracy: 0.7609 - val_loss: 1.2127 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 4/500\n",
            "1/1 - 10s - loss: 0.6651 - accuracy: 0.8261 - val_loss: 1.2912 - val_accuracy: 0.7500 - 10s/epoch - 10s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.5210 - accuracy: 0.8913 - val_loss: 1.2951 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.5865 - accuracy: 0.8478 - val_loss: 1.2866 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.4288 - accuracy: 0.9565 - val_loss: 1.2761 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.4535 - accuracy: 0.9130 - val_loss: 1.2745 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.4169 - accuracy: 1.0000 - val_loss: 1.2605 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 8s - loss: 0.3901 - accuracy: 0.9348 - val_loss: 1.2714 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.3427 - accuracy: 0.9783 - val_loss: 1.2754 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.2950 - accuracy: 1.0000 - val_loss: 1.2909 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.2991 - accuracy: 1.0000 - val_loss: 1.3127 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3024 - accuracy: 0.9783 - val_loss: 1.2976 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.2756 - accuracy: 1.0000 - val_loss: 1.2578 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.2625 - accuracy: 1.0000 - val_loss: 1.2453 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.2629 - accuracy: 1.0000 - val_loss: 1.2394 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.2768 - accuracy: 1.0000 - val_loss: 1.2483 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.2725 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.2631 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.2636 - accuracy: 1.0000 - val_loss: 1.2499 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.2585 - accuracy: 1.0000 - val_loss: 1.2325 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.2582 - accuracy: 1.0000 - val_loss: 1.2532 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2490 - accuracy: 1.0000 - val_loss: 1.2664 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2563 - accuracy: 1.0000 - val_loss: 1.2590 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2442 - accuracy: 1.0000 - val_loss: 1.2060 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2423 - accuracy: 1.0000 - val_loss: 1.2324 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2445 - accuracy: 1.0000 - val_loss: 1.2953 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2442 - accuracy: 1.0000 - val_loss: 1.3619 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2418 - accuracy: 1.0000 - val_loss: 1.5273 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2336 - accuracy: 1.0000 - val_loss: 1.5885 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2388 - accuracy: 1.0000 - val_loss: 1.9218 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 8s - loss: 0.2366 - accuracy: 1.0000 - val_loss: 2.0756 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 2.1263 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2346 - accuracy: 1.0000 - val_loss: 2.3014 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2360 - accuracy: 1.0000 - val_loss: 2.1517 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 8s - loss: 0.2356 - accuracy: 1.0000 - val_loss: 2.1837 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 2.2744 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 8s - loss: 0.2294 - accuracy: 1.0000 - val_loss: 2.2397 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 2.2488 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2316 - accuracy: 1.0000 - val_loss: 2.2100 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2291 - accuracy: 1.0000 - val_loss: 2.1781 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 8s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 44/500\n",
            "1/1 - 8s - loss: 0.2299 - accuracy: 1.0000 - val_loss: 1.8187 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 45/500\n",
            "1/1 - 8s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 1.7273 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 46/500\n",
            "1/1 - 8s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 1.3424 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 47/500\n",
            "1/1 - 8s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2274 - accuracy: 1.0000 - val_loss: 1.1064 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 8s - loss: 0.2260 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 50/500\n",
            "1/1 - 8s - loss: 0.2260 - accuracy: 1.0000 - val_loss: 1.1879 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 51/500\n",
            "1/1 - 8s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 1.1817 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 52/500\n",
            "1/1 - 8s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 53/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.9884 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 54/500\n",
            "1/1 - 8s - loss: 0.2253 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 55/500\n",
            "1/1 - 8s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.7383 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 56/500\n",
            "1/1 - 8s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.4750 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 57/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.4667 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 58/500\n",
            "1/1 - 8s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 1.5929 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 59/500\n",
            "1/1 - 8s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 1.8196 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 60/500\n",
            "1/1 - 8s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 2.0611 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 61/500\n",
            "1/1 - 8s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 2.0982 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 62/500\n",
            "1/1 - 8s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.6650 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 63/500\n",
            "1/1 - 8s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.7621 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 64/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.6541 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 65/500\n",
            "1/1 - 8s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 1.5764 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 66/500\n",
            "1/1 - 8s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 1.4388 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 67/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.2893 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 10s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.8333 - 10s/epoch - 10s/step\n",
            "Epoch 70/500\n",
            "1/1 - 8s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.7791 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 71/500\n",
            "1/1 - 8s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 72/500\n",
            "1/1 - 10s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.9167 - 10s/epoch - 10s/step\n",
            "Epoch 73/500\n",
            "1/1 - 8s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 74/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.8583 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 75/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.8648 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 76/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.8238 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.8356 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 0.8325 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 80/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 81/500\n",
            "1/1 - 8s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 82/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.7754 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 83/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.7428 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.7281 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 86/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 8s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.7921 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 89/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 8s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 93/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.8467 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.7803 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 8s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 96/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.6555 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 99/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.6222 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 100/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 0.6026 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.6695 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.6386 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.6983 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.7549 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 108/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.6958 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 109/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.7670 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.7607 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 112/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.7417 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.7196 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 115/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.7542 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.7427 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.7659 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.7788 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 125/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.7409 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.8421 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.9013 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.7334 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.6497 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.6489 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.6619 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.6815 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 144/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.7448 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.7731 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 147/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.7413 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.5936 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.8554 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.9633 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.2155 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.7469 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.2022 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.0958 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.4130 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.6127 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.7190 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.6562 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.5208 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.4311 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 169/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.1435 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 170/500\n",
            "1/1 - 9s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 2.5896 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 2.5497 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.9187 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.2537 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.7510 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.6807 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.3460 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.0737 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.6278 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.5713 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.7285 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.7794 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.7826 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.8794 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.2185 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.2088 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.2066 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.1085 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.2371 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1640 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.2381 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.2677 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.7650 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8936 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.1736 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.5250 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.6387 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3045 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.3243 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.8682 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.4987 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.7548 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 216/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.9608 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.0715 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.2928 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 2.2488 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.8650 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.5182 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.3694 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.5503 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.5750 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.7552 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.2037 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 232/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.8088 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.6492 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 235/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.6205 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.6578 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.6624 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.7832 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7831 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7544 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.7899 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.7988 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 256/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8220 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 257/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.7651 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 258/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.6735 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.7872 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.8597 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8099 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.7917 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.7859 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.7596 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.7399 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 0.7735 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 271/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8242 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8353 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 274/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.0464 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8119 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8058 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7594 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7263 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.6999 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8567 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8547 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8344 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.8307 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.9412 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9094 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9774 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.0894 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.9727 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9257 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9389 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 304/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 305/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 306/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.8889 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.8905 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 309/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9263 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.0552 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8973 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 315/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8300 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.8146 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.9275 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.7617 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.2126 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9185 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.1872 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9271 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.0311 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.1327 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4793 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4004 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.8457 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9770 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.4042 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 335/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.2516 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 336/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.9991 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 337/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.1921 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.0662 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9870 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 340/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.1001 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.1777 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.0785 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.0937 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.7124 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.3961 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.5384 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.4158 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.1696 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 353/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.9997 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.1257 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.2560 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 356/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1363 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.9014 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.8585 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.8724 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0540 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.9927 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.0136 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9742 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.0082 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 370/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1030 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 371/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.1197 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 372/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1765 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.0875 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1785 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 379/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 382/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.0340 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.7756 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 385/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.8759 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.7796 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.4532 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 388/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.6483 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.6335 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0494 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.9747 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 395/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.0507 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.9072 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9433 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9121 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.9443 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.9435 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.9047 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.8662 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.4120 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.2642 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.7804 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.8450 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9715 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8857 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 0.9862 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.9677 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.3862 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.4765 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.4474 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.3188 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8946 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.1289 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.0754 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.0103 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 442/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.9201 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.9357 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.8687 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 445/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.8632 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.2327 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.3416 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.3123 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.9479 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 451/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 452/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 453/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.8186 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 454/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 455/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.8589 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 456/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 457/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.8865 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 458/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.9585 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.9444 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 461/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.8276 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.8261 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.8533 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 468/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 471/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0848 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0963 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.0840 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.1011 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.1333 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.0704 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.0845 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.9677 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.0851 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 8s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 486/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 487/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.0780 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 490/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9499 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 491/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 492/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.9181 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 493/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 494/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9245 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 495/500\n",
            "1/1 - 8s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 496/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 497/500\n",
            "1/1 - 8s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 498/500\n",
            "1/1 - 8s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.0027 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 499/500\n",
            "1/1 - 8s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 500/500\n",
            "1/1 - 8s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Time exp_cmex_3class_model_fold_1 = 4182.789949417114 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_1\n",
            "saved-model-001-0.5000.hdf5\n",
            "Loss=1.3016 y Accuracy=0.5000\n",
            "\n",
            "saved-model-001-0.6667.hdf5\n",
            "Loss=1.2335 y Accuracy=0.6667\n",
            "\n",
            "saved-model-002-0.5833.hdf5\n",
            "Loss=1.2542 y Accuracy=0.5833\n",
            "\n",
            "saved-model-004-0.7500.hdf5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 509 calls to <function Model.make_test_function.<locals>.test_function at 0x790cd6c41b20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=1.2912 y Accuracy=0.7500\n",
            "\n",
            "saved-model-043-0.6667.hdf5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 510 calls to <function Model.make_test_function.<locals>.test_function at 0x790db9760220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=1.0459 y Accuracy=0.6667\n",
            "\n",
            "saved-model-044-0.7500.hdf5\n",
            "Loss=0.9957 y Accuracy=0.7500\n",
            "\n",
            "saved-model-052-0.8333.hdf5\n",
            "Loss=0.8513 y Accuracy=0.8333\n",
            "\n",
            "saved-model-069-0.8333.hdf5\n",
            "Loss=0.8191 y Accuracy=0.8333\n",
            "\n",
            "saved-model-072-0.9167.hdf5\n",
            "Loss=0.7425 y Accuracy=0.9167\n",
            "\n",
            "saved-model-077-0.9167.hdf5\n",
            "Loss=0.6048 y Accuracy=0.9167\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-072-0.9167.hdf5\n",
            "Loss=0.7425 y Accuracy=0.9167\n",
            "\n",
            "Evaluating the best model from fold 1...\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       0.86      1.00      0.92         6\n",
            "     Class_C       1.00      1.00      1.00         3\n",
            "     Class_F       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.92        12\n",
            "   macro avg       0.95      0.89      0.91        12\n",
            "weighted avg       0.93      0.92      0.91        12\n",
            "\n",
            "Fold 1 - Metrics: {'Fold': 1, 'Accuracy': 0.9166666666666666, 'Precision': 0.9285714285714285, 'Recall': 0.9166666666666666, 'F1-Score': 0.9115384615384615}\n",
            "--- Fold 2/5 ---\n",
            "X_train1_fold: (46, 21)\n",
            "X_test1_fold: (12, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 132s - loss: 1.7767 - accuracy: 0.3913 - val_loss: 1.2333 - val_accuracy: 0.4167 - 132s/epoch - 132s/step\n",
            "Epoch 2/500\n",
            "1/1 - 8s - loss: 0.9508 - accuracy: 0.7391 - val_loss: 1.2080 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 3/500\n",
            "1/1 - 10s - loss: 0.7565 - accuracy: 0.7826 - val_loss: 1.2033 - val_accuracy: 0.5000 - 10s/epoch - 10s/step\n",
            "Epoch 4/500\n",
            "1/1 - 8s - loss: 0.6992 - accuracy: 0.8043 - val_loss: 1.4004 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.5933 - accuracy: 0.9130 - val_loss: 1.4077 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.6277 - accuracy: 0.8043 - val_loss: 1.3879 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.5714 - accuracy: 0.8696 - val_loss: 1.4153 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.5477 - accuracy: 0.8478 - val_loss: 1.4290 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.4480 - accuracy: 0.9565 - val_loss: 1.4447 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 8s - loss: 0.4379 - accuracy: 0.9783 - val_loss: 1.4583 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.4123 - accuracy: 0.9565 - val_loss: 1.4583 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.4133 - accuracy: 0.9783 - val_loss: 1.4561 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.3735 - accuracy: 0.9565 - val_loss: 1.4243 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3641 - accuracy: 0.9783 - val_loss: 1.4244 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.3370 - accuracy: 0.9783 - val_loss: 1.4506 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.3644 - accuracy: 0.9565 - val_loss: 1.4948 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.3297 - accuracy: 1.0000 - val_loss: 1.5231 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.3310 - accuracy: 1.0000 - val_loss: 1.5565 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.2887 - accuracy: 1.0000 - val_loss: 1.5958 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.2986 - accuracy: 1.0000 - val_loss: 1.6604 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.2984 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.2789 - accuracy: 1.0000 - val_loss: 1.7334 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.2832 - accuracy: 1.0000 - val_loss: 1.7796 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2711 - accuracy: 1.0000 - val_loss: 1.7853 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2871 - accuracy: 1.0000 - val_loss: 1.7992 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2647 - accuracy: 1.0000 - val_loss: 1.8241 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2731 - accuracy: 1.0000 - val_loss: 1.7831 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2620 - accuracy: 1.0000 - val_loss: 1.8256 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2651 - accuracy: 1.0000 - val_loss: 1.8550 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2574 - accuracy: 1.0000 - val_loss: 1.9206 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2596 - accuracy: 1.0000 - val_loss: 1.9336 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2531 - accuracy: 1.0000 - val_loss: 1.8531 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 8s - loss: 0.2562 - accuracy: 1.0000 - val_loss: 1.7205 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2524 - accuracy: 1.0000 - val_loss: 1.7984 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2536 - accuracy: 1.0000 - val_loss: 1.6903 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2515 - accuracy: 1.0000 - val_loss: 1.7162 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 8s - loss: 0.2553 - accuracy: 1.0000 - val_loss: 1.7010 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2514 - accuracy: 1.0000 - val_loss: 1.7556 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 8s - loss: 0.2482 - accuracy: 1.0000 - val_loss: 1.8151 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2500 - accuracy: 1.0000 - val_loss: 1.8674 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2485 - accuracy: 1.0000 - val_loss: 1.6273 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2464 - accuracy: 1.0000 - val_loss: 1.1553 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 10s - loss: 0.2446 - accuracy: 1.0000 - val_loss: 1.1947 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 44/500\n",
            "1/1 - 10s - loss: 0.2449 - accuracy: 1.0000 - val_loss: 0.9090 - val_accuracy: 0.7500 - 10s/epoch - 10s/step\n",
            "Epoch 45/500\n",
            "1/1 - 9s - loss: 0.2460 - accuracy: 1.0000 - val_loss: 1.1417 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 46/500\n",
            "1/1 - 9s - loss: 0.2460 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 47/500\n",
            "1/1 - 11s - loss: 0.2423 - accuracy: 1.0000 - val_loss: 0.8237 - val_accuracy: 0.8333 - 11s/epoch - 11s/step\n",
            "Epoch 48/500\n",
            "1/1 - 9s - loss: 0.2447 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 49/500\n",
            "1/1 - 9s - loss: 0.2408 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 50/500\n",
            "1/1 - 9s - loss: 0.2408 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 51/500\n",
            "1/1 - 9s - loss: 0.2413 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 52/500\n",
            "1/1 - 9s - loss: 0.2420 - accuracy: 1.0000 - val_loss: 1.1279 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 53/500\n",
            "1/1 - 9s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 54/500\n",
            "1/1 - 9s - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.8543 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 55/500\n",
            "1/1 - 9s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 0.9301 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 56/500\n",
            "1/1 - 9s - loss: 0.2390 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 57/500\n",
            "1/1 - 9s - loss: 0.2371 - accuracy: 1.0000 - val_loss: 1.0613 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 58/500\n",
            "1/1 - 9s - loss: 0.2375 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 59/500\n",
            "1/1 - 9s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 1.4989 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 60/500\n",
            "1/1 - 9s - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.9486 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 61/500\n",
            "1/1 - 9s - loss: 0.2356 - accuracy: 1.0000 - val_loss: 0.8533 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 62/500\n",
            "1/1 - 9s - loss: 0.2358 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 63/500\n",
            "1/1 - 9s - loss: 0.2365 - accuracy: 1.0000 - val_loss: 1.7689 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 64/500\n",
            "1/1 - 9s - loss: 0.2367 - accuracy: 1.0000 - val_loss: 1.5230 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 65/500\n",
            "1/1 - 9s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 66/500\n",
            "1/1 - 9s - loss: 0.2335 - accuracy: 1.0000 - val_loss: 1.5172 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 67/500\n",
            "1/1 - 9s - loss: 0.2350 - accuracy: 1.0000 - val_loss: 1.2047 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 68/500\n",
            "1/1 - 9s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 69/500\n",
            "1/1 - 9s - loss: 0.2326 - accuracy: 1.0000 - val_loss: 0.8199 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 70/500\n",
            "1/1 - 9s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 71/500\n",
            "1/1 - 9s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 72/500\n",
            "1/1 - 9s - loss: 0.2326 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 73/500\n",
            "1/1 - 9s - loss: 0.2334 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 74/500\n",
            "1/1 - 9s - loss: 0.2322 - accuracy: 1.0000 - val_loss: 0.8511 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 75/500\n",
            "1/1 - 9s - loss: 0.2324 - accuracy: 1.0000 - val_loss: 0.7974 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 76/500\n",
            "1/1 - 9s - loss: 0.2323 - accuracy: 1.0000 - val_loss: 0.8269 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 77/500\n",
            "1/1 - 9s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 78/500\n",
            "1/1 - 9s - loss: 0.2322 - accuracy: 1.0000 - val_loss: 0.8897 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 79/500\n",
            "1/1 - 9s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 0.7591 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 80/500\n",
            "1/1 - 9s - loss: 0.2311 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 81/500\n",
            "1/1 - 9s - loss: 0.2305 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 82/500\n",
            "1/1 - 9s - loss: 0.2318 - accuracy: 1.0000 - val_loss: 0.9099 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 83/500\n",
            "1/1 - 9s - loss: 0.2310 - accuracy: 1.0000 - val_loss: 0.9364 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 84/500\n",
            "1/1 - 9s - loss: 0.2315 - accuracy: 1.0000 - val_loss: 1.0185 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 85/500\n",
            "1/1 - 9s - loss: 0.2310 - accuracy: 1.0000 - val_loss: 0.8428 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 86/500\n",
            "1/1 - 9s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 87/500\n",
            "1/1 - 9s - loss: 0.2305 - accuracy: 1.0000 - val_loss: 0.8160 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 88/500\n",
            "1/1 - 9s - loss: 0.2307 - accuracy: 1.0000 - val_loss: 0.8054 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 89/500\n",
            "1/1 - 9s - loss: 0.2306 - accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 90/500\n",
            "1/1 - 9s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 91/500\n",
            "1/1 - 9s - loss: 0.2291 - accuracy: 1.0000 - val_loss: 0.9938 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 92/500\n",
            "1/1 - 9s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 1.1848 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 93/500\n",
            "1/1 - 9s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 94/500\n",
            "1/1 - 9s - loss: 0.2301 - accuracy: 1.0000 - val_loss: 0.8500 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 95/500\n",
            "1/1 - 9s - loss: 0.2296 - accuracy: 1.0000 - val_loss: 1.0725 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 96/500\n",
            "1/1 - 9s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 1.0362 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 97/500\n",
            "1/1 - 9s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 0.8161 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 98/500\n",
            "1/1 - 9s - loss: 0.2295 - accuracy: 1.0000 - val_loss: 1.0586 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 99/500\n",
            "1/1 - 9s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 100/500\n",
            "1/1 - 9s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 101/500\n",
            "1/1 - 9s - loss: 0.2278 - accuracy: 1.0000 - val_loss: 1.1440 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 102/500\n",
            "1/1 - 9s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 103/500\n",
            "1/1 - 9s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 0.6674 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 104/500\n",
            "1/1 - 9s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 105/500\n",
            "1/1 - 9s - loss: 0.2276 - accuracy: 1.0000 - val_loss: 0.8331 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 106/500\n",
            "1/1 - 9s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.9622 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 107/500\n",
            "1/1 - 9s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 108/500\n",
            "1/1 - 9s - loss: 0.2274 - accuracy: 1.0000 - val_loss: 0.7312 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 109/500\n",
            "1/1 - 11s - loss: 0.2279 - accuracy: 1.0000 - val_loss: 0.6002 - val_accuracy: 0.9167 - 11s/epoch - 11s/step\n",
            "Epoch 110/500\n",
            "1/1 - 10s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.6667 - 10s/epoch - 10s/step\n",
            "Epoch 111/500\n",
            "1/1 - 9s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 112/500\n",
            "1/1 - 9s - loss: 0.2277 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 113/500\n",
            "1/1 - 9s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 0.7357 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 114/500\n",
            "1/1 - 9s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 0.6656 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 115/500\n",
            "1/1 - 9s - loss: 0.2271 - accuracy: 1.0000 - val_loss: 0.8615 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 116/500\n",
            "1/1 - 9s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.9875 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 117/500\n",
            "1/1 - 9s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 1.1401 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 118/500\n",
            "1/1 - 9s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.3838 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 119/500\n",
            "1/1 - 9s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 1.1767 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 120/500\n",
            "1/1 - 9s - loss: 0.2267 - accuracy: 1.0000 - val_loss: 1.2348 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 121/500\n",
            "1/1 - 9s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 122/500\n",
            "1/1 - 9s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 123/500\n",
            "1/1 - 9s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 0.7707 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 124/500\n",
            "1/1 - 9s - loss: 0.2267 - accuracy: 1.0000 - val_loss: 1.0562 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 125/500\n",
            "1/1 - 9s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 126/500\n",
            "1/1 - 9s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.8563 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 127/500\n",
            "1/1 - 9s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.6685 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 128/500\n",
            "1/1 - 9s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 129/500\n",
            "1/1 - 9s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 0.7851 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 130/500\n",
            "1/1 - 9s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 0.8578 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 131/500\n",
            "1/1 - 9s - loss: 0.2257 - accuracy: 1.0000 - val_loss: 0.7140 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 132/500\n",
            "1/1 - 9s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 133/500\n",
            "1/1 - 9s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 134/500\n",
            "1/1 - 9s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 135/500\n",
            "1/1 - 9s - loss: 0.2252 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 136/500\n",
            "1/1 - 9s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 137/500\n",
            "1/1 - 9s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 138/500\n",
            "1/1 - 9s - loss: 0.2240 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 139/500\n",
            "1/1 - 9s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 140/500\n",
            "1/1 - 9s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 141/500\n",
            "1/1 - 9s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 142/500\n",
            "1/1 - 9s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.2342 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 143/500\n",
            "1/1 - 9s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.4483 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 144/500\n",
            "1/1 - 9s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.3223 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 145/500\n",
            "1/1 - 9s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.7328 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 146/500\n",
            "1/1 - 9s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 147/500\n",
            "1/1 - 9s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 0.5953 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 148/500\n",
            "1/1 - 9s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 149/500\n",
            "1/1 - 9s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 150/500\n",
            "1/1 - 9s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 0.6197 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 151/500\n",
            "1/1 - 9s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 152/500\n",
            "1/1 - 9s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.8656 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 153/500\n",
            "1/1 - 9s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 154/500\n",
            "1/1 - 9s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 0.5960 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 155/500\n",
            "1/1 - 9s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 156/500\n",
            "1/1 - 9s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 157/500\n",
            "1/1 - 10s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 0.5833 - val_accuracy: 0.9167 - 10s/epoch - 10s/step\n",
            "Epoch 158/500\n",
            "1/1 - 9s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 0.8171 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 159/500\n",
            "1/1 - 9s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 160/500\n",
            "1/1 - 9s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.1325 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 161/500\n",
            "1/1 - 9s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.0901 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 162/500\n",
            "1/1 - 9s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 163/500\n",
            "1/1 - 9s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 164/500\n",
            "1/1 - 9s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.2040 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 165/500\n",
            "1/1 - 9s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 1.3260 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 166/500\n",
            "1/1 - 9s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3618 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 167/500\n",
            "1/1 - 9s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 1.4576 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 168/500\n",
            "1/1 - 9s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.5737 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 169/500\n",
            "1/1 - 9s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.6803 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 170/500\n",
            "1/1 - 9s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.5408 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 171/500\n",
            "1/1 - 9s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.4879 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 172/500\n",
            "1/1 - 9s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.4994 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 173/500\n",
            "1/1 - 9s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.5597 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 174/500\n",
            "1/1 - 9s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.0300 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 175/500\n",
            "1/1 - 9s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.0553 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 176/500\n",
            "1/1 - 9s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 177/500\n",
            "1/1 - 9s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.9362 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 178/500\n",
            "1/1 - 9s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 179/500\n",
            "1/1 - 9s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.8999 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 180/500\n",
            "1/1 - 9s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 181/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8274 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 182/500\n",
            "1/1 - 9s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.7825 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 183/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8293 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 184/500\n",
            "1/1 - 9s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 185/500\n",
            "1/1 - 9s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 186/500\n",
            "1/1 - 9s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 187/500\n",
            "1/1 - 9s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 188/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.5902 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 189/500\n",
            "1/1 - 10s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.9167 - 10s/epoch - 10s/step\n",
            "Epoch 190/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 191/500\n",
            "1/1 - 9s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 192/500\n",
            "1/1 - 9s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.8022 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 193/500\n",
            "1/1 - 9s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 194/500\n",
            "1/1 - 9s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 195/500\n",
            "1/1 - 9s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 196/500\n",
            "1/1 - 9s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 197/500\n",
            "1/1 - 9s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.7455 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 198/500\n",
            "1/1 - 9s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.0089 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 199/500\n",
            "1/1 - 9s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.8823 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 200/500\n",
            "1/1 - 9s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0707 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 201/500\n",
            "1/1 - 9s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.0394 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 202/500\n",
            "1/1 - 9s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 203/500\n",
            "1/1 - 9s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.1676 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 204/500\n",
            "1/1 - 9s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 2.0855 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 205/500\n",
            "1/1 - 9s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 2.6764 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 206/500\n",
            "1/1 - 9s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 207/500\n",
            "1/1 - 9s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.2620 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 208/500\n",
            "1/1 - 9s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.9540 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 209/500\n",
            "1/1 - 9s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 210/500\n",
            "1/1 - 9s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 211/500\n",
            "1/1 - 9s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 212/500\n",
            "1/1 - 9s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.4200 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 213/500\n",
            "1/1 - 9s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.7472 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 214/500\n",
            "1/1 - 9s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.4467 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 215/500\n",
            "1/1 - 9s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.3129 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 216/500\n",
            "1/1 - 9s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 217/500\n",
            "1/1 - 9s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 218/500\n",
            "1/1 - 9s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 219/500\n",
            "1/1 - 9s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.9545 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 220/500\n",
            "1/1 - 9s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.1719 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 221/500\n",
            "1/1 - 9s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.6316 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 222/500\n",
            "1/1 - 9s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 223/500\n",
            "1/1 - 9s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 224/500\n",
            "1/1 - 9s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 225/500\n",
            "1/1 - 9s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.7807 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 226/500\n",
            "1/1 - 9s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.2031 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 227/500\n",
            "1/1 - 9s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.9823 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 228/500\n",
            "1/1 - 9s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 2.3631 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 229/500\n",
            "1/1 - 9s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.7283 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 230/500\n",
            "1/1 - 9s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 231/500\n",
            "1/1 - 9s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.2196 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 232/500\n",
            "1/1 - 9s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 233/500\n",
            "1/1 - 9s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.1336 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 234/500\n",
            "1/1 - 9s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 235/500\n",
            "1/1 - 9s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 236/500\n",
            "1/1 - 9s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.8712 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 237/500\n",
            "1/1 - 9s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 238/500\n",
            "1/1 - 9s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 239/500\n",
            "1/1 - 9s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 0.5775 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 240/500\n",
            "1/1 - 9s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.5774 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 241/500\n",
            "1/1 - 9s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.5736 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 242/500\n",
            "1/1 - 9s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 243/500\n",
            "1/1 - 9s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 244/500\n",
            "1/1 - 9s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 245/500\n",
            "1/1 - 9s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 246/500\n",
            "1/1 - 9s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 247/500\n",
            "1/1 - 9s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.2725 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 248/500\n",
            "1/1 - 9s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.5891 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 249/500\n",
            "1/1 - 9s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 250/500\n",
            "1/1 - 9s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 251/500\n",
            "1/1 - 9s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 252/500\n",
            "1/1 - 9s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.7105 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 253/500\n",
            "1/1 - 9s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 254/500\n",
            "1/1 - 9s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.5656 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 255/500\n",
            "1/1 - 9s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 256/500\n",
            "1/1 - 9s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 257/500\n",
            "1/1 - 9s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 258/500\n",
            "1/1 - 9s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.5868 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 259/500\n",
            "1/1 - 9s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.3530 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 260/500\n",
            "1/1 - 9s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.8508 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 261/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.2566 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 262/500\n",
            "1/1 - 9s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.5696 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 263/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 264/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.4697 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 265/500\n",
            "1/1 - 9s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.4841 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 266/500\n",
            "1/1 - 9s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.4412 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 267/500\n",
            "1/1 - 9s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.1588 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 268/500\n",
            "1/1 - 9s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 269/500\n",
            "1/1 - 9s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 270/500\n",
            "1/1 - 9s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 271/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.0299 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 272/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.4415 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 273/500\n",
            "1/1 - 9s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.1133 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 274/500\n",
            "1/1 - 9s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 275/500\n",
            "1/1 - 9s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.7911 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 276/500\n",
            "1/1 - 9s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 277/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.8027 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 278/500\n",
            "1/1 - 9s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 279/500\n",
            "1/1 - 9s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.2883 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 280/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.6432 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 281/500\n",
            "1/1 - 9s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 282/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 283/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 284/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 285/500\n",
            "1/1 - 9s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 286/500\n",
            "1/1 - 9s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 287/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 288/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 289/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 290/500\n",
            "1/1 - 9s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.5671 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 291/500\n",
            "1/1 - 9s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.7919 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 292/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.7144 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 293/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.2849 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 294/500\n",
            "1/1 - 9s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.5063 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 295/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.6088 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 296/500\n",
            "1/1 - 9s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.2861 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 297/500\n",
            "1/1 - 9s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.6853 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 298/500\n",
            "1/1 - 9s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.7583 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 299/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 2.6649 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 300/500\n",
            "1/1 - 9s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.5562 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 301/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.4580 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 302/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 303/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 304/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.3065 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 305/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.5068 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 306/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.5083 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 307/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.3008 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 308/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.1674 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 309/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.8910 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 310/500\n",
            "1/1 - 9s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.3084 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 311/500\n",
            "1/1 - 9s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.9535 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 312/500\n",
            "1/1 - 9s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 2.2461 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 313/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 314/500\n",
            "1/1 - 9s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 315/500\n",
            "1/1 - 9s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.2513 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 316/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.7788 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 317/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.5978 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 318/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.5146 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 319/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.8663 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 320/500\n",
            "1/1 - 9s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.3121 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 321/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.7304 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 322/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.7237 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 323/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.0372 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 324/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.5887 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 325/500\n",
            "1/1 - 9s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.8378 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 326/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.6785 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 327/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.0545 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 328/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.3045 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 329/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3314 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 330/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 331/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 332/500\n",
            "1/1 - 9s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.1612 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 333/500\n",
            "1/1 - 9s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.9456 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 334/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.3985 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 335/500\n",
            "1/1 - 9s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 336/500\n",
            "1/1 - 9s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.8308 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 337/500\n",
            "1/1 - 9s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9140 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 338/500\n",
            "1/1 - 9s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 339/500\n",
            "1/1 - 9s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.3774 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 340/500\n",
            "1/1 - 9s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.8682 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 341/500\n",
            "1/1 - 9s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.6539 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 342/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.1771 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 343/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.9999 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 344/500\n",
            "1/1 - 9s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.6717 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 345/500\n",
            "1/1 - 9s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.3870 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 346/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.9383 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 347/500\n",
            "1/1 - 10s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 348/500\n",
            "1/1 - 9s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.2236 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 349/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.9061 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 350/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.4409 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 351/500\n",
            "1/1 - 9s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.6330 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 352/500\n",
            "1/1 - 9s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.6529 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 353/500\n",
            "1/1 - 9s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.1197 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 354/500\n",
            "1/1 - 9s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.8132 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 355/500\n",
            "1/1 - 9s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.2755 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 356/500\n",
            "1/1 - 9s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.2342 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 357/500\n",
            "1/1 - 9s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.1626 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 358/500\n",
            "1/1 - 9s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.6337 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 359/500\n",
            "1/1 - 9s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 360/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.2404 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 361/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 362/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.5916 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 363/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.4250 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 364/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.1890 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 365/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 366/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.2460 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 367/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.1504 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 368/500\n",
            "1/1 - 9s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 369/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 370/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9327 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 371/500\n",
            "1/1 - 9s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 372/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.6054 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 373/500\n",
            "1/1 - 9s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 374/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 375/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 376/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.7000 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 377/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.0119 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 378/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 379/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 380/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.6741 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 381/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.8924 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 382/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.4699 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 383/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 384/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 385/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.2220 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 386/500\n",
            "1/1 - 9s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.1094 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 387/500\n",
            "1/1 - 9s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.3435 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 388/500\n",
            "1/1 - 9s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.4345 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 389/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.6758 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 390/500\n",
            "1/1 - 9s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 391/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.5374 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 392/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 393/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.5672 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 394/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 395/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 396/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 397/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.5614 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 398/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.0189 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 399/500\n",
            "1/1 - 9s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.4825 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 400/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.2087 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 401/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 402/500\n",
            "1/1 - 9s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.1132 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 403/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 404/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 405/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.6009 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 406/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 407/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.8270 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 408/500\n",
            "1/1 - 9s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9154 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 409/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 410/500\n",
            "1/1 - 9s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.1313 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 411/500\n",
            "1/1 - 9s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.1685 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 412/500\n",
            "1/1 - 9s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9471 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 413/500\n",
            "1/1 - 9s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 414/500\n",
            "1/1 - 9s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.2510 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 415/500\n",
            "1/1 - 9s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9799 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 416/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 417/500\n",
            "1/1 - 9s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.7501 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 418/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 419/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 420/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 421/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 422/500\n",
            "1/1 - 9s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 423/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 424/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 425/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 426/500\n",
            "1/1 - 9s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.6066 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 427/500\n",
            "1/1 - 9s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 428/500\n",
            "1/1 - 9s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 429/500\n",
            "1/1 - 9s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 430/500\n",
            "1/1 - 9s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 431/500\n",
            "1/1 - 9s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 432/500\n",
            "1/1 - 9s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 433/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.5868 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 434/500\n",
            "1/1 - 9s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.6034 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 435/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 436/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 437/500\n",
            "1/1 - 9s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.5741 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 438/500\n",
            "1/1 - 9s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 439/500\n",
            "1/1 - 9s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.5920 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 440/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 441/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.5979 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 442/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 443/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 444/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 445/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.0074 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 446/500\n",
            "1/1 - 9s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.4478 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 447/500\n",
            "1/1 - 9s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.8455 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 448/500\n",
            "1/1 - 9s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.4287 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 449/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.0472 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 450/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.5112 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 451/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.9663 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 452/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 2.4341 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 453/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.5254 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 454/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 2.7397 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 455/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.2215 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 456/500\n",
            "1/1 - 9s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.3358 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 457/500\n",
            "1/1 - 9s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.0366 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 458/500\n",
            "1/1 - 9s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.1089 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 459/500\n",
            "1/1 - 9s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.9167 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 460/500\n",
            "1/1 - 9s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.4328 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 461/500\n",
            "1/1 - 9s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 462/500\n",
            "1/1 - 9s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 463/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 464/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 465/500\n",
            "1/1 - 9s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.5909 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 466/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.5893 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 467/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 468/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 469/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 470/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 471/500\n",
            "1/1 - 10s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.8333 - 10s/epoch - 10s/step\n",
            "Epoch 472/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 473/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.0646 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 474/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.9482 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 475/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.0811 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 476/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.8848 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 477/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.2595 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 478/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.5001 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 479/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.8346 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 480/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.1002 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 481/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.9233 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 482/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.3671 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 483/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.6583 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 484/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.1156 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 485/500\n",
            "1/1 - 9s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 486/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9184 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 487/500\n",
            "1/1 - 9s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.5297 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 488/500\n",
            "1/1 - 9s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 489/500\n",
            "1/1 - 9s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 490/500\n",
            "1/1 - 9s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 491/500\n",
            "1/1 - 9s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 492/500\n",
            "1/1 - 9s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 493/500\n",
            "1/1 - 9s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 494/500\n",
            "1/1 - 9s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.7606 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 495/500\n",
            "1/1 - 9s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.5436 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 496/500\n",
            "1/1 - 9s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.2612 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 497/500\n",
            "1/1 - 10s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.6182 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 498/500\n",
            "1/1 - 9s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.1588 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 499/500\n",
            "1/1 - 10s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.2124 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 500/500\n",
            "1/1 - 10s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.7129 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Time exp_cmex_3class_model_fold_2 = 4709.716437578201 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_2\n",
            "saved-model-001-0.4167.hdf5\n",
            "Loss=1.2333 y Accuracy=0.4167\n",
            "\n",
            "saved-model-001-0.5833.hdf5\n",
            "Loss=1.2252 y Accuracy=0.5833\n",
            "\n",
            "saved-model-002-0.6667.hdf5\n",
            "Loss=1.1465 y Accuracy=0.6667\n",
            "\n",
            "saved-model-003-0.5000.hdf5\n",
            "Loss=1.2033 y Accuracy=0.5000\n",
            "\n",
            "saved-model-043-0.5833.hdf5\n",
            "Loss=1.1947 y Accuracy=0.5833\n",
            "\n",
            "saved-model-044-0.7500.hdf5\n",
            "Loss=0.9090 y Accuracy=0.7500\n",
            "\n",
            "saved-model-047-0.8333.hdf5\n",
            "Loss=0.8237 y Accuracy=0.8333\n",
            "\n",
            "saved-model-086-0.7500.hdf5\n",
            "Loss=0.8598 y Accuracy=0.7500\n",
            "\n",
            "saved-model-105-0.8333.hdf5\n",
            "Loss=0.7661 y Accuracy=0.8333\n",
            "\n",
            "saved-model-109-0.9167.hdf5\n",
            "Loss=0.6002 y Accuracy=0.9167\n",
            "\n",
            "saved-model-111-0.9167.hdf5\n",
            "Loss=0.5948 y Accuracy=0.9167\n",
            "\n",
            "saved-model-277-1.0000.hdf5\n",
            "Loss=0.3260 y Accuracy=1.0000\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-277-1.0000.hdf5\n",
            "Loss=0.3260 y Accuracy=1.0000\n",
            "\n",
            "Evaluating the best model from fold 2...\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       1.00      1.00      1.00         6\n",
            "     Class_C       1.00      1.00      1.00         4\n",
            "     Class_F       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        12\n",
            "   macro avg       1.00      1.00      1.00        12\n",
            "weighted avg       1.00      1.00      1.00        12\n",
            "\n",
            "Fold 2 - Metrics: {'Fold': 2, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1-Score': 1.0}\n",
            "--- Fold 3/5 ---\n",
            "X_train1_fold: (46, 21)\n",
            "X_test1_fold: (12, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 142s - loss: 2.1822 - accuracy: 0.2174 - val_loss: 1.2683 - val_accuracy: 0.2500 - 142s/epoch - 142s/step\n",
            "Epoch 2/500\n",
            "1/1 - 8s - loss: 1.3541 - accuracy: 0.5435 - val_loss: 1.2524 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 3/500\n",
            "1/1 - 8s - loss: 0.8857 - accuracy: 0.7174 - val_loss: 1.3700 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 4/500\n",
            "1/1 - 9s - loss: 0.9129 - accuracy: 0.7174 - val_loss: 1.8712 - val_accuracy: 0.1667 - 9s/epoch - 9s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.8317 - accuracy: 0.7826 - val_loss: 1.8698 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.6675 - accuracy: 0.8261 - val_loss: 1.8427 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.5719 - accuracy: 0.8913 - val_loss: 1.8225 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.5115 - accuracy: 0.9348 - val_loss: 1.7240 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.5572 - accuracy: 0.9130 - val_loss: 1.6551 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 8s - loss: 0.4821 - accuracy: 0.9348 - val_loss: 1.6698 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.4771 - accuracy: 0.9348 - val_loss: 1.7017 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.4707 - accuracy: 0.9565 - val_loss: 1.6101 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.4222 - accuracy: 0.9565 - val_loss: 1.6650 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3712 - accuracy: 0.9783 - val_loss: 1.6802 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.3913 - accuracy: 0.9783 - val_loss: 1.6798 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.3577 - accuracy: 0.9783 - val_loss: 1.6734 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.3705 - accuracy: 0.9783 - val_loss: 1.6796 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.3608 - accuracy: 0.9783 - val_loss: 1.6836 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.3369 - accuracy: 0.9783 - val_loss: 1.7362 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.3147 - accuracy: 0.9783 - val_loss: 1.8032 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.3199 - accuracy: 1.0000 - val_loss: 1.8683 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.3000 - accuracy: 0.9783 - val_loss: 1.9774 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.3032 - accuracy: 1.0000 - val_loss: 2.0379 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2957 - accuracy: 1.0000 - val_loss: 2.1473 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2821 - accuracy: 1.0000 - val_loss: 2.2582 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2937 - accuracy: 0.9783 - val_loss: 2.3421 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2740 - accuracy: 1.0000 - val_loss: 2.3187 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2653 - accuracy: 1.0000 - val_loss: 2.3303 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2770 - accuracy: 1.0000 - val_loss: 2.3678 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2533 - accuracy: 1.0000 - val_loss: 2.3933 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2711 - accuracy: 0.9783 - val_loss: 2.4167 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2628 - accuracy: 1.0000 - val_loss: 2.4322 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 8s - loss: 0.2610 - accuracy: 1.0000 - val_loss: 2.4112 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2446 - accuracy: 1.0000 - val_loss: 2.3901 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2464 - accuracy: 1.0000 - val_loss: 2.4621 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2473 - accuracy: 1.0000 - val_loss: 2.5473 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 8s - loss: 0.2424 - accuracy: 1.0000 - val_loss: 2.6077 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2429 - accuracy: 1.0000 - val_loss: 2.6323 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 8s - loss: 0.2428 - accuracy: 1.0000 - val_loss: 2.6422 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2405 - accuracy: 1.0000 - val_loss: 2.5447 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2424 - accuracy: 1.0000 - val_loss: 2.4830 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2359 - accuracy: 1.0000 - val_loss: 2.1126 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 8s - loss: 0.2397 - accuracy: 1.0000 - val_loss: 2.1507 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 44/500\n",
            "1/1 - 8s - loss: 0.2391 - accuracy: 1.0000 - val_loss: 2.1468 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 45/500\n",
            "1/1 - 8s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 2.4596 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 46/500\n",
            "1/1 - 8s - loss: 0.2376 - accuracy: 1.0000 - val_loss: 2.7476 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 47/500\n",
            "1/1 - 8s - loss: 0.2338 - accuracy: 1.0000 - val_loss: 2.7862 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2423 - accuracy: 1.0000 - val_loss: 2.8707 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 8s - loss: 0.2332 - accuracy: 1.0000 - val_loss: 2.8237 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 50/500\n",
            "1/1 - 8s - loss: 0.2345 - accuracy: 1.0000 - val_loss: 2.7072 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 51/500\n",
            "1/1 - 8s - loss: 0.2334 - accuracy: 1.0000 - val_loss: 2.8376 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 52/500\n",
            "1/1 - 8s - loss: 0.2334 - accuracy: 1.0000 - val_loss: 2.7641 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 53/500\n",
            "1/1 - 8s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 2.6265 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 54/500\n",
            "1/1 - 8s - loss: 0.2297 - accuracy: 1.0000 - val_loss: 2.5327 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 55/500\n",
            "1/1 - 8s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 2.3882 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 56/500\n",
            "1/1 - 8s - loss: 0.2336 - accuracy: 1.0000 - val_loss: 2.5197 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 57/500\n",
            "1/1 - 8s - loss: 0.2324 - accuracy: 1.0000 - val_loss: 2.7232 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 58/500\n",
            "1/1 - 8s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 2.5748 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 59/500\n",
            "1/1 - 8s - loss: 0.2308 - accuracy: 1.0000 - val_loss: 2.4002 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 60/500\n",
            "1/1 - 8s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 2.0250 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 61/500\n",
            "1/1 - 8s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 1.5699 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 62/500\n",
            "1/1 - 8s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 2.0684 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 63/500\n",
            "1/1 - 8s - loss: 0.2279 - accuracy: 1.0000 - val_loss: 1.5009 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 64/500\n",
            "1/1 - 10s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.2867 - val_accuracy: 0.5000 - 10s/epoch - 10s/step\n",
            "Epoch 65/500\n",
            "1/1 - 8s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 1.6389 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 66/500\n",
            "1/1 - 8s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.5951 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 67/500\n",
            "1/1 - 8s - loss: 0.2274 - accuracy: 1.0000 - val_loss: 1.7359 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 1.7160 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 10s - loss: 0.2269 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.8333 - 10s/epoch - 10s/step\n",
            "Epoch 70/500\n",
            "1/1 - 8s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 1.0103 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 71/500\n",
            "1/1 - 8s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 72/500\n",
            "1/1 - 8s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.9681 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 73/500\n",
            "1/1 - 8s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 74/500\n",
            "1/1 - 8s - loss: 0.2260 - accuracy: 1.0000 - val_loss: 1.7327 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 75/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 2.2026 - val_accuracy: 0.1667 - 8s/epoch - 8s/step\n",
            "Epoch 76/500\n",
            "1/1 - 8s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 2.0546 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 1.2808 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.2830 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 80/500\n",
            "1/1 - 8s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.7694 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 81/500\n",
            "1/1 - 8s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 82/500\n",
            "1/1 - 8s - loss: 0.2258 - accuracy: 1.0000 - val_loss: 1.7716 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 83/500\n",
            "1/1 - 8s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 8s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 86/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.4372 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.9979 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 10s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.9167 - 10s/epoch - 10s/step\n",
            "Epoch 89/500\n",
            "1/1 - 8s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 0.6387 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 0.6076 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 8s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.3621 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 93/500\n",
            "1/1 - 8s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 1.5502 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 0.8133 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 8s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.7435 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 96/500\n",
            "1/1 - 8s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 8s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 99/500\n",
            "1/1 - 8s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 100/500\n",
            "1/1 - 10s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 1.0000 - 10s/epoch - 10s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 0.7653 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 0.8865 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 1.4173 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.9142 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 108/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 109/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 8s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 112/500\n",
            "1/1 - 8s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 115/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.6001 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 125/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.8893 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.7980 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.0220 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 1.2965 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.0705 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.0028 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.6361 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.0588 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.0747 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.3578 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 144/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9464 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 8s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.6942 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 147/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.9251 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.4204 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.3485 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.1500 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.1596 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.9515 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.2344 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.8473 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.8909 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.8176 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 8s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9241 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.4028 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.3189 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 169/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.3025 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 170/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.4892 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.3063 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.2002 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.5874 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.7675 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.6473 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.3932 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.5863 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.8809 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.9560 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.1565 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.9278 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.6988 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.8352 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.8916 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 216/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.4176 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.3385 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.1769 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.0579 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.3246 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 232/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 235/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.6763 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.6160 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.6641 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.3891 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.5675 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.1768 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.5023 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.0467 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.3292 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.7957 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.2179 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.0234 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 256/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 257/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 258/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.2600 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.1561 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.3218 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.1966 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.2884 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1895 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 271/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.1698 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.6862 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 274/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.5827 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.5801 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.7552 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.4169 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.2870 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.4312 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.2998 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.9673 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 304/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.9837 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 305/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.8549 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 306/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.9078 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 2.2524 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.6365 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 309/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.9856 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.0147 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.7394 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.9301 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.0288 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.4969 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 315/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.8740 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.1707 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8726 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.8578 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.0689 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.7970 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.6169 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.5616 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.1995 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.9147 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.2254 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.3917 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.3793 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 335/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.3985 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 336/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.2390 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 337/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8287 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 340/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7374 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.1744 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 353/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 356/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.5930 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.6197 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.5503 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 370/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 371/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 372/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.3084 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 379/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 382/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.7795 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.0395 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.5278 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 385/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.7037 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.5068 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 388/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.6500 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.5816 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.7230 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 395/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.6484 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.1847 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.7133 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.7783 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.9368 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.2368 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.9650 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.7755 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.7997 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 0.7537 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.3006 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.3803 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.2333 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.1119 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 442/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 445/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.2758 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.2786 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 451/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 452/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 453/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 454/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 455/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 456/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.5568 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 457/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 458/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.3055 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 461/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.5771 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 468/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.3243 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 471/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.3118 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 486/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 487/500\n",
            "1/1 - 9s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 490/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 491/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.6135 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 492/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.6056 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 493/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 494/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 495/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 496/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 497/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 1.0000 - 8s/epoch - 8s/step\n",
            "Epoch 498/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 499/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Epoch 500/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9167 - 8s/epoch - 8s/step\n",
            "Time exp_cmex_3class_model_fold_3 = 4208.87186217308 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_3\n",
            "saved-model-001-0.2500.hdf5\n",
            "Loss=1.2683 y Accuracy=0.2500\n",
            "\n",
            "saved-model-001-0.5833.hdf5\n",
            "Loss=1.2250 y Accuracy=0.5833\n",
            "\n",
            "saved-model-002-0.7500.hdf5\n",
            "Loss=1.1575 y Accuracy=0.7500\n",
            "\n",
            "saved-model-032-0.8333.hdf5\n",
            "Loss=1.0994 y Accuracy=0.8333\n",
            "\n",
            "saved-model-054-0.9167.hdf5\n",
            "Loss=0.8174 y Accuracy=0.9167\n",
            "\n",
            "saved-model-064-0.5000.hdf5\n",
            "Loss=1.2867 y Accuracy=0.5000\n",
            "\n",
            "saved-model-069-0.8333.hdf5\n",
            "Loss=0.8574 y Accuracy=0.8333\n",
            "\n",
            "saved-model-088-0.9167.hdf5\n",
            "Loss=0.6047 y Accuracy=0.9167\n",
            "\n",
            "saved-model-088-1.0000.hdf5\n",
            "Loss=0.5568 y Accuracy=1.0000\n",
            "\n",
            "saved-model-100-1.0000.hdf5\n",
            "Loss=0.4951 y Accuracy=1.0000\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-088-1.0000.hdf5\n",
            "Loss=0.5568 y Accuracy=1.0000\n",
            "\n",
            "Evaluating the best model from fold 3...\n",
            "1/1 [==============================] - 10s 10s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       1.00      1.00      1.00         6\n",
            "     Class_C       1.00      1.00      1.00         4\n",
            "     Class_F       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00        12\n",
            "   macro avg       1.00      1.00      1.00        12\n",
            "weighted avg       1.00      1.00      1.00        12\n",
            "\n",
            "Fold 3 - Metrics: {'Fold': 3, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1-Score': 1.0}\n",
            "--- Fold 4/5 ---\n",
            "X_train1_fold: (47, 21)\n",
            "X_test1_fold: (11, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 148s - loss: 2.0422 - accuracy: 0.2979 - val_loss: 1.2657 - val_accuracy: 0.4545 - 148s/epoch - 148s/step\n",
            "Epoch 2/500\n",
            "1/1 - 8s - loss: 1.1176 - accuracy: 0.6383 - val_loss: 1.2710 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 3/500\n",
            "1/1 - 8s - loss: 0.9372 - accuracy: 0.7234 - val_loss: 1.3127 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 4/500\n",
            "1/1 - 8s - loss: 0.7345 - accuracy: 0.8298 - val_loss: 1.2971 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.6433 - accuracy: 0.8085 - val_loss: 1.3163 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.5908 - accuracy: 0.8723 - val_loss: 1.3286 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.5375 - accuracy: 0.8936 - val_loss: 1.3347 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.4851 - accuracy: 0.9574 - val_loss: 1.3326 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.4642 - accuracy: 0.9149 - val_loss: 1.3320 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 9s - loss: 0.4461 - accuracy: 0.9574 - val_loss: 1.3423 - val_accuracy: 0.2727 - 9s/epoch - 9s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.4480 - accuracy: 0.9574 - val_loss: 1.3355 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.4163 - accuracy: 0.9787 - val_loss: 1.3293 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.3802 - accuracy: 0.9787 - val_loss: 1.3245 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3299 - accuracy: 1.0000 - val_loss: 1.3228 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.3763 - accuracy: 0.9787 - val_loss: 1.3232 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.3514 - accuracy: 0.9787 - val_loss: 1.3227 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.3107 - accuracy: 0.9787 - val_loss: 1.3223 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.3206 - accuracy: 0.9787 - val_loss: 1.3206 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.2976 - accuracy: 1.0000 - val_loss: 1.3193 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.2941 - accuracy: 1.0000 - val_loss: 1.3209 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.2932 - accuracy: 1.0000 - val_loss: 1.3176 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.2993 - accuracy: 1.0000 - val_loss: 1.3172 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.2895 - accuracy: 1.0000 - val_loss: 1.3179 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2761 - accuracy: 1.0000 - val_loss: 1.3205 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2871 - accuracy: 0.9787 - val_loss: 1.3172 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2969 - accuracy: 0.9787 - val_loss: 1.3215 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2606 - accuracy: 1.0000 - val_loss: 1.3205 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2580 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2667 - accuracy: 1.0000 - val_loss: 1.3139 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2623 - accuracy: 1.0000 - val_loss: 1.3066 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2569 - accuracy: 1.0000 - val_loss: 1.2973 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2538 - accuracy: 1.0000 - val_loss: 1.2850 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 11s - loss: 0.2518 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.5455 - 11s/epoch - 11s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2534 - accuracy: 1.0000 - val_loss: 1.2749 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2496 - accuracy: 1.0000 - val_loss: 1.2736 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2540 - accuracy: 1.0000 - val_loss: 1.2666 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 8s - loss: 0.2483 - accuracy: 1.0000 - val_loss: 1.2670 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2478 - accuracy: 1.0000 - val_loss: 1.2410 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 8s - loss: 0.2484 - accuracy: 1.0000 - val_loss: 1.1976 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2472 - accuracy: 1.0000 - val_loss: 1.1841 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2437 - accuracy: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2428 - accuracy: 1.0000 - val_loss: 1.2469 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 8s - loss: 0.2411 - accuracy: 1.0000 - val_loss: 1.2613 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 44/500\n",
            "1/1 - 8s - loss: 0.2411 - accuracy: 1.0000 - val_loss: 1.2163 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 45/500\n",
            "1/1 - 8s - loss: 0.2446 - accuracy: 1.0000 - val_loss: 1.2027 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 46/500\n",
            "1/1 - 8s - loss: 0.2383 - accuracy: 1.0000 - val_loss: 1.2244 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 47/500\n",
            "1/1 - 8s - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2401 - accuracy: 1.0000 - val_loss: 1.1406 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 8s - loss: 0.2356 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 50/500\n",
            "1/1 - 9s - loss: 0.2355 - accuracy: 1.0000 - val_loss: 1.0901 - val_accuracy: 0.4545 - 9s/epoch - 9s/step\n",
            "Epoch 51/500\n",
            "1/1 - 8s - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.0617 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 52/500\n",
            "1/1 - 8s - loss: 0.2365 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 53/500\n",
            "1/1 - 8s - loss: 0.2341 - accuracy: 1.0000 - val_loss: 1.1762 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 54/500\n",
            "1/1 - 10s - loss: 0.2363 - accuracy: 1.0000 - val_loss: 1.1049 - val_accuracy: 0.7273 - 10s/epoch - 10s/step\n",
            "Epoch 55/500\n",
            "1/1 - 9s - loss: 0.2352 - accuracy: 1.0000 - val_loss: 1.1172 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 56/500\n",
            "1/1 - 8s - loss: 0.2332 - accuracy: 1.0000 - val_loss: 1.1213 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 57/500\n",
            "1/1 - 8s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 58/500\n",
            "1/1 - 8s - loss: 0.2339 - accuracy: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 59/500\n",
            "1/1 - 8s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 60/500\n",
            "1/1 - 8s - loss: 0.2335 - accuracy: 1.0000 - val_loss: 0.9723 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 61/500\n",
            "1/1 - 8s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 1.0918 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 62/500\n",
            "1/1 - 8s - loss: 0.2322 - accuracy: 1.0000 - val_loss: 1.1155 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 63/500\n",
            "1/1 - 8s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 1.0900 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 64/500\n",
            "1/1 - 10s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.0523 - val_accuracy: 0.8182 - 10s/epoch - 10s/step\n",
            "Epoch 65/500\n",
            "1/1 - 8s - loss: 0.2286 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 66/500\n",
            "1/1 - 8s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 0.9690 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 67/500\n",
            "1/1 - 8s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 0.9894 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.1002 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 8s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 1.0685 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 70/500\n",
            "1/1 - 8s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 1.1355 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 71/500\n",
            "1/1 - 8s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 1.1048 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 72/500\n",
            "1/1 - 8s - loss: 0.2286 - accuracy: 1.0000 - val_loss: 1.0904 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 73/500\n",
            "1/1 - 8s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 74/500\n",
            "1/1 - 8s - loss: 0.2297 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 75/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.0579 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 76/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.1673 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2276 - accuracy: 1.0000 - val_loss: 1.3707 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.2728 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 80/500\n",
            "1/1 - 8s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 1.2299 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 81/500\n",
            "1/1 - 8s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 82/500\n",
            "1/1 - 8s - loss: 0.2267 - accuracy: 1.0000 - val_loss: 1.2848 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 83/500\n",
            "1/1 - 8s - loss: 0.2257 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 1.0995 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 8s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 0.9972 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 86/500\n",
            "1/1 - 8s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 0.9334 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 8s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 0.8943 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 89/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.0570 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 8s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.2668 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 93/500\n",
            "1/1 - 8s - loss: 0.2258 - accuracy: 1.0000 - val_loss: 1.1840 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2253 - accuracy: 1.0000 - val_loss: 1.1894 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.2325 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 96/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.0018 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.8698 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 8s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.1301 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 99/500\n",
            "1/1 - 8s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 0.9452 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 100/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.0732 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 8s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.8030 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 0.7990 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 0.9270 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 8s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.8411 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 0.9138 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 108/500\n",
            "1/1 - 8s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.0111 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 109/500\n",
            "1/1 - 8s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.0238 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.1497 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 8s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.2573 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 112/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.1708 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.0724 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 8s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 115/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.1260 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3388 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.1368 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 0.9500 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 0.8416 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.8917 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.7897 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 125/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.3520 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.8038 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.8528 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.8052 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.9622 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.8065 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.8373 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.7929 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.3179 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 1.1294 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.1367 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 11s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.8158 - val_accuracy: 0.9091 - 11s/epoch - 11s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.8504 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 1.0250 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.9033 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 0.7975 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 144/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.8828 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.1492 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 147/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.9857 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.0951 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.4044 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.8084 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.5236 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.1699 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.1236 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.1285 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.1891 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.3191 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.6345 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.9617 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 2.0311 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.8423 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.9612 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.5912 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.3275 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.6319 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.4658 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.3759 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 169/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.1221 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 170/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.1388 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.1602 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.0403 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 0.9401 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.2526 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.2182 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.3568 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.3229 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.0891 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.4150 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.6407 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.9752 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 2.4250 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.8822 - val_accuracy: 0.3636 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.4999 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.3155 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.0813 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.1539 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0532 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.9153 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 0.9063 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.9139 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.9329 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.9469 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.5134 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.5588 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.7462 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.9361 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 216/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.4906 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.3319 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.7377 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.4185 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.2608 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.3533 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.1915 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.1157 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.0239 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.1331 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.0731 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.1993 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.5186 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 232/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.5344 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.2208 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.3199 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 235/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.3648 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.0234 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.2048 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.7931 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.9355 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8044 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.3113 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.8227 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.0932 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 2.0269 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.6753 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.6340 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 9s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.9728 - val_accuracy: 0.6364 - 9s/epoch - 9s/step\n",
            "Epoch 256/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8408 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 257/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 258/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.8631 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.8722 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.7803 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.7499 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.8019 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.8517 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.9712 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.2426 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.3898 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 271/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.4673 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.7280 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 274/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.6831 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.8347 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 9s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.3601 - val_accuracy: 0.6364 - 9s/epoch - 9s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.3176 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.2920 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.0877 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.1070 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.1993 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9808 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0178 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0596 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.9469 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.8832 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.8709 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.8223 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8526 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.8442 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 304/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 305/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 306/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.9118 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 309/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.1261 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.0102 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.0670 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.7955 - val_accuracy: 0.7273 - 9s/epoch - 9s/step\n",
            "Epoch 315/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 0.6956 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.7717 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.8727 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7913 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8285 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.0437 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.2555 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.9353 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.7865 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.9285 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.7806 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8301 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.9064 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.9861 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.3161 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.3806 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 335/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.3441 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 336/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.2029 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 337/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 340/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8421 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8545 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9789 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.1202 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4898 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.4560 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8404 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.8620 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.4809 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.7083 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 353/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.7186 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.8027 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.7717 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 356/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.7764 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.7385 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.0238 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.9397 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.2079 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.5683 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.2255 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.9461 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.5021 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.3179 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.7580 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.1941 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.8151 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.6300 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 370/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.3821 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 371/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 372/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.0677 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.3030 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3999 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.4861 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3746 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.2149 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 379/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.9673 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 382/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.8372 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.9179 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 385/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.8479 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.8580 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.9545 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 388/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.8673 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.9164 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.8713 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.8668 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.8333 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 395/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 0.8858 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.0583 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0525 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1145 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.1457 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.2314 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.3117 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.2393 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.8866 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.7886 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 0.8542 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.1686 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.3758 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.2571 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 0.8768 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.0330 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.2601 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.0773 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.9437 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.0760 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.8768 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.9085 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.4988 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.6502 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.7698 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.6910 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.8370 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.8049 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.5602 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.6881 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.8784 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.1416 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.1446 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.9415 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.2537 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.3666 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 442/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.3750 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.5336 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.0411 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 445/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.0467 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.0705 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.3724 - val_accuracy: 0.5455 - 9s/epoch - 9s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.6484 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.6613 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.6241 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 451/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.2673 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 452/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.2529 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 453/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.1479 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 454/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.2964 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 455/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.1054 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 456/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.1263 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 457/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.2233 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 458/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.0057 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.9827 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.4887 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 461/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.2387 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.0591 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9997 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9514 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 468/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.8701 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.8997 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.9739 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 471/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.1298 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.9976 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.9196 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.9139 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 0.9363 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.9853 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.3711 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.2799 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4877 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.2972 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 486/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.2266 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 487/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4724 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.3642 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.5274 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 490/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.9084 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 491/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.8023 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 492/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.5763 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 493/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.2699 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 494/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 495/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.2740 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 496/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.6179 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 497/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.0818 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 498/500\n",
            "1/1 - 9s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.0704 - val_accuracy: 0.7273 - 9s/epoch - 9s/step\n",
            "Epoch 499/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 500/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.9676 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Time exp_cmex_3class_model_fold_4 = 4240.761803865433 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_4\n",
            "saved-model-001-0.4545.hdf5\n",
            "Loss=1.2657 y Accuracy=0.4545\n",
            "\n",
            "saved-model-033-0.5455.hdf5\n",
            "Loss=1.2780 y Accuracy=0.5455\n",
            "\n",
            "saved-model-054-0.7273.hdf5\n",
            "Loss=1.1049 y Accuracy=0.7273\n",
            "\n",
            "saved-model-064-0.8182.hdf5\n",
            "Loss=1.0523 y Accuracy=0.8182\n",
            "\n",
            "saved-model-137-0.9091.hdf5\n",
            "Loss=0.8158 y Accuracy=0.9091\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-137-0.9091.hdf5\n",
            "Loss=0.8158 y Accuracy=0.9091\n",
            "\n",
            "Evaluating the best model from fold 4...\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       1.00      0.80      0.89         5\n",
            "     Class_C       1.00      1.00      1.00         3\n",
            "     Class_F       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.91        11\n",
            "   macro avg       0.92      0.93      0.92        11\n",
            "weighted avg       0.93      0.91      0.91        11\n",
            "\n",
            "Fold 4 - Metrics: {'Fold': 4, 'Accuracy': 0.9090909090909091, 'Precision': 0.9318181818181818, 'Recall': 0.9090909090909091, 'F1-Score': 0.9105339105339105}\n",
            "--- Fold 5/5 ---\n",
            "X_train1_fold: (47, 21)\n",
            "X_test1_fold: (11, 21)\n",
            "Ultima capa input b(None, 10, 128)\n",
            "Ultima capa input a(None, 14, 14, 512)\n",
            "(None, 14, 14, 512)\n",
            "layer: (None, 10, 128)\n",
            "encoded_patches: (None, 1, 128)\n",
            "attn_1_to_2: (None, 10, 128)\n",
            "attn_2_to_1: (None, 1, 128)\n",
            "(None, 11, 128)\n",
            "Transformer_create\n",
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 135s - loss: 1.8446 - accuracy: 0.4043 - val_loss: 1.2892 - val_accuracy: 0.4545 - 135s/epoch - 135s/step\n",
            "Epoch 2/500\n",
            "1/1 - 11s - loss: 1.1742 - accuracy: 0.5957 - val_loss: 1.2647 - val_accuracy: 0.5455 - 11s/epoch - 11s/step\n",
            "Epoch 3/500\n",
            "1/1 - 8s - loss: 0.9017 - accuracy: 0.7021 - val_loss: 1.2666 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 4/500\n",
            "1/1 - 8s - loss: 0.7793 - accuracy: 0.8085 - val_loss: 1.2967 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 5/500\n",
            "1/1 - 8s - loss: 0.6243 - accuracy: 0.8723 - val_loss: 1.3229 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.5188 - accuracy: 0.9149 - val_loss: 1.3116 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 8s - loss: 0.4635 - accuracy: 0.9574 - val_loss: 1.3380 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 8/500\n",
            "1/1 - 8s - loss: 0.3923 - accuracy: 1.0000 - val_loss: 1.4002 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 9/500\n",
            "1/1 - 8s - loss: 0.4473 - accuracy: 0.9362 - val_loss: 1.4064 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 10/500\n",
            "1/1 - 8s - loss: 0.3603 - accuracy: 0.9787 - val_loss: 1.3893 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.3928 - accuracy: 0.9574 - val_loss: 1.4193 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 8s - loss: 0.3408 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 13/500\n",
            "1/1 - 8s - loss: 0.3199 - accuracy: 1.0000 - val_loss: 1.2890 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 14/500\n",
            "1/1 - 8s - loss: 0.3061 - accuracy: 1.0000 - val_loss: 1.3737 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 15/500\n",
            "1/1 - 8s - loss: 0.3473 - accuracy: 0.9787 - val_loss: 1.4793 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.2857 - accuracy: 1.0000 - val_loss: 1.4914 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 8s - loss: 0.2836 - accuracy: 1.0000 - val_loss: 1.5060 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 18/500\n",
            "1/1 - 8s - loss: 0.2857 - accuracy: 1.0000 - val_loss: 1.4926 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 19/500\n",
            "1/1 - 8s - loss: 0.2851 - accuracy: 1.0000 - val_loss: 1.5704 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 20/500\n",
            "1/1 - 8s - loss: 0.2851 - accuracy: 1.0000 - val_loss: 1.9978 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 21/500\n",
            "1/1 - 8s - loss: 0.2690 - accuracy: 1.0000 - val_loss: 2.1749 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 22/500\n",
            "1/1 - 8s - loss: 0.2819 - accuracy: 1.0000 - val_loss: 2.3006 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 23/500\n",
            "1/1 - 8s - loss: 0.2612 - accuracy: 1.0000 - val_loss: 2.4461 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 24/500\n",
            "1/1 - 8s - loss: 0.2680 - accuracy: 1.0000 - val_loss: 2.3835 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 25/500\n",
            "1/1 - 8s - loss: 0.2520 - accuracy: 1.0000 - val_loss: 2.3712 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 26/500\n",
            "1/1 - 8s - loss: 0.2534 - accuracy: 1.0000 - val_loss: 2.4102 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 27/500\n",
            "1/1 - 8s - loss: 0.2475 - accuracy: 1.0000 - val_loss: 2.4952 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 28/500\n",
            "1/1 - 8s - loss: 0.2516 - accuracy: 1.0000 - val_loss: 2.4282 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 29/500\n",
            "1/1 - 8s - loss: 0.2476 - accuracy: 1.0000 - val_loss: 2.5574 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 30/500\n",
            "1/1 - 8s - loss: 0.2455 - accuracy: 1.0000 - val_loss: 2.3443 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 31/500\n",
            "1/1 - 8s - loss: 0.2440 - accuracy: 1.0000 - val_loss: 2.3063 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 32/500\n",
            "1/1 - 8s - loss: 0.2481 - accuracy: 1.0000 - val_loss: 1.8976 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 33/500\n",
            "1/1 - 8s - loss: 0.2404 - accuracy: 1.0000 - val_loss: 1.5318 - val_accuracy: 0.2727 - 8s/epoch - 8s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2441 - accuracy: 1.0000 - val_loss: 1.2681 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 8s - loss: 0.2382 - accuracy: 1.0000 - val_loss: 1.0475 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 36/500\n",
            "1/1 - 10s - loss: 0.2413 - accuracy: 1.0000 - val_loss: 0.9762 - val_accuracy: 0.6364 - 10s/epoch - 10s/step\n",
            "Epoch 37/500\n",
            "1/1 - 10s - loss: 0.2394 - accuracy: 1.0000 - val_loss: 0.9298 - val_accuracy: 0.7273 - 10s/epoch - 10s/step\n",
            "Epoch 38/500\n",
            "1/1 - 8s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 0.9256 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 39/500\n",
            "1/1 - 10s - loss: 0.2361 - accuracy: 1.0000 - val_loss: 0.9127 - val_accuracy: 0.8182 - 10s/epoch - 10s/step\n",
            "Epoch 40/500\n",
            "1/1 - 8s - loss: 0.2344 - accuracy: 1.0000 - val_loss: 1.0035 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 41/500\n",
            "1/1 - 8s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 0.9720 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 42/500\n",
            "1/1 - 8s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 1.0008 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 43/500\n",
            "1/1 - 8s - loss: 0.2315 - accuracy: 1.0000 - val_loss: 1.0546 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 44/500\n",
            "1/1 - 8s - loss: 0.2345 - accuracy: 1.0000 - val_loss: 0.9478 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 45/500\n",
            "1/1 - 8s - loss: 0.2311 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 46/500\n",
            "1/1 - 8s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 47/500\n",
            "1/1 - 8s - loss: 0.2352 - accuracy: 1.0000 - val_loss: 0.8811 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2331 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 8s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 0.8620 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 50/500\n",
            "1/1 - 8s - loss: 0.2318 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 51/500\n",
            "1/1 - 8s - loss: 0.2320 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 52/500\n",
            "1/1 - 8s - loss: 0.2328 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 53/500\n",
            "1/1 - 8s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 54/500\n",
            "1/1 - 8s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 0.8622 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 55/500\n",
            "1/1 - 8s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 56/500\n",
            "1/1 - 8s - loss: 0.2285 - accuracy: 1.0000 - val_loss: 0.8652 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 57/500\n",
            "1/1 - 8s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 0.8699 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 58/500\n",
            "1/1 - 8s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 59/500\n",
            "1/1 - 8s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 0.9279 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 60/500\n",
            "1/1 - 8s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 61/500\n",
            "1/1 - 8s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 62/500\n",
            "1/1 - 8s - loss: 0.2269 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 63/500\n",
            "1/1 - 8s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 64/500\n",
            "1/1 - 8s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.9541 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 65/500\n",
            "1/1 - 8s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 66/500\n",
            "1/1 - 8s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 67/500\n",
            "1/1 - 8s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.0263 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.0275 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 8s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.0667 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 70/500\n",
            "1/1 - 8s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.1124 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 71/500\n",
            "1/1 - 8s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.1340 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 72/500\n",
            "1/1 - 8s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.0989 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 73/500\n",
            "1/1 - 8s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 74/500\n",
            "1/1 - 8s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 75/500\n",
            "1/1 - 8s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 76/500\n",
            "1/1 - 8s - loss: 0.2273 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 1.0417 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.1051 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 8s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 1.1224 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 80/500\n",
            "1/1 - 8s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 1.0428 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 81/500\n",
            "1/1 - 8s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 82/500\n",
            "1/1 - 8s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.0796 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 83/500\n",
            "1/1 - 8s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 8s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 86/500\n",
            "1/1 - 8s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.2097 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.2415 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 8s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.1984 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 89/500\n",
            "1/1 - 8s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.1834 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.1512 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.1487 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 8s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.0919 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 93/500\n",
            "1/1 - 8s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.1383 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 8s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.2486 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 96/500\n",
            "1/1 - 8s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 8s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.0808 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 99/500\n",
            "1/1 - 8s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 1.1875 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 100/500\n",
            "1/1 - 8s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.2140 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.2660 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 8s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.0280 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.0632 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.0530 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 8s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.0236 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 108/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.0222 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 109/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.0348 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.0892 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.1748 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 112/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.0838 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.0445 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.8953 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 115/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.1072 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.1243 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 8s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 1.2394 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3201 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.2928 - val_accuracy: 0.4545 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.2040 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.2231 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.1356 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.9874 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 125/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.0048 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.9067 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.8486 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.0608 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.1596 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 1.1775 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.2443 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 8s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.2122 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.1794 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.1450 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 144/500\n",
            "1/1 - 8s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.0589 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 147/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.9432 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.0785 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.0908 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0833 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9366 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.7692 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0432 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.0798 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.0440 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.0697 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.0451 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.1444 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.2264 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.2624 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.3099 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.2326 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 169/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.1871 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 170/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.1312 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.9899 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 0.9898 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.0700 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.0568 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.2112 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.2539 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.2108 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.2134 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.2233 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.2409 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.1716 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.0011 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.9153 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.0313 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.0688 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0617 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.1034 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.1216 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.0480 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9865 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.0282 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.3906 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.5525 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.3561 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.1208 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.0784 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0010 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.9275 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9015 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.0603 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.0535 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 216/500\n",
            "1/1 - 8s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.1741 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.1982 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.2293 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.9940 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.1126 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.0886 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.1271 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.0819 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.0458 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1953 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.2248 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.1709 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.0316 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 232/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1838 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 235/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.2573 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.0366 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.0973 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.9737 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.1722 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.1464 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1477 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.2294 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.3056 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.2800 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.3171 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.1800 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.9367 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.0738 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.1246 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.1351 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 256/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.0760 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 257/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.8741 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 258/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.8605 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.9746 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.0114 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9403 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.8992 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.8554 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0273 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.1304 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 271/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.1385 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.0782 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 274/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.0646 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.1550 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.1831 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2282 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 8s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.2794 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.3462 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.3300 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.1204 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.2448 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.0233 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.0802 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2073 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2146 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2680 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.3204 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.3494 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.4397 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.3947 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.3078 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.2063 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.1704 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.1566 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.1389 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.1292 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 304/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.1693 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 305/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.1758 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 306/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.1355 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 309/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.1279 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.0937 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.7486 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.8351 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 315/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.1059 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8853 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.9439 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.9879 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.1583 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.3430 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.4561 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.4335 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.4841 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.5472 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.4749 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.5154 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.4569 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4376 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.5578 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.4881 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.3235 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.3068 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 335/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.9274 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 336/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.8384 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 337/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7814 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7480 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 10s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.9091 - 10s/epoch - 10s/step\n",
            "Epoch 340/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8079 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.9504 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.1636 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.2380 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 353/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.0353 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.0301 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.2847 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 356/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4621 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.5521 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.5378 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.4415 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4206 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3372 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4306 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.4279 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.4820 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.9832 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.7146 - val_accuracy: 0.5455 - 8s/epoch - 8s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3116 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3896 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 370/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 371/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.0782 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 372/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2272 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.5313 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 379/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.5033 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.4518 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.3395 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 382/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2206 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.2033 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 385/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2214 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.2319 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.2592 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 388/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.1286 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.1111 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.1273 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.2708 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 395/500\n",
            "1/1 - 9s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.7273 - 9s/epoch - 9s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.1518 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.0756 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.1928 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.1976 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.3893 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.4145 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.5402 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.3466 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.3407 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.2684 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 8s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.1986 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.2886 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2589 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.2856 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.3847 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.4409 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.3399 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.4086 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.3942 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.3956 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2500 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.2273 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.2397 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.3692 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.2628 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.0453 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 8s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.1788 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.7827 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.0795 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.0388 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.0715 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.5953 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.2139 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.3179 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.2614 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.4031 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.2540 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.2215 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.2216 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.2145 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 442/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.9149 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8491 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 8s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.8751 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 445/500\n",
            "1/1 - 8s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.8760 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.1356 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.1883 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 9s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.7273 - 9s/epoch - 9s/step\n",
            "Epoch 451/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.3459 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 452/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.5719 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 453/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.5071 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 454/500\n",
            "1/1 - 8s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.4693 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 455/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 456/500\n",
            "1/1 - 9s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.4205 - val_accuracy: 0.6364 - 9s/epoch - 9s/step\n",
            "Epoch 457/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4484 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 458/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.4967 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.6130 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.5491 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 461/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.2798 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.0034 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 8s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.1682 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.2626 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.1243 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 8s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 468/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.0877 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.1567 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 8s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.3126 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 471/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.3992 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 8s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.3765 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.3531 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.4454 - val_accuracy: 0.7273 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 8s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4553 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.4041 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.0654 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.3294 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.4302 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.4581 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.4864 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.3121 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.8213 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 486/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.7304 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 487/500\n",
            "1/1 - 8s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.7001 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.6413 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.9091 - 8s/epoch - 8s/step\n",
            "Epoch 490/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 491/500\n",
            "1/1 - 8s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 492/500\n",
            "1/1 - 8s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 493/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 494/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 495/500\n",
            "1/1 - 8s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 0.9570 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 496/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 497/500\n",
            "1/1 - 8s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 0.9714 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 498/500\n",
            "1/1 - 8s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 0.8915 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 499/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 0.9583 - val_accuracy: 0.8182 - 8s/epoch - 8s/step\n",
            "Epoch 500/500\n",
            "1/1 - 8s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.2242 - val_accuracy: 0.6364 - 8s/epoch - 8s/step\n",
            "Time exp_cmex_3class_model_fold_5 = 4190.022245883942 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/exp_cmex_3class_model_fold_5\n",
            "saved-model-001-0.4545.hdf5\n",
            "Loss=1.2892 y Accuracy=0.4545\n",
            "\n",
            "saved-model-002-0.5455.hdf5\n",
            "Loss=1.2647 y Accuracy=0.5455\n",
            "\n",
            "saved-model-036-0.6364.hdf5\n",
            "Loss=0.9762 y Accuracy=0.6364\n",
            "\n",
            "saved-model-037-0.7273.hdf5\n",
            "Loss=0.9298 y Accuracy=0.7273\n",
            "\n",
            "saved-model-039-0.8182.hdf5\n",
            "Loss=0.9127 y Accuracy=0.8182\n",
            "\n",
            "saved-model-339-0.9091.hdf5\n",
            "Loss=0.7016 y Accuracy=0.9091\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-339-0.9091.hdf5\n",
            "Loss=0.7016 y Accuracy=0.9091\n",
            "\n",
            "Evaluating the best model from fold 5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7905a33a4ae0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 11s 11s/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class_A       0.83      1.00      0.91         5\n",
            "     Class_C       1.00      1.00      1.00         3\n",
            "     Class_F       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.91        11\n",
            "   macro avg       0.94      0.89      0.90        11\n",
            "weighted avg       0.92      0.91      0.90        11\n",
            "\n",
            "Fold 5 - Metrics: {'Fold': 5, 'Accuracy': 0.9090909090909091, 'Precision': 0.9242424242424243, 'Recall': 0.9090909090909091, 'F1-Score': 0.9041322314049587}\n",
            "\n",
            "--- Cross-Validation Results ---\n",
            "   Fold  Accuracy  Precision    Recall  F1-Score\n",
            "0     1  0.916667   0.928571  0.916667  0.911538\n",
            "1     2  1.000000   1.000000  1.000000  1.000000\n",
            "2     3  1.000000   1.000000  1.000000  1.000000\n",
            "3     4  0.909091   0.931818  0.909091  0.910534\n",
            "4     5  0.909091   0.924242  0.909091  0.904132\n",
            "\n",
            "Mean Metrics:\n",
            "Fold         3.000000\n",
            "Accuracy     0.946970\n",
            "Precision    0.956926\n",
            "Recall       0.946970\n",
            "F1-Score     0.945241\n",
            "dtype: float64\n",
            "\n",
            "Standard Deviation Metrics:\n",
            "Fold         1.581139\n",
            "Accuracy     0.048509\n",
            "Precision    0.039412\n",
            "Recall       0.048509\n",
            "F1-Score     0.050069\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HOwLcJxkDTu"
      },
      "source": [
        "# Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIywdt6umllp",
        "outputId": "213d6b6c-448d-484d-868b-6488e4721c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 133s - loss: 2.0701 - accuracy: 0.2826 - val_loss: 1.3069 - val_accuracy: 0.5000 - 133s/epoch - 133s/step\n",
            "Epoch 2/500\n",
            "1/1 - 7s - loss: 1.6061 - accuracy: 0.4348 - val_loss: 1.2758 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 3/500\n",
            "1/1 - 7s - loss: 0.9846 - accuracy: 0.6739 - val_loss: 1.2745 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 4/500\n",
            "1/1 - 8s - loss: 0.8677 - accuracy: 0.7391 - val_loss: 1.2997 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 0.6387 - accuracy: 0.8261 - val_loss: 1.2654 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 8s - loss: 0.5418 - accuracy: 0.9348 - val_loss: 1.2516 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.5760 - accuracy: 0.8696 - val_loss: 1.2525 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.5002 - accuracy: 0.9348 - val_loss: 1.2566 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.4846 - accuracy: 0.9130 - val_loss: 1.2461 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.4181 - accuracy: 0.9565 - val_loss: 1.2443 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 8s - loss: 0.4589 - accuracy: 0.9348 - val_loss: 1.2597 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.4419 - accuracy: 0.9348 - val_loss: 1.2992 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.3457 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.3259 - accuracy: 1.0000 - val_loss: 1.3452 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.3404 - accuracy: 0.9783 - val_loss: 1.3359 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 8s - loss: 0.3197 - accuracy: 1.0000 - val_loss: 1.3564 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.3160 - accuracy: 1.0000 - val_loss: 1.3585 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.3097 - accuracy: 1.0000 - val_loss: 1.2807 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.2883 - accuracy: 1.0000 - val_loss: 1.2574 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.2924 - accuracy: 1.0000 - val_loss: 1.2965 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.2929 - accuracy: 1.0000 - val_loss: 1.3474 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.2756 - accuracy: 1.0000 - val_loss: 1.3809 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.2879 - accuracy: 1.0000 - val_loss: 1.3378 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.2747 - accuracy: 1.0000 - val_loss: 1.3158 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.2698 - accuracy: 1.0000 - val_loss: 1.3021 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.2680 - accuracy: 1.0000 - val_loss: 1.3629 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.2684 - accuracy: 1.0000 - val_loss: 1.3582 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.2625 - accuracy: 1.0000 - val_loss: 1.3069 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.2620 - accuracy: 1.0000 - val_loss: 1.3267 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.2663 - accuracy: 1.0000 - val_loss: 1.2598 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.2622 - accuracy: 1.0000 - val_loss: 1.2049 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 9s - loss: 0.2573 - accuracy: 1.0000 - val_loss: 1.0663 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.2569 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 8s - loss: 0.2609 - accuracy: 1.0000 - val_loss: 1.1935 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.2582 - accuracy: 1.0000 - val_loss: 1.0226 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 8s - loss: 0.2526 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 37/500\n",
            "1/1 - 7s - loss: 0.2552 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.2509 - accuracy: 1.0000 - val_loss: 1.0880 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.2482 - accuracy: 1.0000 - val_loss: 1.4797 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.2508 - accuracy: 1.0000 - val_loss: 1.4939 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.2526 - accuracy: 1.0000 - val_loss: 1.3455 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.2491 - accuracy: 1.0000 - val_loss: 1.3021 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.2446 - accuracy: 1.0000 - val_loss: 1.1000 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.2442 - accuracy: 1.0000 - val_loss: 1.3042 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.2468 - accuracy: 1.0000 - val_loss: 0.7726 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.2430 - accuracy: 1.0000 - val_loss: 0.8369 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.2451 - accuracy: 1.0000 - val_loss: 0.7415 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 8s - loss: 0.2434 - accuracy: 1.0000 - val_loss: 0.8324 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.2515 - accuracy: 1.0000 - val_loss: 1.2304 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 7s - loss: 0.2437 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.2427 - accuracy: 1.0000 - val_loss: 1.3877 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.2399 - accuracy: 1.0000 - val_loss: 1.5166 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 7s - loss: 0.2364 - accuracy: 1.0000 - val_loss: 1.5773 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 54/500\n",
            "1/1 - 7s - loss: 0.2421 - accuracy: 1.0000 - val_loss: 1.4692 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.2397 - accuracy: 1.0000 - val_loss: 1.5117 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.2399 - accuracy: 1.0000 - val_loss: 1.5729 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 7s - loss: 0.2389 - accuracy: 1.0000 - val_loss: 1.5059 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.2414 - accuracy: 1.0000 - val_loss: 1.7766 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.2367 - accuracy: 1.0000 - val_loss: 1.7968 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 7s - loss: 0.2366 - accuracy: 1.0000 - val_loss: 1.8218 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 61/500\n",
            "1/1 - 7s - loss: 0.2357 - accuracy: 1.0000 - val_loss: 1.8304 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 62/500\n",
            "1/1 - 7s - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.8720 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 63/500\n",
            "1/1 - 7s - loss: 0.2344 - accuracy: 1.0000 - val_loss: 1.8702 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.2350 - accuracy: 1.0000 - val_loss: 1.8648 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.2340 - accuracy: 1.0000 - val_loss: 1.9294 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 7s - loss: 0.2337 - accuracy: 1.0000 - val_loss: 1.9324 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 67/500\n",
            "1/1 - 7s - loss: 0.2341 - accuracy: 1.0000 - val_loss: 1.8931 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 68/500\n",
            "1/1 - 8s - loss: 0.2340 - accuracy: 1.0000 - val_loss: 1.8120 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 69/500\n",
            "1/1 - 7s - loss: 0.2322 - accuracy: 1.0000 - val_loss: 1.2008 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 0.9082 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 7s - loss: 0.2324 - accuracy: 1.0000 - val_loss: 1.2005 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 72/500\n",
            "1/1 - 7s - loss: 0.2323 - accuracy: 1.0000 - val_loss: 1.1363 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.2319 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 7s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 0.8170 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 9s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 77/500\n",
            "1/1 - 8s - loss: 0.2299 - accuracy: 1.0000 - val_loss: 0.8623 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 78/500\n",
            "1/1 - 8s - loss: 0.2313 - accuracy: 1.0000 - val_loss: 1.0593 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 79/500\n",
            "1/1 - 9s - loss: 0.2299 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 80/500\n",
            "1/1 - 9s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 81/500\n",
            "1/1 - 9s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 0.7098 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 82/500\n",
            "1/1 - 9s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 83/500\n",
            "1/1 - 9s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 1.0221 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 84/500\n",
            "1/1 - 8s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 0.6690 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 85/500\n",
            "1/1 - 9s - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.6487 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 86/500\n",
            "1/1 - 9s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 0.9058 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 87/500\n",
            "1/1 - 8s - loss: 0.2278 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 88/500\n",
            "1/1 - 9s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 89/500\n",
            "1/1 - 9s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 1.6789 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 90/500\n",
            "1/1 - 8s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.8082 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 91/500\n",
            "1/1 - 8s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 1.6286 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 92/500\n",
            "1/1 - 9s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.7587 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 93/500\n",
            "1/1 - 9s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.6891 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 94/500\n",
            "1/1 - 8s - loss: 0.2285 - accuracy: 1.0000 - val_loss: 2.0018 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 95/500\n",
            "1/1 - 9s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.9568 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 96/500\n",
            "1/1 - 9s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 2.1100 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 97/500\n",
            "1/1 - 8s - loss: 0.2264 - accuracy: 1.0000 - val_loss: 2.0207 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 98/500\n",
            "1/1 - 9s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 2.1501 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 99/500\n",
            "1/1 - 9s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 2.2557 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 100/500\n",
            "1/1 - 8s - loss: 0.2269 - accuracy: 1.0000 - val_loss: 2.3055 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 101/500\n",
            "1/1 - 8s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 2.2289 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 102/500\n",
            "1/1 - 9s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 2.2063 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 103/500\n",
            "1/1 - 8s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 2.0518 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 104/500\n",
            "1/1 - 8s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 1.8184 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 105/500\n",
            "1/1 - 9s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 2.1637 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 106/500\n",
            "1/1 - 8s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.2438 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 107/500\n",
            "1/1 - 9s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 2.0785 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 108/500\n",
            "1/1 - 9s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 2.2618 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 109/500\n",
            "1/1 - 9s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 2.2546 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 110/500\n",
            "1/1 - 8s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 2.2254 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 111/500\n",
            "1/1 - 9s - loss: 0.2240 - accuracy: 1.0000 - val_loss: 2.1865 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 112/500\n",
            "1/1 - 9s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 2.1253 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 113/500\n",
            "1/1 - 8s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 2.1091 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 114/500\n",
            "1/1 - 9s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 2.0805 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 115/500\n",
            "1/1 - 9s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.9937 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 116/500\n",
            "1/1 - 8s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 1.5021 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 117/500\n",
            "1/1 - 8s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 1.4438 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 118/500\n",
            "1/1 - 9s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.4377 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 119/500\n",
            "1/1 - 8s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.5941 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 120/500\n",
            "1/1 - 8s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.3348 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 121/500\n",
            "1/1 - 9s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 122/500\n",
            "1/1 - 8s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 123/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.6514 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 124/500\n",
            "1/1 - 9s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 1.8459 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 125/500\n",
            "1/1 - 9s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.8490 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 126/500\n",
            "1/1 - 8s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.8272 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 127/500\n",
            "1/1 - 9s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.7506 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 128/500\n",
            "1/1 - 8s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 1.7520 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 129/500\n",
            "1/1 - 8s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.7291 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 130/500\n",
            "1/1 - 9s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.8243 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 131/500\n",
            "1/1 - 8s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.8504 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 132/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.8759 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 133/500\n",
            "1/1 - 9s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 134/500\n",
            "1/1 - 8s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.6410 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 135/500\n",
            "1/1 - 8s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.6233 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 136/500\n",
            "1/1 - 8s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.1611 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 137/500\n",
            "1/1 - 8s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.0964 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 138/500\n",
            "1/1 - 8s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.6185 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 139/500\n",
            "1/1 - 8s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.8978 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 140/500\n",
            "1/1 - 8s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.8599 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 141/500\n",
            "1/1 - 8s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.7000 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 142/500\n",
            "1/1 - 8s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.6870 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 143/500\n",
            "1/1 - 9s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 144/500\n",
            "1/1 - 9s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.7938 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 145/500\n",
            "1/1 - 8s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 1.9024 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 146/500\n",
            "1/1 - 9s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.8741 - val_accuracy: 0.3333 - 9s/epoch - 9s/step\n",
            "Epoch 147/500\n",
            "1/1 - 9s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.8969 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 148/500\n",
            "1/1 - 8s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.7953 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 149/500\n",
            "1/1 - 9s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 1.7810 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 150/500\n",
            "1/1 - 8s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.2292 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 151/500\n",
            "1/1 - 8s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 2.0766 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 152/500\n",
            "1/1 - 8s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 2.1603 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 153/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 2.1334 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 154/500\n",
            "1/1 - 8s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 2.4990 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 155/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 2.4397 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 156/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 2.0161 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 157/500\n",
            "1/1 - 8s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.4879 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 158/500\n",
            "1/1 - 8s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 159/500\n",
            "1/1 - 9s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.8225 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 160/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 2.0654 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 161/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 2.0072 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 162/500\n",
            "1/1 - 9s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 2.0946 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 163/500\n",
            "1/1 - 8s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.2292 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 164/500\n",
            "1/1 - 8s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 165/500\n",
            "1/1 - 8s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 0.7218 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 166/500\n",
            "1/1 - 8s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.6184 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 167/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 168/500\n",
            "1/1 - 9s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 169/500\n",
            "1/1 - 9s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 1.9186 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 170/500\n",
            "1/1 - 9s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.2679 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 171/500\n",
            "1/1 - 8s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 0.9917 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 172/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.0315 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 173/500\n",
            "1/1 - 8s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.1072 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 174/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.0904 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 175/500\n",
            "1/1 - 9s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.3939 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 176/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.5310 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 177/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.2271 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 178/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.4102 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 179/500\n",
            "1/1 - 9s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.3060 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 180/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.2476 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 181/500\n",
            "1/1 - 8s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.1998 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 182/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.2445 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 183/500\n",
            "1/1 - 8s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.5235 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 184/500\n",
            "1/1 - 8s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.6461 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 185/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.7746 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 186/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.7534 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 187/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 188/500\n",
            "1/1 - 8s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.5998 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 189/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.6493 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 190/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.7976 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 191/500\n",
            "1/1 - 8s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.7534 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 192/500\n",
            "1/1 - 8s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.7109 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 193/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.5668 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 194/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.3747 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 195/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 196/500\n",
            "1/1 - 8s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.7507 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 197/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 2.0246 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 198/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.7400 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 199/500\n",
            "1/1 - 8s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 2.0297 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 200/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.2056 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 201/500\n",
            "1/1 - 8s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.4504 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 202/500\n",
            "1/1 - 8s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.1325 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 203/500\n",
            "1/1 - 8s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.6492 - val_accuracy: 0.3333 - 8s/epoch - 8s/step\n",
            "Epoch 204/500\n",
            "1/1 - 8s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.3589 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 205/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.4687 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 206/500\n",
            "1/1 - 9s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.8677 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 207/500\n",
            "1/1 - 8s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.5565 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 208/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.1217 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 209/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.0570 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 210/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 211/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.4299 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 212/500\n",
            "1/1 - 9s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.9245 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 213/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.7766 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 214/500\n",
            "1/1 - 8s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9962 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 215/500\n",
            "1/1 - 9s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.4039 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 216/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.8374 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 217/500\n",
            "1/1 - 8s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 2.0634 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 218/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.6641 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 219/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.8168 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 220/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.8878 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 221/500\n",
            "1/1 - 8s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.4665 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 222/500\n",
            "1/1 - 8s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 2.0311 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 223/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 2.1690 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 224/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.8735 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 225/500\n",
            "1/1 - 8s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.0072 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 226/500\n",
            "1/1 - 8s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.1189 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 227/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.1622 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 228/500\n",
            "1/1 - 8s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.0972 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 229/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 230/500\n",
            "1/1 - 8s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 231/500\n",
            "1/1 - 9s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.6005 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 232/500\n",
            "1/1 - 9s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.4218 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 233/500\n",
            "1/1 - 8s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 234/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.9241 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 235/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 2.4360 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 236/500\n",
            "1/1 - 8s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 2.5918 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 237/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.9966 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 238/500\n",
            "1/1 - 9s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.7988 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 239/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 240/500\n",
            "1/1 - 8s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.4200 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 241/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.5104 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 242/500\n",
            "1/1 - 8s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.4422 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 243/500\n",
            "1/1 - 8s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.2770 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 244/500\n",
            "1/1 - 9s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.3366 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 245/500\n",
            "1/1 - 8s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 246/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.9696 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 247/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.2611 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 248/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 2.6791 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 249/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 2.7659 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 250/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 2.6592 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 251/500\n",
            "1/1 - 9s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 2.8591 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 252/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 2.4782 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 253/500\n",
            "1/1 - 9s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 2.0454 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 254/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 2.9365 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 255/500\n",
            "1/1 - 8s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 2.9460 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 256/500\n",
            "1/1 - 9s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 2.7175 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 257/500\n",
            "1/1 - 11s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.4905 - val_accuracy: 1.0000 - 11s/epoch - 11s/step\n",
            "Epoch 258/500\n",
            "1/1 - 9s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.9167 - 9s/epoch - 9s/step\n",
            "Epoch 259/500\n",
            "1/1 - 8s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.1644 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 260/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 261/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.5606 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 262/500\n",
            "1/1 - 8s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 0.7114 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 263/500\n",
            "1/1 - 8s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 264/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.7444 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 265/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.7889 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 266/500\n",
            "1/1 - 8s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 3.1793 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 267/500\n",
            "1/1 - 9s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 3.1064 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 268/500\n",
            "1/1 - 8s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 2.7436 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 269/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.1399 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 270/500\n",
            "1/1 - 9s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 2.8404 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 271/500\n",
            "1/1 - 9s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.5281 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 272/500\n",
            "1/1 - 8s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.8272 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 273/500\n",
            "1/1 - 9s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.0608 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 274/500\n",
            "1/1 - 9s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.3027 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 275/500\n",
            "1/1 - 8s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.6807 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 276/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.4841 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 277/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 278/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 0.6252 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 279/500\n",
            "1/1 - 9s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 280/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.9570 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 281/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.9762 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 282/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 0.6791 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 283/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 284/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.8822 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 285/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.1375 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 286/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.8907 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 287/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.3861 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 288/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.7186 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 289/500\n",
            "1/1 - 8s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.6207 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 290/500\n",
            "1/1 - 8s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.5824 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 291/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 2.4598 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 292/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.2449 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 293/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 3.2868 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 294/500\n",
            "1/1 - 8s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 3.4216 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 295/500\n",
            "1/1 - 8s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 3.5195 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 296/500\n",
            "1/1 - 8s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 2.7217 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 297/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.0194 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 298/500\n",
            "1/1 - 8s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 299/500\n",
            "1/1 - 8s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.0061 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 300/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 2.1952 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 301/500\n",
            "1/1 - 8s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 2.0717 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 302/500\n",
            "1/1 - 8s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 2.5088 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 303/500\n",
            "1/1 - 9s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 2.9875 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 304/500\n",
            "1/1 - 9s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 3.6786 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 305/500\n",
            "1/1 - 9s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 3.1180 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 306/500\n",
            "1/1 - 9s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 2.6568 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 307/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 3.0519 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 308/500\n",
            "1/1 - 9s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.9139 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 309/500\n",
            "1/1 - 9s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 2.6740 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 310/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 3.1020 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 311/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.9774 - val_accuracy: 0.4167 - 8s/epoch - 8s/step\n",
            "Epoch 312/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.2119 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 313/500\n",
            "1/1 - 8s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 314/500\n",
            "1/1 - 8s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.0440 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 315/500\n",
            "1/1 - 9s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.0614 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 316/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.0802 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 317/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2244 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 318/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 319/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.1273 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 320/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.1972 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 321/500\n",
            "1/1 - 9s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 322/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.3257 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 323/500\n",
            "1/1 - 8s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.1387 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 324/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.1321 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 325/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.0190 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 326/500\n",
            "1/1 - 8s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 327/500\n",
            "1/1 - 9s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 328/500\n",
            "1/1 - 8s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2250 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 329/500\n",
            "1/1 - 8s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.3615 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 330/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.0915 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 331/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.1465 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 332/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.0605 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 333/500\n",
            "1/1 - 8s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.0514 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 334/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.6810 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 335/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.2821 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 336/500\n",
            "1/1 - 9s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.4797 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 337/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.8566 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 338/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.5669 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 339/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.3416 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 340/500\n",
            "1/1 - 9s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.5892 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 341/500\n",
            "1/1 - 8s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.6078 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 342/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.5813 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 343/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.7347 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 344/500\n",
            "1/1 - 9s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.5433 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 345/500\n",
            "1/1 - 8s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.5171 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 346/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 2.3942 - val_accuracy: 0.2500 - 8s/epoch - 8s/step\n",
            "Epoch 347/500\n",
            "1/1 - 9s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 2.1355 - val_accuracy: 0.2500 - 9s/epoch - 9s/step\n",
            "Epoch 348/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.8233 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 349/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.2336 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 350/500\n",
            "1/1 - 9s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.0505 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 351/500\n",
            "1/1 - 8s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.8624 - val_accuracy: 0.8333 - 8s/epoch - 8s/step\n",
            "Epoch 352/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.4517 - val_accuracy: 0.4167 - 9s/epoch - 9s/step\n",
            "Epoch 353/500\n",
            "1/1 - 9s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 0.7628 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 354/500\n",
            "1/1 - 8s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.0356 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 355/500\n",
            "1/1 - 9s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 2.5551 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 356/500\n",
            "1/1 - 9s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 2.9300 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 357/500\n",
            "1/1 - 8s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.2275 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 358/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.4982 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 359/500\n",
            "1/1 - 9s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.3893 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 360/500\n",
            "1/1 - 8s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.2659 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 361/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 362/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.2501 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 363/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.1686 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 364/500\n",
            "1/1 - 8s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.1096 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 365/500\n",
            "1/1 - 9s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.8635 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 366/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 2.8719 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 367/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 2.8434 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 368/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.8773 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 369/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.9553 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 370/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 2.7904 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 371/500\n",
            "1/1 - 9s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 372/500\n",
            "1/1 - 9s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 2.4598 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 373/500\n",
            "1/1 - 8s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.5591 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 374/500\n",
            "1/1 - 8s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.7376 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 375/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.7913 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 376/500\n",
            "1/1 - 8s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.5840 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 377/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4662 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 378/500\n",
            "1/1 - 9s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 379/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4721 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 380/500\n",
            "1/1 - 8s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4229 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 381/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.4100 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 382/500\n",
            "1/1 - 9s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.5331 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 383/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.8819 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 384/500\n",
            "1/1 - 9s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.3743 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 385/500\n",
            "1/1 - 9s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 386/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.4308 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 387/500\n",
            "1/1 - 9s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.2937 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 388/500\n",
            "1/1 - 9s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.2298 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 389/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.1921 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 390/500\n",
            "1/1 - 8s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.9070 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 391/500\n",
            "1/1 - 9s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 392/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 393/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.1892 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 394/500\n",
            "1/1 - 9s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.8333 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 395/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 0.9842 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 396/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.1497 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 397/500\n",
            "1/1 - 8s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 398/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.0750 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 399/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.1948 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 400/500\n",
            "1/1 - 9s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4325 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 401/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.5720 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 402/500\n",
            "1/1 - 8s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.5358 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 403/500\n",
            "1/1 - 9s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.5120 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 404/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4750 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 405/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.4186 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 406/500\n",
            "1/1 - 8s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4777 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 407/500\n",
            "1/1 - 9s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.5306 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 408/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.5567 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 409/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 2.0809 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 410/500\n",
            "1/1 - 8s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.4935 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 411/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.5400 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 412/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.4508 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 413/500\n",
            "1/1 - 8s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.4596 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 414/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.6391 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 415/500\n",
            "1/1 - 8s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9118 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 416/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3890 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 417/500\n",
            "1/1 - 8s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.1873 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 418/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.1350 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 419/500\n",
            "1/1 - 9s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.2239 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 420/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 421/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.2274 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 422/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.2888 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 423/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.5545 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 424/500\n",
            "1/1 - 8s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.6492 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 425/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.6339 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 426/500\n",
            "1/1 - 9s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.6098 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 427/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 428/500\n",
            "1/1 - 8s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.6149 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 429/500\n",
            "1/1 - 8s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.5179 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 430/500\n",
            "1/1 - 8s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.3045 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 431/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.3621 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 432/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.3667 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 433/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.4174 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 434/500\n",
            "1/1 - 8s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.3626 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 435/500\n",
            "1/1 - 9s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.4474 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 436/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.4231 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 437/500\n",
            "1/1 - 8s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.5871 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 438/500\n",
            "1/1 - 9s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.5468 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 439/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.4007 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 440/500\n",
            "1/1 - 8s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.2546 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 441/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.3791 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 442/500\n",
            "1/1 - 9s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.4671 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 443/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.5278 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 444/500\n",
            "1/1 - 9s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.5848 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 445/500\n",
            "1/1 - 9s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.6603 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 446/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.6296 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 447/500\n",
            "1/1 - 9s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.4156 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 448/500\n",
            "1/1 - 8s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.2980 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 449/500\n",
            "1/1 - 8s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.3819 - val_accuracy: 0.6667 - 8s/epoch - 8s/step\n",
            "Epoch 450/500\n",
            "1/1 - 9s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.3925 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 451/500\n",
            "1/1 - 9s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.4230 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 452/500\n",
            "1/1 - 9s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.4752 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 453/500\n",
            "1/1 - 9s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.5212 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 454/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.3059 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 455/500\n",
            "1/1 - 9s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.2438 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 456/500\n",
            "1/1 - 9s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 0.8377 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 457/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.0853 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 458/500\n",
            "1/1 - 9s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.0102 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 459/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 0.8593 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 460/500\n",
            "1/1 - 9s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.2684 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 461/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.2535 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 462/500\n",
            "1/1 - 8s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.7939 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 463/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.7586 - val_accuracy: 0.5833 - 8s/epoch - 8s/step\n",
            "Epoch 464/500\n",
            "1/1 - 9s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 465/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.4051 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 466/500\n",
            "1/1 - 8s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.5778 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 467/500\n",
            "1/1 - 9s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.5803 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 468/500\n",
            "1/1 - 9s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.5452 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 469/500\n",
            "1/1 - 8s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.5445 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 470/500\n",
            "1/1 - 9s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.4296 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 471/500\n",
            "1/1 - 9s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.3315 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 472/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 473/500\n",
            "1/1 - 9s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.4877 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 474/500\n",
            "1/1 - 8s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.2349 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 475/500\n",
            "1/1 - 8s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.3584 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 476/500\n",
            "1/1 - 9s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.5907 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 477/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.6050 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 478/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.6115 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 479/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.6115 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 480/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.6351 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 481/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.7091 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 482/500\n",
            "1/1 - 8s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.6891 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 483/500\n",
            "1/1 - 9s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.7613 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 484/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.6805 - val_accuracy: 0.7500 - 8s/epoch - 8s/step\n",
            "Epoch 485/500\n",
            "1/1 - 9s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.6880 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 486/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.6482 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 487/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.6249 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 488/500\n",
            "1/1 - 8s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.8709 - val_accuracy: 0.5000 - 8s/epoch - 8s/step\n",
            "Epoch 489/500\n",
            "1/1 - 9s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.8412 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 490/500\n",
            "1/1 - 9s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.2050 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 491/500\n",
            "1/1 - 9s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.9779 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 492/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.8083 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 493/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 3.4839 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 494/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 3.5147 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 495/500\n",
            "1/1 - 9s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 3.1165 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 496/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 2.5076 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 497/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.6662 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 498/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.7134 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 499/500\n",
            "1/1 - 9s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 2.0778 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 500/500\n",
            "1/1 - 9s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.7874 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Time Bimodal_EEG+Data_clean = 4313.185218811035 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_clean_2025-01-11_23-07-28\n",
            "saved-model-001-0.5000.hdf5\n",
            "Loss=1.3069 y Accuracy=0.5000\n",
            "\n",
            "saved-model-032-0.7500.hdf5\n",
            "Loss=1.0663 y Accuracy=0.7500\n",
            "\n",
            "saved-model-076-0.9167.hdf5\n",
            "Loss=0.7004 y Accuracy=0.9167\n",
            "\n",
            "saved-model-257-1.0000.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 509 calls to <function Model.make_test_function.<locals>.test_function at 0x7826616d01f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=0.4905 y Accuracy=1.0000\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-257-1.0000.hdf5\n",
            "Loss=0.4905 y Accuracy=1.0000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 58 standar scaler features without moca_total,ifs_total_score\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data_clean\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJKT1G1_x8yQ",
        "outputId": "9bdc9a66-5151-4609-8eb6-72142ee37cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 147s - loss: 1.5632 - accuracy: 0.3971 - val_loss: 1.2558 - val_accuracy: 0.5294 - 147s/epoch - 147s/step\n",
            "Epoch 2/500\n",
            "1/1 - 7s - loss: 1.3054 - accuracy: 0.5735 - val_loss: 1.2528 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 3/500\n",
            "1/1 - 7s - loss: 0.9673 - accuracy: 0.7059 - val_loss: 1.2455 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 4/500\n",
            "1/1 - 7s - loss: 0.7298 - accuracy: 0.8382 - val_loss: 1.3158 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 0.6248 - accuracy: 0.8529 - val_loss: 1.3236 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 7s - loss: 0.5949 - accuracy: 0.8824 - val_loss: 1.3339 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.5514 - accuracy: 0.9118 - val_loss: 1.3374 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.5404 - accuracy: 0.8971 - val_loss: 1.3371 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.5127 - accuracy: 0.9412 - val_loss: 1.3463 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.4546 - accuracy: 0.9265 - val_loss: 1.3563 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 7s - loss: 0.4163 - accuracy: 0.9559 - val_loss: 1.3564 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.4898 - accuracy: 0.9118 - val_loss: 1.3621 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.3824 - accuracy: 0.9706 - val_loss: 1.3636 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.3772 - accuracy: 0.9559 - val_loss: 1.3907 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.3563 - accuracy: 0.9853 - val_loss: 1.4188 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 7s - loss: 0.3510 - accuracy: 0.9706 - val_loss: 1.4709 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.3273 - accuracy: 0.9853 - val_loss: 1.4776 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.3090 - accuracy: 0.9853 - val_loss: 1.4507 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.3192 - accuracy: 0.9853 - val_loss: 1.4033 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.2924 - accuracy: 1.0000 - val_loss: 1.4315 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.3064 - accuracy: 0.9853 - val_loss: 1.4431 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.2798 - accuracy: 1.0000 - val_loss: 1.4956 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.2860 - accuracy: 1.0000 - val_loss: 1.5514 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.2895 - accuracy: 1.0000 - val_loss: 1.5308 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.2660 - accuracy: 1.0000 - val_loss: 1.5437 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.2646 - accuracy: 1.0000 - val_loss: 1.4863 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.2659 - accuracy: 0.9853 - val_loss: 1.4201 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.2617 - accuracy: 1.0000 - val_loss: 1.3674 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.2483 - accuracy: 1.0000 - val_loss: 1.3782 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.2510 - accuracy: 1.0000 - val_loss: 1.3951 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.2489 - accuracy: 1.0000 - val_loss: 1.4205 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 7s - loss: 0.2550 - accuracy: 1.0000 - val_loss: 1.5112 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.2461 - accuracy: 1.0000 - val_loss: 1.6291 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 7s - loss: 0.2434 - accuracy: 1.0000 - val_loss: 1.4175 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.2438 - accuracy: 1.0000 - val_loss: 1.6669 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 7s - loss: 0.2422 - accuracy: 1.0000 - val_loss: 1.6785 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 37/500\n",
            "1/1 - 9s - loss: 0.2396 - accuracy: 1.0000 - val_loss: 1.4713 - val_accuracy: 0.5882 - 9s/epoch - 9s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.2369 - accuracy: 1.0000 - val_loss: 1.5305 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.2393 - accuracy: 1.0000 - val_loss: 1.5117 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.2367 - accuracy: 1.0000 - val_loss: 1.5416 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.2368 - accuracy: 1.0000 - val_loss: 1.6856 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.2347 - accuracy: 1.0000 - val_loss: 1.3983 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.2337 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.2341 - accuracy: 1.0000 - val_loss: 1.4543 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.2343 - accuracy: 1.0000 - val_loss: 1.4128 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.2338 - accuracy: 1.0000 - val_loss: 1.3850 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.2309 - accuracy: 1.0000 - val_loss: 1.3821 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 7s - loss: 0.2310 - accuracy: 1.0000 - val_loss: 1.3822 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 7s - loss: 0.2304 - accuracy: 1.0000 - val_loss: 1.4118 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.2297 - accuracy: 1.0000 - val_loss: 1.4839 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.2277 - accuracy: 1.0000 - val_loss: 1.5952 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 9s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 1.1121 - val_accuracy: 0.7059 - 9s/epoch - 9s/step\n",
            "Epoch 54/500\n",
            "1/1 - 9s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 0.7647 - 9s/epoch - 9s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.8774 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 0.9523 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 7s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 0.8942 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 0.8753 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.2258 - accuracy: 1.0000 - val_loss: 0.8901 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 10s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.8235 - 10s/epoch - 10s/step\n",
            "Epoch 61/500\n",
            "1/1 - 7s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 1.1424 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 62/500\n",
            "1/1 - 7s - loss: 0.2240 - accuracy: 1.0000 - val_loss: 1.7105 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 63/500\n",
            "1/1 - 7s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.7372 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.6224 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 1.5896 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 7s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.8178 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 67/500\n",
            "1/1 - 7s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.8600 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 68/500\n",
            "1/1 - 7s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.9094 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 69/500\n",
            "1/1 - 7s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.7811 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 1.8168 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 7s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.8987 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 72/500\n",
            "1/1 - 7s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.4025 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 1.7964 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 7s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.8737 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.8777 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 7s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.6136 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 77/500\n",
            "1/1 - 7s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.4111 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 78/500\n",
            "1/1 - 7s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 79/500\n",
            "1/1 - 7s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 1.0195 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 80/500\n",
            "1/1 - 7s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 1.6838 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 81/500\n",
            "1/1 - 7s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.3988 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 82/500\n",
            "1/1 - 7s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.8196 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 83/500\n",
            "1/1 - 7s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.9648 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 84/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 2.0029 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 85/500\n",
            "1/1 - 7s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.9531 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 86/500\n",
            "1/1 - 7s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.7362 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 87/500\n",
            "1/1 - 7s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.9582 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 88/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.9649 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 89/500\n",
            "1/1 - 7s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.6892 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 90/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 2.1017 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 91/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.9265 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 92/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 2.0592 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 93/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.9367 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 94/500\n",
            "1/1 - 7s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 1.6631 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 95/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.4628 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 96/500\n",
            "1/1 - 7s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 1.7936 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 97/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.9823 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 98/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.9541 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 99/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.9843 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 100/500\n",
            "1/1 - 7s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.9024 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 101/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.6414 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 102/500\n",
            "1/1 - 7s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.1396 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 103/500\n",
            "1/1 - 7s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 104/500\n",
            "1/1 - 7s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 105/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.0194 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 106/500\n",
            "1/1 - 7s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.9639 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 107/500\n",
            "1/1 - 7s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 108/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 109/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.9662 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 110/500\n",
            "1/1 - 7s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 0.9937 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 111/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.8685 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 112/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 113/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 114/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 115/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.8795 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 116/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 117/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.2857 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 118/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.6964 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 119/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.9843 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 120/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.0027 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 121/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 0.8950 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 122/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.2494 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 123/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.2463 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 124/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.0294 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 125/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 126/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.1328 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 127/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 128/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 129/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 130/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 131/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.4456 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 132/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.5316 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 133/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.4493 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 134/500\n",
            "1/1 - 7s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.1358 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 135/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.9819 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 136/500\n",
            "1/1 - 7s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.1974 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 137/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.1439 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 138/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.8189 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 139/500\n",
            "1/1 - 7s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.9397 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 140/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.9401 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 141/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9114 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 142/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.8884 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 143/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 144/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.9485 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 145/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.0587 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 146/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 147/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 148/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.1143 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 149/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 0.9595 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 150/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 151/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.3854 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 152/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.2628 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 153/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.1473 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 154/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.2050 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 155/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.4070 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 156/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.0999 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 157/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.2547 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 158/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.5482 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 159/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.2134 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 160/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 2.4442 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 161/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 2.5356 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 162/500\n",
            "1/1 - 7s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 2.4439 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 163/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.0202 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 164/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.9856 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 165/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.8142 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 166/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.5779 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 167/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.3672 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 168/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.1309 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 169/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 170/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.2184 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 171/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.0163 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 172/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 173/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.1124 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 174/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 175/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 176/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.9299 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 177/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 178/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 0.9509 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 179/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 180/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.9311 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 181/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.0034 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 182/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.1293 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 183/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.2223 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 184/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.3503 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 185/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.3853 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 186/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.3444 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 187/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.1963 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 188/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1533 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 189/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.1007 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 190/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.0629 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 191/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 192/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.1487 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 193/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 194/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 195/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 196/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 197/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 198/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.8473 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 199/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.8661 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 200/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 201/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.1008 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 202/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.1149 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 203/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.3776 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 204/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.8389 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 205/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.0593 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 206/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.0695 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 207/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.9184 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 208/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.2175 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 209/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.0088 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 210/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 211/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.0707 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 212/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.0570 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 213/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.0161 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 214/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.0624 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 215/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 216/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.9144 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 217/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.9900 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 218/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 0.9338 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 219/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.9370 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 220/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.9407 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 221/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.9365 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 222/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.0759 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 223/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 224/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 225/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 226/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.9271 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 227/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.2575 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 228/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.6145 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 229/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.4862 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 230/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.2174 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 231/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.0392 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 232/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9868 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 233/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9485 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 234/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.8914 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 235/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 0.9150 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 236/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.9148 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 237/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.8991 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 238/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 239/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 240/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 241/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.9339 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 242/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.0341 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 243/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.1774 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 244/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.0840 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 245/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.0079 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 246/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 0.9455 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 247/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.0485 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 248/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.9522 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 249/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.1060 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 250/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 251/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.1002 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 252/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.0147 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 253/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.0230 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 254/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.9922 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 255/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.0142 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 256/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.1264 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 257/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.2586 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 258/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.1342 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 259/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.0470 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 260/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.0127 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 261/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 262/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9993 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 263/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.0519 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 264/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.8729 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 265/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 266/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.8916 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 267/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9012 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 268/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.0452 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 269/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.2903 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 270/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.3334 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 271/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.3558 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 272/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.2745 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 273/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.2274 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 274/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.2570 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 275/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.0878 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 276/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.2931 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 277/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.1530 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 278/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 279/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.1323 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 280/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 281/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.1219 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 282/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.4082 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 283/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.5187 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 284/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.4180 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 285/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.1825 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 286/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.0328 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 287/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.2660 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 288/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.4030 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 289/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.4980 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 290/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 291/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.2156 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 292/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.3209 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 293/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.1968 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 294/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.1959 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 295/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.3690 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 296/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4181 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 297/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.4357 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 298/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.3440 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 299/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 300/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.4692 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 301/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 302/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.7648 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 303/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.4125 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 304/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.0450 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 305/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.0144 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 306/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 307/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.9787 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 308/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 0.9228 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 309/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.9130 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 310/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 311/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 312/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.2320 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 313/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.1588 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 314/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 315/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 316/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.1158 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 317/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 318/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.1546 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 319/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 320/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.1993 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 321/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3731 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 322/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.2252 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 323/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.2410 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 324/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 325/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.2009 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 326/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.3531 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 327/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.6106 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 328/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3764 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 329/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3607 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 330/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 331/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.2211 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 332/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.2471 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 333/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.4576 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 334/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3169 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 335/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.3524 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 336/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.3692 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 337/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1419 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 338/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 339/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1246 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 340/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 341/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.2681 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 342/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1897 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 343/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.0841 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 344/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.0934 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 345/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 346/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.2109 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 347/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.1861 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 348/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.3086 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 349/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.6094 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 350/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.8280 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 351/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.9385 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 352/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.6568 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 353/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.8123 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 354/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.6639 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 355/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.4716 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 356/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.3812 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 357/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.5992 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 358/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.3558 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 359/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.3811 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 360/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.2657 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 361/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.2812 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 362/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.2138 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 363/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.0889 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 364/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.1488 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 365/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 366/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.2136 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 367/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.1667 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 368/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 369/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.1494 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 370/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.2489 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 371/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.3230 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 372/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.5369 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 373/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.3227 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 374/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.1475 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 375/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 376/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2550 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 377/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.4940 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 378/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.4569 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 379/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 380/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.1233 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 381/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.0921 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 382/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.2491 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 383/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.4081 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 384/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 385/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 386/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.1028 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 387/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.0969 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 388/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 389/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 390/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.2753 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 391/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.2171 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 392/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.3658 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 393/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.2076 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 394/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.1845 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 395/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.1183 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 396/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.1485 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 397/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.1391 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 398/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.0310 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 399/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.0180 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 400/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.0674 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 401/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.3313 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 402/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.0649 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 403/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.2462 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 404/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.1677 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 405/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 0.9859 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 406/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.3873 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 407/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.2971 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 408/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.1473 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 409/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.2608 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 410/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.1329 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 411/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.1902 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 412/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.2322 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 413/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.2084 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 414/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.1144 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 415/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.3192 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 416/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.5180 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 417/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.3756 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 418/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.3196 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 419/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.1239 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 420/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.1584 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 421/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.2196 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 422/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 423/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.1694 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 424/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.1881 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 425/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.0307 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 426/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.0948 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 427/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 428/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.3392 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 429/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.1813 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 430/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 431/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.1644 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 432/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.1862 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 433/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.2098 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 434/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.2481 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 435/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.2512 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 436/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.1317 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 437/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.2464 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 438/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.1577 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 439/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.5857 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 440/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.6620 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 441/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.4983 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 442/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.4388 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 443/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 444/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.2480 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 445/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.2738 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 446/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 447/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.3540 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 448/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.5076 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 449/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.3437 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 450/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.1547 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 451/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.1351 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 452/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.2712 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 453/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.1467 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 454/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.3890 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 455/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.5964 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 456/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.6607 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 457/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 2.0737 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 458/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.8670 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 459/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 1.7686 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 460/500\n",
            "1/1 - 7s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.6420 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 461/500\n",
            "1/1 - 7s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.3013 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 462/500\n",
            "1/1 - 7s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.3392 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 463/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 1.4740 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 464/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 1.4114 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 465/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 1.6566 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 466/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.4003 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 467/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.6118 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 468/500\n",
            "1/1 - 7s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 1.2396 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 469/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.2795 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 470/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 1.2480 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 471/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 1.2907 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 472/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.3167 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 473/500\n",
            "1/1 - 7s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 1.1751 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 474/500\n",
            "1/1 - 7s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.1415 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 475/500\n",
            "1/1 - 7s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.1471 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 476/500\n",
            "1/1 - 7s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.1683 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 477/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.1341 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 478/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.0610 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 479/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.0947 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 480/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.1481 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 481/500\n",
            "1/1 - 7s - loss: 0.2063 - accuracy: 1.0000 - val_loss: 1.2596 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 482/500\n",
            "1/1 - 7s - loss: 0.2062 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 483/500\n",
            "1/1 - 7s - loss: 0.2062 - accuracy: 1.0000 - val_loss: 1.0783 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 484/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.0489 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 485/500\n",
            "1/1 - 7s - loss: 0.2063 - accuracy: 1.0000 - val_loss: 1.1883 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 486/500\n",
            "1/1 - 7s - loss: 0.2062 - accuracy: 1.0000 - val_loss: 1.2057 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 487/500\n",
            "1/1 - 7s - loss: 0.2061 - accuracy: 1.0000 - val_loss: 1.3467 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 488/500\n",
            "1/1 - 7s - loss: 0.2061 - accuracy: 1.0000 - val_loss: 1.1896 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 489/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.1119 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 490/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.2011 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 491/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.0789 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 492/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.2307 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 493/500\n",
            "1/1 - 7s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 494/500\n",
            "1/1 - 7s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 1.4632 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 495/500\n",
            "1/1 - 7s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 1.4511 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 496/500\n",
            "1/1 - 7s - loss: 0.2058 - accuracy: 1.0000 - val_loss: 1.3833 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 497/500\n",
            "1/1 - 7s - loss: 0.2057 - accuracy: 1.0000 - val_loss: 1.3888 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 498/500\n",
            "1/1 - 7s - loss: 0.2058 - accuracy: 1.0000 - val_loss: 1.3085 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 499/500\n",
            "1/1 - 7s - loss: 0.2058 - accuracy: 1.0000 - val_loss: 1.1879 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 500/500\n",
            "1/1 - 7s - loss: 0.2057 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Time Bimodal_EEG+Data_clean = 3672.8807842731476 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_clean_2025-01-11_19-18-48\n",
            "saved-model-001-0.5294.hdf5\n",
            "Loss=1.2558 y Accuracy=0.5294\n",
            "\n",
            "saved-model-037-0.5882.hdf5\n",
            "Loss=1.4713 y Accuracy=0.5882\n",
            "\n",
            "saved-model-053-0.7059.hdf5\n",
            "Loss=1.1121 y Accuracy=0.7059\n",
            "\n",
            "saved-model-054-0.7647.hdf5\n",
            "Loss=0.9283 y Accuracy=0.7647\n",
            "\n",
            "saved-model-060-0.8235.hdf5\n",
            "Loss=0.9573 y Accuracy=0.8235\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-060-0.8235.hdf5\n",
            "Loss=0.9573 y Accuracy=0.8235\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 85 standar scaler 21 features\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data_clean\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfV6zVU1_Pz3",
        "outputId": "544e6eae-381c-4727-f738-abd33ab9ccf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 139s - loss: 1.4975 - accuracy: 0.4130 - val_loss: 1.3125 - val_accuracy: 0.2500 - 139s/epoch - 139s/step\n",
            "Epoch 2/500\n",
            "1/1 - 7s - loss: 1.5871 - accuracy: 0.4130 - val_loss: 1.3072 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 3/500\n",
            "1/1 - 9s - loss: 1.3792 - accuracy: 0.4130 - val_loss: 1.2874 - val_accuracy: 0.5000 - 9s/epoch - 9s/step\n",
            "Epoch 4/500\n",
            "1/1 - 7s - loss: 0.9882 - accuracy: 0.6304 - val_loss: 1.3111 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 0.8257 - accuracy: 0.7174 - val_loss: 1.3827 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 7s - loss: 0.8860 - accuracy: 0.7391 - val_loss: 1.4364 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.6936 - accuracy: 0.8261 - val_loss: 1.3623 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.5987 - accuracy: 0.8261 - val_loss: 1.4237 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.5757 - accuracy: 0.8696 - val_loss: 1.3241 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.4810 - accuracy: 0.9348 - val_loss: 1.3516 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 7s - loss: 0.4063 - accuracy: 1.0000 - val_loss: 1.3704 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.3931 - accuracy: 0.9783 - val_loss: 1.3623 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.3809 - accuracy: 0.9783 - val_loss: 1.3778 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.4179 - accuracy: 0.9565 - val_loss: 1.3751 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.3475 - accuracy: 1.0000 - val_loss: 1.3865 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 7s - loss: 0.3554 - accuracy: 1.0000 - val_loss: 1.3898 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.3173 - accuracy: 0.9783 - val_loss: 1.3901 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.3078 - accuracy: 1.0000 - val_loss: 1.3800 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.3098 - accuracy: 0.9783 - val_loss: 1.3731 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.3001 - accuracy: 1.0000 - val_loss: 1.3702 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.2874 - accuracy: 1.0000 - val_loss: 1.3664 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.2891 - accuracy: 1.0000 - val_loss: 1.3682 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.2834 - accuracy: 1.0000 - val_loss: 1.3682 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.2841 - accuracy: 1.0000 - val_loss: 1.3701 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.2803 - accuracy: 1.0000 - val_loss: 1.3693 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.2633 - accuracy: 1.0000 - val_loss: 1.3715 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.2732 - accuracy: 1.0000 - val_loss: 1.3751 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.2662 - accuracy: 1.0000 - val_loss: 1.3748 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.2639 - accuracy: 1.0000 - val_loss: 1.3755 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.2601 - accuracy: 1.0000 - val_loss: 1.3750 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.2551 - accuracy: 1.0000 - val_loss: 1.3748 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 7s - loss: 0.2565 - accuracy: 1.0000 - val_loss: 1.3753 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.2491 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 7s - loss: 0.2605 - accuracy: 1.0000 - val_loss: 1.4265 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.2533 - accuracy: 1.0000 - val_loss: 1.4406 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 7s - loss: 0.2448 - accuracy: 1.0000 - val_loss: 1.4799 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 37/500\n",
            "1/1 - 7s - loss: 0.2474 - accuracy: 1.0000 - val_loss: 1.4876 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.2486 - accuracy: 1.0000 - val_loss: 1.5630 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.2461 - accuracy: 1.0000 - val_loss: 1.5219 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.2417 - accuracy: 1.0000 - val_loss: 1.6798 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.2449 - accuracy: 1.0000 - val_loss: 1.7118 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.2449 - accuracy: 1.0000 - val_loss: 1.8313 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.2425 - accuracy: 1.0000 - val_loss: 1.9562 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.2403 - accuracy: 1.0000 - val_loss: 2.2863 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.2427 - accuracy: 1.0000 - val_loss: 2.4974 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.2388 - accuracy: 1.0000 - val_loss: 2.5152 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.2384 - accuracy: 1.0000 - val_loss: 2.8030 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 7s - loss: 0.2405 - accuracy: 1.0000 - val_loss: 2.4694 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.2386 - accuracy: 1.0000 - val_loss: 2.7285 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 7s - loss: 0.2370 - accuracy: 1.0000 - val_loss: 2.8050 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.2338 - accuracy: 1.0000 - val_loss: 2.6664 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.2354 - accuracy: 1.0000 - val_loss: 2.2362 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 7s - loss: 0.2369 - accuracy: 1.0000 - val_loss: 1.8543 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 54/500\n",
            "1/1 - 7s - loss: 0.2339 - accuracy: 1.0000 - val_loss: 1.4649 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.2327 - accuracy: 1.0000 - val_loss: 1.5745 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.2340 - accuracy: 1.0000 - val_loss: 1.4559 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 7s - loss: 0.2336 - accuracy: 1.0000 - val_loss: 1.6854 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.2311 - accuracy: 1.0000 - val_loss: 1.5537 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.2333 - accuracy: 1.0000 - val_loss: 1.6771 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 7s - loss: 0.2317 - accuracy: 1.0000 - val_loss: 1.7344 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 61/500\n",
            "1/1 - 7s - loss: 0.2322 - accuracy: 1.0000 - val_loss: 1.9421 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 62/500\n",
            "1/1 - 7s - loss: 0.2314 - accuracy: 1.0000 - val_loss: 2.1225 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 63/500\n",
            "1/1 - 7s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 2.2196 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 2.0159 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 1.8875 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 7s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 2.1523 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 67/500\n",
            "1/1 - 7s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.8290 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 68/500\n",
            "1/1 - 7s - loss: 0.2291 - accuracy: 1.0000 - val_loss: 1.7968 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 69/500\n",
            "1/1 - 7s - loss: 0.2303 - accuracy: 1.0000 - val_loss: 1.8413 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.2297 - accuracy: 1.0000 - val_loss: 1.7902 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 7s - loss: 0.2299 - accuracy: 1.0000 - val_loss: 1.6810 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 72/500\n",
            "1/1 - 9s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.3305 - val_accuracy: 0.5833 - 9s/epoch - 9s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 9s - loss: 0.2292 - accuracy: 1.0000 - val_loss: 1.3251 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.2278 - accuracy: 1.0000 - val_loss: 1.6702 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 7s - loss: 0.2278 - accuracy: 1.0000 - val_loss: 1.3636 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 77/500\n",
            "1/1 - 9s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 1.2500 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 78/500\n",
            "1/1 - 7s - loss: 0.2277 - accuracy: 1.0000 - val_loss: 1.1766 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 79/500\n",
            "1/1 - 7s - loss: 0.2273 - accuracy: 1.0000 - val_loss: 1.0713 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 80/500\n",
            "1/1 - 7s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.0508 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 81/500\n",
            "1/1 - 7s - loss: 0.2281 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 82/500\n",
            "1/1 - 7s - loss: 0.2279 - accuracy: 1.0000 - val_loss: 0.9680 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 83/500\n",
            "1/1 - 7s - loss: 0.2260 - accuracy: 1.0000 - val_loss: 0.9250 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 84/500\n",
            "1/1 - 7s - loss: 0.2271 - accuracy: 1.0000 - val_loss: 1.1480 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 85/500\n",
            "1/1 - 7s - loss: 0.2276 - accuracy: 1.0000 - val_loss: 1.1079 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 86/500\n",
            "1/1 - 7s - loss: 0.2269 - accuracy: 1.0000 - val_loss: 1.1071 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 87/500\n",
            "1/1 - 7s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 1.9924 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 88/500\n",
            "1/1 - 7s - loss: 0.2271 - accuracy: 1.0000 - val_loss: 2.3456 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 89/500\n",
            "1/1 - 7s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 2.2072 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 90/500\n",
            "1/1 - 7s - loss: 0.2274 - accuracy: 1.0000 - val_loss: 2.2305 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 91/500\n",
            "1/1 - 7s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.9668 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 92/500\n",
            "1/1 - 7s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.8007 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 93/500\n",
            "1/1 - 7s - loss: 0.2258 - accuracy: 1.0000 - val_loss: 1.5560 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 94/500\n",
            "1/1 - 7s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.4575 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 95/500\n",
            "1/1 - 7s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.5088 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 96/500\n",
            "1/1 - 7s - loss: 0.2258 - accuracy: 1.0000 - val_loss: 1.5706 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 97/500\n",
            "1/1 - 7s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.4752 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 98/500\n",
            "1/1 - 7s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 1.0720 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 99/500\n",
            "1/1 - 7s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.1697 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 100/500\n",
            "1/1 - 7s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.3516 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 101/500\n",
            "1/1 - 7s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.4402 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 102/500\n",
            "1/1 - 7s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.4972 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 103/500\n",
            "1/1 - 7s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 1.5275 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 104/500\n",
            "1/1 - 7s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 1.5491 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 105/500\n",
            "1/1 - 7s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.4318 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 106/500\n",
            "1/1 - 7s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.3006 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 107/500\n",
            "1/1 - 7s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 108/500\n",
            "1/1 - 7s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.3056 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 109/500\n",
            "1/1 - 7s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.3010 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 110/500\n",
            "1/1 - 7s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.3572 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 111/500\n",
            "1/1 - 7s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.5451 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 112/500\n",
            "1/1 - 7s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.4382 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 113/500\n",
            "1/1 - 7s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.3479 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 114/500\n",
            "1/1 - 7s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.3261 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 115/500\n",
            "1/1 - 7s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.3054 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 116/500\n",
            "1/1 - 7s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.2678 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 117/500\n",
            "1/1 - 7s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.2885 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 118/500\n",
            "1/1 - 7s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.3776 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 119/500\n",
            "1/1 - 7s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.5711 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 120/500\n",
            "1/1 - 7s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.5596 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 121/500\n",
            "1/1 - 7s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.4867 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 122/500\n",
            "1/1 - 7s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.5114 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 123/500\n",
            "1/1 - 7s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.6052 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 124/500\n",
            "1/1 - 7s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.6498 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 125/500\n",
            "1/1 - 7s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 126/500\n",
            "1/1 - 7s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.7591 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 127/500\n",
            "1/1 - 7s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 1.8832 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 128/500\n",
            "1/1 - 7s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 1.8568 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 129/500\n",
            "1/1 - 7s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.7304 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 130/500\n",
            "1/1 - 7s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.4029 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 131/500\n",
            "1/1 - 7s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 132/500\n",
            "1/1 - 7s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.1912 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 133/500\n",
            "1/1 - 7s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.3015 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 134/500\n",
            "1/1 - 7s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.2872 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 135/500\n",
            "1/1 - 7s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 136/500\n",
            "1/1 - 7s - loss: 0.2224 - accuracy: 1.0000 - val_loss: 1.4142 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 137/500\n",
            "1/1 - 7s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.4267 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 138/500\n",
            "1/1 - 7s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.4050 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 139/500\n",
            "1/1 - 7s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.4110 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 140/500\n",
            "1/1 - 7s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.2036 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 141/500\n",
            "1/1 - 7s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.2901 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 142/500\n",
            "1/1 - 7s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.3116 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 143/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.2950 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 144/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.2671 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 145/500\n",
            "1/1 - 7s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.2458 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 146/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.3067 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 147/500\n",
            "1/1 - 7s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.2204 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 148/500\n",
            "1/1 - 7s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.1583 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 149/500\n",
            "1/1 - 7s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.1379 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 150/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.2594 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 151/500\n",
            "1/1 - 7s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 1.1593 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 152/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 153/500\n",
            "1/1 - 7s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 154/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.1295 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 155/500\n",
            "1/1 - 7s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.3679 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 156/500\n",
            "1/1 - 7s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.1440 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 157/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 2.2932 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 158/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 2.0044 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 159/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.9673 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 160/500\n",
            "1/1 - 7s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.8221 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 161/500\n",
            "1/1 - 7s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.7464 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 162/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.1041 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 163/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.3339 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 164/500\n",
            "1/1 - 7s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.6338 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 165/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.2762 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 166/500\n",
            "1/1 - 7s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.1438 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 167/500\n",
            "1/1 - 7s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.2421 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 168/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.5220 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 169/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.5597 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 170/500\n",
            "1/1 - 7s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 2.1110 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 171/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.8685 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 172/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.5451 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 173/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.3881 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 174/500\n",
            "1/1 - 7s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.3727 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 175/500\n",
            "1/1 - 7s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 1.4704 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 176/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.3064 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 177/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.3098 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 178/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.3067 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 179/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.3131 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 180/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.3332 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 181/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.3741 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 182/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.4155 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 183/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.3635 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 184/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 185/500\n",
            "1/1 - 7s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.3174 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 186/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.3096 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 187/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.2975 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 188/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.2948 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 189/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.3153 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 190/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.3205 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 191/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 192/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.3633 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 193/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.4010 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 194/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.3606 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 195/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.3617 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 196/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.3708 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 197/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.3750 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 198/500\n",
            "1/1 - 7s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.3530 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 199/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 200/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.4734 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 201/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.3713 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 202/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.4548 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 203/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.4616 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 204/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.4075 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 205/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.4240 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 206/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.6337 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 207/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.7084 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 208/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 209/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.4234 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 210/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.4536 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 211/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.4337 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 212/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.3759 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 213/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.3423 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 214/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.4628 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 215/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 2.1990 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 216/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 2.5190 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 217/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 2.6490 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 218/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 2.6854 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 219/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 2.7586 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 220/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 2.1359 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 221/500\n",
            "Epoch 222/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 223/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.6673 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 224/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 2.2262 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 225/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 2.3122 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 226/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 2.3077 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 227/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.8694 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 228/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.3192 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 229/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.3867 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 230/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.6218 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 231/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.9701 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 232/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 2.1005 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 233/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.6693 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 234/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 2.0044 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 235/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 236/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.2883 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 237/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 2.4155 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 238/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.6323 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 239/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 2.6692 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 240/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 2.5003 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 241/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 2.3271 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 242/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.3827 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 243/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.2891 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 244/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.6098 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 245/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 2.2949 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 246/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.9350 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 247/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.7305 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 248/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.9396 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 249/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.6951 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 250/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.6134 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 251/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.3592 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 252/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.3260 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 253/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.8062 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 254/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.4829 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 255/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.7149 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 256/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 2.4197 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 257/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.6528 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 258/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.5300 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 259/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.5235 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 260/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.8899 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 261/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.8665 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 262/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.5368 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 263/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.4752 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 264/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.4516 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 265/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.4591 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 266/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.5855 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 267/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.9168 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 268/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.4909 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 269/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.4557 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 270/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.4114 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 271/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.4265 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 272/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.4429 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 273/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.4830 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 274/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.5097 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 275/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.5058 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 276/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.4890 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 277/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.4634 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 278/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.4817 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 279/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.5025 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 280/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.5125 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 281/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.5057 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 282/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.5172 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 283/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.4323 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 284/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.6629 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 285/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.6959 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 286/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.3959 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 287/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3583 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 288/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3469 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 289/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.6501 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 290/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 2.0949 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 291/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.1403 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 292/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.3129 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 293/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.4456 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 294/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.6303 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 295/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.9056 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 296/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 3.1188 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 297/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.7753 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 298/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.8478 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 299/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.8848 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 300/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.7801 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 301/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.5147 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 302/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 3.0661 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 303/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 3.0292 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 304/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.8531 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 305/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 3.0121 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 306/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 3.1481 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 307/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 3.1048 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 308/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 3.0248 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 309/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 3.2262 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 310/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 3.2391 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 311/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 3.0499 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 312/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.8521 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 313/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.8004 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 314/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.7487 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 315/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.8298 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 316/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 2.2150 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 317/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.1811 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 318/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.1745 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 319/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.9684 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 320/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.1019 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 321/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.1239 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 322/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.3093 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 323/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.8027 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 324/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.6516 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 325/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.4360 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 326/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.4137 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 327/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 2.3844 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 328/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.2965 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 329/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.2950 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 330/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.0386 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 331/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.0903 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 332/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.0832 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 333/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.3002 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 334/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.5300 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 335/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.4251 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 336/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.4879 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 337/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.4683 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 338/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.5223 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 339/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.4899 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 340/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.5083 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 341/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.5501 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 342/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.5498 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 343/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.5363 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 344/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.4730 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 345/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.4445 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 346/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.4461 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 347/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.4175 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 348/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.4399 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 349/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.4256 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 350/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.5437 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 351/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.5000 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 352/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.5570 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 353/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.6597 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 354/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 355/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.5624 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 356/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.5806 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 357/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.7683 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 358/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.9813 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 359/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 2.3139 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 360/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 2.8705 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 361/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 3.3517 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 362/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 3.2910 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 363/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 3.3488 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 364/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.7959 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 365/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.8094 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 366/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.4389 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 367/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.4938 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 368/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.4335 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 369/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.5494 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 370/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.0490 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 371/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.5307 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 372/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.7382 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 373/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.4660 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 374/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.5061 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 375/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.5412 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 376/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.5797 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 377/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 378/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.5479 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 379/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.4118 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 380/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.3529 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 381/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.3751 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 382/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.7923 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 383/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.4772 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 384/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.6152 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 385/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.4925 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 386/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.4499 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 387/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.4628 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 388/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.5333 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 389/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.5119 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 390/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.5086 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 391/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.5141 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 392/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.5360 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 393/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.5338 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 394/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.5746 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 395/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.5755 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 396/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.5338 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 397/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.5225 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 398/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4643 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 399/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.5023 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 400/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.8046 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 401/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.7443 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 402/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.7086 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 403/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.4799 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 404/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.5080 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 405/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.5318 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 406/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 2.9932 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 407/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 3.0558 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 408/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.9556 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 409/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.7236 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 410/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.0273 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 411/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.6077 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 412/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.9528 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 413/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.7477 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 414/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.8747 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 415/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.0134 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 416/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.6272 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 417/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.7836 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 418/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.4163 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 419/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.0347 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 420/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.0692 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 421/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 3.1883 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 422/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 3.5578 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 423/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 3.7283 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 424/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 3.7656 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 425/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 3.6603 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 426/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 3.4241 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 427/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 3.3098 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 428/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 3.1345 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 429/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.8389 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 430/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.9905 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 431/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.0286 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 432/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 2.4603 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 433/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.5664 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 434/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 1.5457 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 435/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.6210 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 436/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.6296 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 437/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.6271 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 438/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.5536 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 439/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.4623 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 440/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.5209 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 441/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.4478 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 442/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.4777 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 443/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.5187 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 444/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.9198 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 445/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 2.4079 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 446/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.4997 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 447/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.8933 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 448/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.0802 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 449/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.9869 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 450/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.5907 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 451/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.5215 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 452/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.6911 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 453/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.9834 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 454/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 2.1129 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 455/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.9378 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 456/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.8054 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 457/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.2513 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 458/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.8636 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 459/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.5275 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 460/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.5326 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 461/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.4981 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 462/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.5229 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 463/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.4991 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 464/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.8248 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 465/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.4701 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 466/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.8188 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 467/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.7217 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 468/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.5932 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 469/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.8166 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 470/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.0345 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 471/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.8609 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 472/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.8267 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 473/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.7829 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 474/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.5561 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 475/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.7104 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 476/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.5417 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 477/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.7053 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 478/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.2844 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 479/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.9142 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 480/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.6717 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 481/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.5509 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 482/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.5164 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 483/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.5679 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 484/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.5683 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 485/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.7380 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 486/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 2.2797 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 487/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.2546 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 488/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.8248 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 489/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.7257 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 490/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.6373 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 491/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.6823 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 492/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.8169 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 493/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.6569 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 494/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.5538 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 495/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.5333 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 496/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.5500 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 497/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.4907 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 498/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.7663 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 499/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.8696 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 500/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.6466 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Time Bimodal_EEG+Data_clean = 3579.786881685257 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_clean_2025-01-10_16-36-08\n",
            "saved-model-001-0.2500.hdf5\n",
            "Loss=1.3125 y Accuracy=0.2500\n",
            "\n",
            "saved-model-003-0.5000.hdf5\n",
            "Loss=1.2874 y Accuracy=0.5000\n",
            "\n",
            "saved-model-072-0.5833.hdf5\n",
            "Loss=1.3305 y Accuracy=0.5833\n",
            "\n",
            "saved-model-074-0.6667.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 509 calls to <function Model.make_test_function.<locals>.test_function at 0x7b020fdef9a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=1.3251 y Accuracy=0.6667\n",
            "\n",
            "saved-model-077-0.7500.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 510 calls to <function Model.make_test_function.<locals>.test_function at 0x7b020f418af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=1.2500 y Accuracy=0.7500\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-077-0.7500.hdf5\n",
            "Loss=1.2500 y Accuracy=0.7500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 85 datos r42\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data_clean\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6M-SCDnhV3D",
        "outputId": "13068835-ff94-43b9-cb6a-29529cff5c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 141s - loss: 1.8369 - accuracy: 0.2826 - val_loss: 1.2608 - val_accuracy: 0.5000 - 141s/epoch - 141s/step\n",
            "Epoch 2/500\n",
            "1/1 - 10s - loss: 1.1694 - accuracy: 0.6087 - val_loss: 1.2496 - val_accuracy: 0.5833 - 10s/epoch - 10s/step\n",
            "Epoch 3/500\n",
            "1/1 - 7s - loss: 1.0200 - accuracy: 0.6522 - val_loss: 1.2088 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 4/500\n",
            "1/1 - 7s - loss: 0.9255 - accuracy: 0.7391 - val_loss: 1.2462 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 0.8612 - accuracy: 0.7391 - val_loss: 1.2545 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 7s - loss: 0.7825 - accuracy: 0.8043 - val_loss: 1.3511 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.7467 - accuracy: 0.8478 - val_loss: 1.3505 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.7912 - accuracy: 0.7391 - val_loss: 1.3663 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.6884 - accuracy: 0.7826 - val_loss: 1.3566 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.6139 - accuracy: 0.8478 - val_loss: 1.3704 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 7s - loss: 0.6700 - accuracy: 0.7609 - val_loss: 1.2544 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.5410 - accuracy: 0.8696 - val_loss: 1.2540 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.5324 - accuracy: 0.8696 - val_loss: 1.2537 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.4288 - accuracy: 0.9565 - val_loss: 1.2540 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.5394 - accuracy: 0.8913 - val_loss: 1.2532 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 7s - loss: 0.4343 - accuracy: 0.9348 - val_loss: 1.2519 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.4073 - accuracy: 0.9783 - val_loss: 1.2520 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.3823 - accuracy: 0.9565 - val_loss: 1.2515 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.4032 - accuracy: 0.9565 - val_loss: 1.2518 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.3698 - accuracy: 0.9565 - val_loss: 1.2512 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.4105 - accuracy: 0.9348 - val_loss: 1.2510 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.3382 - accuracy: 0.9783 - val_loss: 1.2515 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.3659 - accuracy: 1.0000 - val_loss: 1.2518 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.3161 - accuracy: 1.0000 - val_loss: 1.2521 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.3008 - accuracy: 1.0000 - val_loss: 1.2525 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.3060 - accuracy: 0.9783 - val_loss: 1.2513 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.3113 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.2943 - accuracy: 1.0000 - val_loss: 1.2538 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.2794 - accuracy: 1.0000 - val_loss: 1.2549 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.2717 - accuracy: 1.0000 - val_loss: 1.2578 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.2694 - accuracy: 1.0000 - val_loss: 1.2603 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 7s - loss: 0.2956 - accuracy: 0.9783 - val_loss: 1.2583 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.2667 - accuracy: 1.0000 - val_loss: 1.2592 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 7s - loss: 0.2731 - accuracy: 1.0000 - val_loss: 1.2623 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.2620 - accuracy: 1.0000 - val_loss: 1.2641 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 7s - loss: 0.2715 - accuracy: 1.0000 - val_loss: 1.2634 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 37/500\n",
            "1/1 - 7s - loss: 0.2577 - accuracy: 1.0000 - val_loss: 1.2670 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.2586 - accuracy: 1.0000 - val_loss: 1.2751 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.2512 - accuracy: 1.0000 - val_loss: 1.2945 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.2472 - accuracy: 1.0000 - val_loss: 1.3210 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.2507 - accuracy: 1.0000 - val_loss: 1.3230 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.2517 - accuracy: 1.0000 - val_loss: 1.3261 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.2518 - accuracy: 1.0000 - val_loss: 1.3211 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.2459 - accuracy: 1.0000 - val_loss: 1.3273 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.2425 - accuracy: 1.0000 - val_loss: 1.3558 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.2413 - accuracy: 1.0000 - val_loss: 1.3674 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.2418 - accuracy: 1.0000 - val_loss: 1.3727 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 7s - loss: 0.2518 - accuracy: 1.0000 - val_loss: 1.3567 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.2503 - accuracy: 1.0000 - val_loss: 1.3741 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 7s - loss: 0.2408 - accuracy: 1.0000 - val_loss: 1.3611 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.2434 - accuracy: 1.0000 - val_loss: 1.3573 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.2413 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 7s - loss: 0.2412 - accuracy: 1.0000 - val_loss: 1.3786 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 54/500\n",
            "1/1 - 7s - loss: 0.2421 - accuracy: 1.0000 - val_loss: 1.4181 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.2378 - accuracy: 1.0000 - val_loss: 1.2616 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.2362 - accuracy: 1.0000 - val_loss: 1.2905 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 7s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 1.2726 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.2368 - accuracy: 1.0000 - val_loss: 1.3953 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.2388 - accuracy: 1.0000 - val_loss: 1.3694 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 7s - loss: 0.2358 - accuracy: 1.0000 - val_loss: 1.3994 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 61/500\n",
            "1/1 - 7s - loss: 0.2390 - accuracy: 1.0000 - val_loss: 1.3945 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 62/500\n",
            "1/1 - 7s - loss: 0.2365 - accuracy: 1.0000 - val_loss: 1.3937 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 63/500\n",
            "1/1 - 7s - loss: 0.2332 - accuracy: 1.0000 - val_loss: 1.4342 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.2393 - accuracy: 1.0000 - val_loss: 1.4543 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.2325 - accuracy: 1.0000 - val_loss: 1.4874 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 7s - loss: 0.2347 - accuracy: 1.0000 - val_loss: 1.4972 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 67/500\n",
            "1/1 - 7s - loss: 0.2390 - accuracy: 1.0000 - val_loss: 1.4523 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 68/500\n",
            "1/1 - 7s - loss: 0.2386 - accuracy: 1.0000 - val_loss: 1.4923 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 69/500\n",
            "1/1 - 7s - loss: 0.2368 - accuracy: 1.0000 - val_loss: 1.5075 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.2340 - accuracy: 1.0000 - val_loss: 1.5078 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 7s - loss: 0.2351 - accuracy: 1.0000 - val_loss: 1.4988 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 72/500\n",
            "1/1 - 7s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 1.5068 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.2326 - accuracy: 1.0000 - val_loss: 1.4987 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 7s - loss: 0.2328 - accuracy: 1.0000 - val_loss: 1.5178 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.2345 - accuracy: 1.0000 - val_loss: 1.5771 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 7s - loss: 0.2299 - accuracy: 1.0000 - val_loss: 1.5695 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 77/500\n",
            "1/1 - 7s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 1.5732 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 78/500\n",
            "1/1 - 7s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 1.5837 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 79/500\n",
            "1/1 - 7s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 1.6114 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 80/500\n",
            "1/1 - 7s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 1.6703 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 81/500\n",
            "1/1 - 7s - loss: 0.2313 - accuracy: 1.0000 - val_loss: 1.6909 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 82/500\n",
            "1/1 - 7s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 1.6798 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 83/500\n",
            "1/1 - 7s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 1.6652 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 84/500\n",
            "1/1 - 7s - loss: 0.2323 - accuracy: 1.0000 - val_loss: 1.7008 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 85/500\n",
            "1/1 - 7s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 1.7910 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 86/500\n",
            "1/1 - 7s - loss: 0.2301 - accuracy: 1.0000 - val_loss: 1.8825 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 87/500\n",
            "1/1 - 7s - loss: 0.2309 - accuracy: 1.0000 - val_loss: 1.7541 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 88/500\n",
            "1/1 - 7s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.7664 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 89/500\n",
            "1/1 - 7s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 1.7119 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 90/500\n",
            "1/1 - 7s - loss: 0.2297 - accuracy: 1.0000 - val_loss: 1.7096 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 91/500\n",
            "1/1 - 7s - loss: 0.2301 - accuracy: 1.0000 - val_loss: 1.3648 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 92/500\n",
            "1/1 - 7s - loss: 0.2278 - accuracy: 1.0000 - val_loss: 1.1303 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 93/500\n",
            "1/1 - 7s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 94/500\n",
            "1/1 - 7s - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 95/500\n",
            "1/1 - 9s - loss: 0.2288 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 96/500\n",
            "1/1 - 7s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 0.9158 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 97/500\n",
            "1/1 - 7s - loss: 0.2277 - accuracy: 1.0000 - val_loss: 0.9199 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 98/500\n",
            "1/1 - 9s - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 99/500\n",
            "1/1 - 7s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 1.1935 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 100/500\n",
            "1/1 - 7s - loss: 0.2271 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 101/500\n",
            "1/1 - 7s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.1203 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 102/500\n",
            "1/1 - 7s - loss: 0.2258 - accuracy: 1.0000 - val_loss: 1.3760 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 103/500\n",
            "1/1 - 7s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.8766 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 104/500\n",
            "1/1 - 7s - loss: 0.2259 - accuracy: 1.0000 - val_loss: 2.1416 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 105/500\n",
            "1/1 - 7s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.7465 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 106/500\n",
            "1/1 - 7s - loss: 0.2265 - accuracy: 1.0000 - val_loss: 1.2345 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 107/500\n",
            "1/1 - 7s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.6250 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 108/500\n",
            "1/1 - 7s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.3668 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 109/500\n",
            "1/1 - 7s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 110/500\n",
            "1/1 - 7s - loss: 0.2271 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 111/500\n",
            "1/1 - 7s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 1.5790 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 112/500\n",
            "1/1 - 7s - loss: 0.2278 - accuracy: 1.0000 - val_loss: 1.6102 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 113/500\n",
            "1/1 - 7s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.4187 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 114/500\n",
            "1/1 - 7s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 115/500\n",
            "1/1 - 7s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.6554 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 116/500\n",
            "1/1 - 7s - loss: 0.2242 - accuracy: 1.0000 - val_loss: 1.6880 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 117/500\n",
            "1/1 - 6s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.6228 - val_accuracy: 0.3333 - 6s/epoch - 6s/step\n",
            "Epoch 118/500\n",
            "1/1 - 7s - loss: 0.2261 - accuracy: 1.0000 - val_loss: 1.3951 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 119/500\n",
            "1/1 - 7s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.1475 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 120/500\n",
            "1/1 - 7s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 1.0963 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 121/500\n",
            "1/1 - 7s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.0809 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 122/500\n",
            "1/1 - 9s - loss: 0.2238 - accuracy: 1.0000 - val_loss: 0.8301 - val_accuracy: 0.8333 - 9s/epoch - 9s/step\n",
            "Epoch 123/500\n",
            "1/1 - 7s - loss: 0.2250 - accuracy: 1.0000 - val_loss: 0.8667 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 124/500\n",
            "1/1 - 7s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.5290 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 125/500\n",
            "1/1 - 7s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 1.7429 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 126/500\n",
            "1/1 - 7s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.7487 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 127/500\n",
            "1/1 - 7s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.7966 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 128/500\n",
            "1/1 - 7s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.7148 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 129/500\n",
            "1/1 - 7s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 1.8076 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 130/500\n",
            "1/1 - 7s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.8263 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 131/500\n",
            "1/1 - 7s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.9209 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 132/500\n",
            "1/1 - 7s - loss: 0.2266 - accuracy: 1.0000 - val_loss: 1.9478 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 133/500\n",
            "1/1 - 7s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.9547 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 134/500\n",
            "1/1 - 7s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.9708 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 135/500\n",
            "1/1 - 7s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 1.9952 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 136/500\n",
            "1/1 - 7s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 2.0253 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 137/500\n",
            "1/1 - 7s - loss: 0.2236 - accuracy: 1.0000 - val_loss: 2.0438 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 138/500\n",
            "1/1 - 7s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.9764 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 139/500\n",
            "1/1 - 7s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.9338 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 140/500\n",
            "1/1 - 7s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.7263 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 141/500\n",
            "1/1 - 7s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.2934 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 142/500\n",
            "1/1 - 7s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 1.1138 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 143/500\n",
            "1/1 - 7s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 144/500\n",
            "1/1 - 7s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.9956 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 145/500\n",
            "1/1 - 7s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.4686 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 146/500\n",
            "1/1 - 7s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 147/500\n",
            "1/1 - 7s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.2294 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 148/500\n",
            "1/1 - 7s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 1.2116 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 149/500\n",
            "1/1 - 7s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 150/500\n",
            "1/1 - 7s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.5428 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 151/500\n",
            "1/1 - 7s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 1.8425 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 152/500\n",
            "1/1 - 7s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.7306 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 153/500\n",
            "1/1 - 7s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 1.8999 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 154/500\n",
            "1/1 - 7s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.8976 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 155/500\n",
            "1/1 - 7s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.9003 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 156/500\n",
            "1/1 - 7s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.8205 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 157/500\n",
            "1/1 - 7s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.6835 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 158/500\n",
            "1/1 - 7s - loss: 0.2230 - accuracy: 1.0000 - val_loss: 1.7753 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 159/500\n",
            "1/1 - 7s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 1.6935 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 160/500\n",
            "1/1 - 7s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 1.7375 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 161/500\n",
            "1/1 - 7s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.1361 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 162/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.1365 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 163/500\n",
            "1/1 - 7s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 1.4078 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 164/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.1645 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 165/500\n",
            "1/1 - 7s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.2892 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 166/500\n",
            "1/1 - 7s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.6008 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 167/500\n",
            "1/1 - 7s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 1.6782 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 168/500\n",
            "1/1 - 7s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.7205 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 169/500\n",
            "1/1 - 7s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.6822 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 170/500\n",
            "1/1 - 7s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.7767 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 171/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 2.0549 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 172/500\n",
            "1/1 - 7s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 2.0932 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 173/500\n",
            "1/1 - 7s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 2.0370 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 174/500\n",
            "1/1 - 7s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 2.4362 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 175/500\n",
            "1/1 - 7s - loss: 0.2212 - accuracy: 1.0000 - val_loss: 2.2630 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 176/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 2.1619 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 177/500\n",
            "1/1 - 7s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.8771 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 178/500\n",
            "1/1 - 7s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 1.1492 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 179/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 2.1682 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 180/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.0503 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 181/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 182/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.9598 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 183/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 184/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.0012 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 185/500\n",
            "1/1 - 7s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 1.0698 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 186/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.0079 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 187/500\n",
            "1/1 - 7s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 188/500\n",
            "1/1 - 7s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.9314 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 189/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.8657 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 190/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 191/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.6232 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 192/500\n",
            "1/1 - 7s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 1.3703 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 193/500\n",
            "1/1 - 7s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 1.1389 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 194/500\n",
            "1/1 - 7s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.6314 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 195/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.2654 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 196/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.1667 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 197/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.0800 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 198/500\n",
            "1/1 - 7s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0706 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 199/500\n",
            "1/1 - 7s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.1005 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 200/500\n",
            "1/1 - 7s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 0.8489 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 201/500\n",
            "1/1 - 7s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.9500 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 202/500\n",
            "1/1 - 7s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.7627 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 203/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 2.0680 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 204/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 2.2523 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 205/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 2.4128 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 206/500\n",
            "1/1 - 7s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 2.2679 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 207/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 2.1438 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 208/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 2.1406 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 209/500\n",
            "1/1 - 7s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.9746 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 210/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.7554 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 211/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 2.2816 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 212/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 2.0230 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 213/500\n",
            "1/1 - 7s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.7824 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 214/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.1813 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 215/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.0714 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 216/500\n",
            "1/1 - 7s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.8886 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 217/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.9865 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 218/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 219/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 220/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 221/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 222/500\n",
            "1/1 - 7s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.4924 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 223/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.2103 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 224/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.3999 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 225/500\n",
            "1/1 - 7s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.1640 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 226/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.2109 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 227/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.7196 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 228/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.8400 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 229/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.4619 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 230/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.7212 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 231/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 2.2393 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 232/500\n",
            "1/1 - 6s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 2.8224 - val_accuracy: 0.3333 - 6s/epoch - 6s/step\n",
            "Epoch 233/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 2.5602 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 234/500\n",
            "1/1 - 6s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 2.8095 - val_accuracy: 0.3333 - 6s/epoch - 6s/step\n",
            "Epoch 235/500\n",
            "1/1 - 7s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 2.9495 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 236/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 3.0634 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 237/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 2.8137 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 238/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 2.7604 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 239/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 2.9570 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 240/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 3.1065 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 241/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 2.7737 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 242/500\n",
            "1/1 - 7s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.8901 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 243/500\n",
            "1/1 - 7s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 2.1131 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 244/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 2.4111 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 245/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.8275 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 246/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.6714 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 247/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 2.9409 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 248/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 3.2621 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 249/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 2.3560 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 250/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.7199 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 251/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.1788 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 252/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.2545 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 253/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.1277 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 254/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.5429 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 255/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 2.7154 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 256/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 2.8247 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 257/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 2.4476 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 258/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 2.4916 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 259/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.5705 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 260/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.1903 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 261/500\n",
            "1/1 - 6s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 1.0269 - val_accuracy: 0.8333 - 6s/epoch - 6s/step\n",
            "Epoch 262/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.0290 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 263/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.3283 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 264/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 265/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.0828 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 266/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.1180 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 267/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 2.6346 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 268/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 2.9555 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 269/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 3.1170 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 270/500\n",
            "1/1 - 7s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 2.9696 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 271/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.4033 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 272/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 273/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.5867 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 274/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 2.5623 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 275/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 2.6691 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 276/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 2.2775 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 277/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.7006 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 278/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.5761 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 279/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 280/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.0856 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 281/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 2.6335 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 282/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 2.6308 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 283/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.1102 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 284/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 2.6888 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 285/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 2.4140 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 286/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 2.9699 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 287/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 2.9583 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 288/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 2.8602 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 289/500\n",
            "1/1 - 7s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 2.8156 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 290/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 2.8998 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 291/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.9440 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 292/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 3.1054 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 293/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 3.0649 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 294/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 3.0429 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 295/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 3.3769 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 296/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 3.4576 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 297/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 3.3336 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 298/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 3.1337 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 299/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 3.0528 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 300/500\n",
            "1/1 - 7s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 3.1792 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 301/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 3.0060 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 302/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 3.0016 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 303/500\n",
            "1/1 - 7s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 3.0381 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 304/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 3.0548 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 305/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 3.0642 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 306/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 3.2914 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 307/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.8820 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 308/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 3.1359 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 309/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 3.2563 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 310/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 3.1812 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 311/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 3.1659 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 312/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 3.1738 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 313/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 2.0773 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 314/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.4713 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 315/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.8072 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 316/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 317/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.1187 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 318/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.2086 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 319/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1580 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 320/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.2938 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 321/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 322/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.2405 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 323/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.1950 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 324/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.1746 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 325/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 326/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 2.0644 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 327/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.2684 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 328/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 3.7987 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 329/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 4.0098 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 330/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 3.7919 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 331/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 3.2605 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 332/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 3.1469 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 333/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 3.2013 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 334/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.6995 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 335/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.7481 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 336/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.8134 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 337/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 2.1186 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 338/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.6364 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 339/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.2663 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 340/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.3230 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 341/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.2401 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 342/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.1959 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 343/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.6946 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 344/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.5963 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 345/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.7267 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 346/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.8891 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 347/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.7303 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 348/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.5557 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 349/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.7492 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 350/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 2.6743 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 351/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.8778 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 352/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 2.6352 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 353/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.4491 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 354/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.7131 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 355/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.1362 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 356/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 357/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.0676 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 358/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.1011 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 359/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 360/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3794 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 361/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.4094 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 362/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3062 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 363/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.1058 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 364/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.7111 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 365/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 2.8039 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 366/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 3.0611 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 367/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 4.2314 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 368/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 4.2552 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 369/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 4.0702 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 370/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 3.8713 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 371/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.9665 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 372/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.2688 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 373/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.3508 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 374/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.9659 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 375/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.7101 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 376/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.3341 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 377/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.2515 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 378/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.2301 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 379/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.4518 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 380/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.3184 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 381/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.3926 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 382/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 2.0002 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 383/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 2.3807 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 384/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.3621 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 385/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.0995 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 386/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.0659 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 387/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.1980 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 388/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.2321 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 389/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.0716 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 390/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.3767 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 391/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.4920 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 392/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.5045 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 393/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.4482 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 394/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.3708 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 395/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.4459 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 396/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.5474 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 397/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.3732 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 398/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 2.2757 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 399/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 400/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.7875 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 401/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.7368 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 402/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.7668 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 403/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.8306 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 404/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.6735 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 405/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.9655 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 406/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.0302 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 407/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.1631 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 408/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.8432 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 409/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.1054 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 410/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.9298 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 411/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.3946 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 412/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.4767 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 413/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.4845 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 414/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.4720 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 415/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.8999 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 416/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.6803 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 417/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.5341 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 418/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.4238 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 419/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.3476 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 420/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 2.9416 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 421/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 2.9272 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 422/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 3.2671 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 423/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 3.2987 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 424/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 3.3043 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 425/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 3.2654 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 426/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 3.2674 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 427/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 3.2263 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 428/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 3.2501 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 429/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 3.1509 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 430/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.9203 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 431/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 2.9916 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 432/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.4679 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 433/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 3.0692 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 434/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 3.3227 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 435/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 3.2204 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 436/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 3.3382 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 437/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 3.3558 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 438/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 3.3114 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 439/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 3.3179 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 440/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.8577 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 441/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.2241 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 442/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 2.8670 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 443/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.7505 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 444/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 445/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.6940 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 446/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.3425 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 447/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.9049 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 448/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.5945 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 449/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.5987 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 450/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.4693 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 451/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 3.2747 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 452/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 3.2819 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 453/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 3.2829 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 454/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 3.3784 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 455/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 3.3762 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 456/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 3.2626 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 457/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 3.1463 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 458/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.5741 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 459/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.9307 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 460/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.7072 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 461/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.9006 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 462/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.3141 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 463/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.6556 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 464/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.7282 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 465/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.3275 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 466/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.3594 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 467/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 1.3207 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 468/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.3418 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 469/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.6263 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 470/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.8268 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 471/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 3.1855 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 472/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 3.1286 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 473/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.6201 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 474/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.6041 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 475/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.5021 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 476/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.4705 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 477/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 3.2355 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 478/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 3.2759 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 479/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.7057 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 480/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.4837 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 481/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.5249 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 482/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.3632 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 483/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.3572 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 484/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.3596 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 485/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.4402 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 486/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3863 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 487/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.4520 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 488/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.5323 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 489/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.4352 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 490/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3833 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 491/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.2854 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 492/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.3145 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 493/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.4467 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 494/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3389 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 495/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.3644 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 496/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.4435 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 497/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.2424 - val_accuracy: 0.8333 - 7s/epoch - 7s/step\n",
            "Epoch 498/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.4729 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 499/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 2.8606 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 500/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.8537 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Time Bimodal_EEG+Data_clean = 3475.9907796382904 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_clean_2025-01-11_17-59-43\n",
            "saved-model-001-0.5000.hdf5\n",
            "Loss=1.2608 y Accuracy=0.5000\n",
            "\n",
            "saved-model-002-0.5833.hdf5\n",
            "Loss=1.2496 y Accuracy=0.5833\n",
            "\n",
            "saved-model-095-0.6667.hdf5\n",
            "Loss=0.8831 y Accuracy=0.6667\n",
            "\n",
            "saved-model-098-0.7500.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 509 calls to <function Model.make_test_function.<locals>.test_function at 0x7f80b3795ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=0.9604 y Accuracy=0.7500\n",
            "\n",
            "saved-model-122-0.8333.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 510 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8129432b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=0.8301 y Accuracy=0.8333\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-122-0.8333.hdf5\n",
            "Loss=0.8301 y Accuracy=0.8333\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 58 datos moca,ifs,demograf\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data_clean\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8iV2BPvTqTg",
        "outputId": "90daea5d-c257-40b1-f9bf-f3372764b574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 144s - loss: 1.8290 - accuracy: 0.3043 - val_loss: 1.2953 - val_accuracy: 0.5000 - 144s/epoch - 144s/step\n",
            "Epoch 2/500\n",
            "1/1 - 7s - loss: 1.6884 - accuracy: 0.3478 - val_loss: 1.2950 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 3/500\n",
            "1/1 - 7s - loss: 1.3073 - accuracy: 0.6087 - val_loss: 1.2758 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 4/500\n",
            "1/1 - 7s - loss: 1.2269 - accuracy: 0.5217 - val_loss: 1.2611 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 1.0604 - accuracy: 0.6087 - val_loss: 1.2745 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 7s - loss: 0.7713 - accuracy: 0.8261 - val_loss: 1.2760 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.7601 - accuracy: 0.7391 - val_loss: 1.2746 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.7736 - accuracy: 0.7174 - val_loss: 1.2789 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.6578 - accuracy: 0.8043 - val_loss: 1.2688 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.6012 - accuracy: 0.8696 - val_loss: 1.2553 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 9s - loss: 0.5507 - accuracy: 0.8261 - val_loss: 1.2877 - val_accuracy: 0.6667 - 9s/epoch - 9s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.4954 - accuracy: 0.8913 - val_loss: 1.3680 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.4900 - accuracy: 0.9130 - val_loss: 1.5782 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.3914 - accuracy: 0.9783 - val_loss: 1.8621 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.4756 - accuracy: 0.9130 - val_loss: 1.9964 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 7s - loss: 0.4556 - accuracy: 0.9130 - val_loss: 2.0714 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.4016 - accuracy: 0.9565 - val_loss: 2.0898 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.3830 - accuracy: 0.9348 - val_loss: 2.0632 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.4620 - accuracy: 0.9348 - val_loss: 2.0502 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.3753 - accuracy: 0.9348 - val_loss: 2.0199 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.3475 - accuracy: 0.9783 - val_loss: 1.9710 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.3187 - accuracy: 1.0000 - val_loss: 1.9141 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.3567 - accuracy: 0.9348 - val_loss: 1.8572 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.3009 - accuracy: 1.0000 - val_loss: 1.8055 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.2823 - accuracy: 1.0000 - val_loss: 1.7745 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.2873 - accuracy: 1.0000 - val_loss: 1.7098 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.2953 - accuracy: 0.9783 - val_loss: 1.4735 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.2665 - accuracy: 1.0000 - val_loss: 1.3823 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.2808 - accuracy: 1.0000 - val_loss: 1.3233 - val_accuracy: 0.0833 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.2532 - accuracy: 1.0000 - val_loss: 1.3467 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.2662 - accuracy: 1.0000 - val_loss: 1.4850 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 7s - loss: 0.2588 - accuracy: 1.0000 - val_loss: 1.5185 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.2531 - accuracy: 1.0000 - val_loss: 1.7045 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 7s - loss: 0.2433 - accuracy: 1.0000 - val_loss: 1.7371 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.2467 - accuracy: 1.0000 - val_loss: 1.7756 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 7s - loss: 0.2382 - accuracy: 1.0000 - val_loss: 1.7671 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 37/500\n",
            "1/1 - 7s - loss: 0.2439 - accuracy: 1.0000 - val_loss: 1.6313 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.2449 - accuracy: 1.0000 - val_loss: 1.6973 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.2354 - accuracy: 1.0000 - val_loss: 1.8206 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.2413 - accuracy: 1.0000 - val_loss: 1.6901 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.2504 - accuracy: 1.0000 - val_loss: 1.5656 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 1.6931 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.2311 - accuracy: 1.0000 - val_loss: 1.6273 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.2333 - accuracy: 1.0000 - val_loss: 1.8050 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.2306 - accuracy: 1.0000 - val_loss: 1.8276 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.2330 - accuracy: 1.0000 - val_loss: 1.7990 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.2337 - accuracy: 1.0000 - val_loss: 1.4366 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 7s - loss: 0.2292 - accuracy: 1.0000 - val_loss: 1.4722 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.2326 - accuracy: 1.0000 - val_loss: 1.4081 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 7s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.5792 - val_accuracy: 0.1667 - 7s/epoch - 7s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.2292 - accuracy: 1.0000 - val_loss: 1.4258 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.2312 - accuracy: 1.0000 - val_loss: 1.5732 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 7s - loss: 0.2291 - accuracy: 1.0000 - val_loss: 1.7730 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 54/500\n",
            "1/1 - 7s - loss: 0.2279 - accuracy: 1.0000 - val_loss: 1.7634 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.2280 - accuracy: 1.0000 - val_loss: 1.8494 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.2269 - accuracy: 1.0000 - val_loss: 1.5721 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 7s - loss: 0.2225 - accuracy: 1.0000 - val_loss: 1.3130 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 1.3799 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.3618 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 7s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.3168 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 61/500\n",
            "1/1 - 7s - loss: 0.2234 - accuracy: 1.0000 - val_loss: 1.3704 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 62/500\n",
            "1/1 - 7s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 1.2930 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 63/500\n",
            "1/1 - 7s - loss: 0.2255 - accuracy: 1.0000 - val_loss: 1.4827 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 1.8101 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.2256 - accuracy: 1.0000 - val_loss: 1.9160 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 7s - loss: 0.2241 - accuracy: 1.0000 - val_loss: 1.8012 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 67/500\n",
            "1/1 - 7s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.8576 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 68/500\n",
            "1/1 - 7s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.5269 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 69/500\n",
            "1/1 - 9s - loss: 0.2248 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.7500 - 9s/epoch - 9s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.3353 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 7s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.8222 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 72/500\n",
            "1/1 - 7s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.9836 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 2.2296 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 7s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 2.3574 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 2.1580 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 7s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 2.1183 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 77/500\n",
            "1/1 - 7s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 2.2454 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 78/500\n",
            "1/1 - 7s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 2.3854 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 79/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 2.5929 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 80/500\n",
            "1/1 - 7s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 2.6044 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 81/500\n",
            "1/1 - 7s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 2.6564 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 82/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 2.5755 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 83/500\n",
            "1/1 - 7s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 2.6803 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 84/500\n",
            "1/1 - 7s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 2.4235 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 85/500\n",
            "1/1 - 7s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 2.4015 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 86/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.9611 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 87/500\n",
            "1/1 - 7s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.9672 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 88/500\n",
            "1/1 - 7s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 2.0612 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 89/500\n",
            "1/1 - 7s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 1.6033 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 90/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 2.5703 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 91/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 2.8149 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 92/500\n",
            "1/1 - 7s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 2.6454 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 93/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 2.3922 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 94/500\n",
            "1/1 - 7s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 1.7606 - val_accuracy: 0.3333 - 7s/epoch - 7s/step\n",
            "Epoch 95/500\n",
            "1/1 - 7s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 1.9552 - val_accuracy: 0.2500 - 7s/epoch - 7s/step\n",
            "Epoch 96/500\n",
            "1/1 - 7s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.8669 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 97/500\n",
            "1/1 - 7s - loss: 0.2193 - accuracy: 1.0000 - val_loss: 2.0301 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 98/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.7442 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 99/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.7023 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 100/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.6736 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 101/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.5720 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 102/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.5680 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 103/500\n",
            "1/1 - 7s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 1.9983 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 104/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.8373 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 105/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.8045 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 106/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.8240 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 107/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.7494 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 108/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.8209 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 109/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.8099 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 110/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.7943 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 111/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.9023 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 112/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.8921 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 113/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.8103 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 114/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.8053 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 115/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.8013 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 116/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.9044 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 117/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.8896 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 118/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.9600 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 119/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.8715 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 120/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.8059 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 121/500\n",
            "1/1 - 7s - loss: 0.2182 - accuracy: 1.0000 - val_loss: 1.7951 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 122/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.7974 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 123/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.7575 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 124/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.6663 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 125/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.6929 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 126/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.8088 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 127/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 1.5126 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 128/500\n",
            "1/1 - 7s - loss: 0.2189 - accuracy: 1.0000 - val_loss: 1.9855 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 129/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.9039 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 130/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.7413 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 131/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.9961 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 132/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.8493 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 133/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.7911 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 134/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.5989 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 135/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.6429 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 136/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.5829 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 137/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.5610 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 138/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.5365 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 139/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.6822 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 140/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.3402 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 141/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.4669 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 142/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.7332 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 143/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.6393 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 144/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.6385 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 145/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.2800 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 146/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.2378 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 147/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.8582 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 148/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.6885 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 149/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.6104 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 150/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.3575 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 151/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.5346 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 152/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.6075 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 153/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.5368 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 154/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.5136 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 155/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.6427 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 156/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.7462 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 157/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.8707 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 158/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.9471 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 159/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.1583 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 160/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.7941 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 161/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.7709 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 162/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.7564 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 163/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.6623 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 164/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 165/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.6281 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 166/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.6452 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 167/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.7125 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 168/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.6480 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 169/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.7205 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 170/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.6297 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 171/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.7464 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 172/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 1.8958 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 173/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.7488 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 174/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 2.0466 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 175/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.5985 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 176/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.6758 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 177/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.6288 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 178/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.6712 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 179/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.9076 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 180/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 2.2404 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 181/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 2.1023 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 182/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 2.1462 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 183/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.6967 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 184/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.5716 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 185/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.5399 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 186/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.7490 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 187/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.5233 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 188/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.5338 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 189/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.5759 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 190/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.9374 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 191/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.0634 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 192/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.7928 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 193/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 2.0539 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 194/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 2.4316 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 195/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.1336 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 196/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.0616 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 197/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 2.2486 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 198/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 2.2345 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 199/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.8279 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 200/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.9205 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 201/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 2.6246 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 202/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 2.2374 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 203/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 2.8294 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 204/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 3.0060 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 205/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 2.1946 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 206/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.8180 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 207/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.8128 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 208/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.8111 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 209/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.8521 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 210/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.8632 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 211/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 1.8339 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 212/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.5279 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 213/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 3.3111 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 214/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 3.4981 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 215/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.4537 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 216/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 2.1985 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 217/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.1156 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 218/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 2.7102 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 219/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 2.4678 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 220/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.8300 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 221/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.8004 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 222/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.2996 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 223/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.7823 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 224/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.8430 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 225/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.9784 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 226/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.8393 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 227/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.8275 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 228/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.7753 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 229/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.7906 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 230/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.8195 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 231/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.8427 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 232/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.7433 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 233/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.7716 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 234/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.6233 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 235/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.5777 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 236/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.4077 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 237/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.4412 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 238/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.4358 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 239/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.4644 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 240/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.7256 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 241/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.5657 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 242/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.4018 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 243/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.3494 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 244/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.4230 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 245/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.5079 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 246/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.6735 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 247/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.7600 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 248/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.8101 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 249/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.8063 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 250/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.7822 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 251/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.7555 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 252/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.7294 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 253/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.7490 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 254/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.5825 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 255/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.4992 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 256/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.6614 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 257/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.7837 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 258/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.8232 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 259/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.9019 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 260/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.8623 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 261/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 2.2640 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 262/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.0914 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 263/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.3016 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 264/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.2786 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 265/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.4724 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 266/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.3069 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 267/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.8395 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 268/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.8275 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 269/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.7630 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 270/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.8112 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 271/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.8198 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 272/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.7366 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 273/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.7873 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 274/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 1.9995 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 275/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 2.6440 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 276/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.5267 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 277/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.5669 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 278/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.7425 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 279/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.6465 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 280/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.9661 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 281/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.8861 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 282/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.1595 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 283/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.4766 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 284/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.9751 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 285/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.9485 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 286/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 2.1097 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 287/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.9908 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 288/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.9541 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 289/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.9653 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 290/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.9576 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 291/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.9423 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 292/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.9181 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 293/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.9375 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 294/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.9820 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 295/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.9704 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 296/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.9564 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 297/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.9431 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 298/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.9275 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 299/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.9631 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 300/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.9396 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 301/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.9541 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 302/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.9638 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 303/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.9303 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 304/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.9825 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 305/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.9323 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 306/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.9543 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 307/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.9645 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 308/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.9345 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 309/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.9100 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 310/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.9619 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 311/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.9608 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 312/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.9494 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 313/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.9442 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 314/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.9485 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 315/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.9447 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 316/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.8106 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 317/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.7004 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 318/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.7700 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 319/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.8122 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 320/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.7014 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 321/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.6918 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 322/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 323/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.6057 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 324/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.7245 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 325/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.7730 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 326/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.2741 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 327/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.5766 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 328/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.9014 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 329/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.7940 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 330/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.9191 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 331/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.1752 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 332/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.3687 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 333/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.5878 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 334/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.6315 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 335/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.4984 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 336/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.0521 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 337/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.9045 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 338/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.8943 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 339/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.9159 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 340/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.9692 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 341/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.0038 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 342/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9482 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 343/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 2.6212 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 344/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.3679 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 345/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.4075 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 346/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 347/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.9849 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 348/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 2.0030 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 349/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.0176 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 350/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.0041 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 351/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.9696 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 352/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.9937 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 353/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.9803 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 354/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.9659 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 355/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.9716 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 356/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9846 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 357/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.0144 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 358/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9754 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 359/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.8772 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 360/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.9683 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 361/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.1844 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 362/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.4384 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 363/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.9549 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 364/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 2.0053 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 365/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.9913 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 366/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.9313 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 367/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.9704 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 368/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 1.7753 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 369/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.7307 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 370/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.6801 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 371/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.7418 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 372/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.9127 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 373/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.9285 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 374/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.9209 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 375/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 1.9250 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 376/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.9013 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 377/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.4344 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 378/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 2.4072 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 379/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.3433 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 380/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.3818 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 381/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.3725 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 382/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 2.4978 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 383/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.5457 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 384/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.3318 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 385/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.2772 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 386/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.3383 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 387/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 2.1609 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 388/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.8725 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 389/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.0286 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 390/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.0804 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 391/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 2.2154 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 392/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.0898 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 393/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 2.8459 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 394/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 2.0209 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 395/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.0093 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 396/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.1781 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 397/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.1650 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 398/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 2.3389 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 399/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.2714 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 400/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 3.0292 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 401/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 3.2232 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 402/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 3.3224 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 403/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 3.6170 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 404/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 3.7197 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 405/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 3.8600 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 406/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 3.7514 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 407/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 3.3041 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 408/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 3.1590 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 409/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 3.1944 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 410/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.5940 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 411/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 3.4152 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 412/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 3.0591 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 413/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.7091 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 414/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.1854 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 415/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.1039 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 416/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.9754 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 417/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.9145 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 418/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.7877 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 419/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.9947 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 420/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.0387 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 421/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.3758 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 422/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.1966 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 423/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.4588 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 424/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.2464 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 425/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.2515 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 426/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.1212 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 427/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.1298 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 428/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.4003 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 429/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.8798 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 430/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.8795 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 431/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.8594 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 432/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.8044 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 433/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.4705 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 434/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.3297 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 435/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.8990 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 436/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.8921 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 437/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.8467 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 438/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.7800 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 439/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.9516 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 440/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.2479 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 441/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.0725 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 442/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.2882 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 443/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.4243 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 444/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.4849 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 445/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.1849 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 446/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.4848 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 447/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.9866 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 448/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.1015 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 449/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.0599 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 450/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.1609 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 451/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.4124 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 452/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.4540 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 453/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.9281 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 454/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.8081 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 455/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.5293 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 456/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.3155 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 457/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 2.4062 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 458/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.8712 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 459/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.5878 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 460/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.7245 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 461/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 3.0704 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 462/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.9661 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 463/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.5608 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 464/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.3858 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 465/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.7622 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 466/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.0056 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 467/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.0634 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 468/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.0855 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 469/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 2.0583 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 470/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.9616 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 471/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.1647 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 472/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 2.9426 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 473/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.4883 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 474/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.3817 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 475/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.9350 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 476/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 2.8035 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 477/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 2.5190 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 478/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.8220 - val_accuracy: 0.6667 - 7s/epoch - 7s/step\n",
            "Epoch 479/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.8646 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 480/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.6351 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 481/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.4520 - val_accuracy: 0.4167 - 7s/epoch - 7s/step\n",
            "Epoch 482/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.9894 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 483/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.8805 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 484/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.8809 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 485/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.8757 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 486/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 3.0246 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 487/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 3.0240 - val_accuracy: 0.5000 - 7s/epoch - 7s/step\n",
            "Epoch 488/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 2.6266 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 489/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 2.7360 - val_accuracy: 0.5833 - 7s/epoch - 7s/step\n",
            "Epoch 490/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.9740 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 491/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 2.0204 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 492/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 2.1293 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 493/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 2.1084 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 494/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.9707 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 495/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 2.0671 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 496/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 2.0836 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 497/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.9974 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 498/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.9445 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 499/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.9858 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Epoch 500/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.9933 - val_accuracy: 0.7500 - 7s/epoch - 7s/step\n",
            "Time Bimodal_EEG+Data_Clean = 3534.0949301719666 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_Clean_2025-01-09_23-06-34\n",
            "saved-model-001-0.5000.hdf5\n",
            "Loss=1.2953 y Accuracy=0.5000\n",
            "\n",
            "saved-model-011-0.6667.hdf5\n",
            "Loss=1.2877 y Accuracy=0.6667\n",
            "\n",
            "saved-model-069-0.7500.hdf5\n",
            "Loss=1.0807 y Accuracy=0.7500\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-069-0.7500.hdf5\n",
            "Loss=1.0807 y Accuracy=0.7500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 58 datos\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data_Clean\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMahpkXFpXkm",
        "outputId": "4340cd2a-c937-4c40-9592-accd248a3212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 134s - loss: 1.8545 - accuracy: 0.3235 - val_loss: 1.2979 - val_accuracy: 0.4118 - 134s/epoch - 134s/step\n",
            "Epoch 2/500\n",
            "1/1 - 7s - loss: 1.5510 - accuracy: 0.3971 - val_loss: 1.2959 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 3/500\n",
            "1/1 - 7s - loss: 1.0372 - accuracy: 0.6324 - val_loss: 1.3285 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 4/500\n",
            "1/1 - 7s - loss: 0.6658 - accuracy: 0.8088 - val_loss: 1.3925 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 0.6128 - accuracy: 0.8382 - val_loss: 1.4207 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 7s - loss: 0.6166 - accuracy: 0.8529 - val_loss: 1.4520 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.5045 - accuracy: 0.9118 - val_loss: 1.5113 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.5362 - accuracy: 0.8824 - val_loss: 1.5378 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.4635 - accuracy: 0.8971 - val_loss: 1.5869 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.3694 - accuracy: 0.9706 - val_loss: 1.6320 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 7s - loss: 0.3770 - accuracy: 0.9706 - val_loss: 1.6669 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.3828 - accuracy: 0.9412 - val_loss: 1.7027 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.3674 - accuracy: 0.9706 - val_loss: 1.7402 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.3284 - accuracy: 0.9853 - val_loss: 1.7637 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.2949 - accuracy: 0.9853 - val_loss: 1.7771 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 7s - loss: 0.2791 - accuracy: 1.0000 - val_loss: 1.7915 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.2866 - accuracy: 1.0000 - val_loss: 1.7934 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.2730 - accuracy: 1.0000 - val_loss: 1.7849 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.2640 - accuracy: 1.0000 - val_loss: 1.7872 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.2598 - accuracy: 1.0000 - val_loss: 1.7881 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.2621 - accuracy: 1.0000 - val_loss: 1.7884 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.2531 - accuracy: 1.0000 - val_loss: 1.7880 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.2434 - accuracy: 1.0000 - val_loss: 1.7927 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.2494 - accuracy: 1.0000 - val_loss: 1.7913 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.2458 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.2423 - accuracy: 1.0000 - val_loss: 1.8048 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.2415 - accuracy: 1.0000 - val_loss: 1.8012 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 1.8030 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.2383 - accuracy: 1.0000 - val_loss: 1.8123 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 1.8123 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.2326 - accuracy: 1.0000 - val_loss: 1.8127 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 7s - loss: 0.2359 - accuracy: 1.0000 - val_loss: 1.8183 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.2315 - accuracy: 1.0000 - val_loss: 1.8040 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 7s - loss: 0.2300 - accuracy: 1.0000 - val_loss: 1.7860 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.2313 - accuracy: 1.0000 - val_loss: 1.7782 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 7s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 1.8109 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 37/500\n",
            "1/1 - 7s - loss: 0.2279 - accuracy: 1.0000 - val_loss: 1.8098 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.2311 - accuracy: 1.0000 - val_loss: 1.8068 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.7973 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.2294 - accuracy: 1.0000 - val_loss: 1.7926 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 1.8084 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.2295 - accuracy: 1.0000 - val_loss: 1.7029 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.2254 - accuracy: 1.0000 - val_loss: 1.6681 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.2270 - accuracy: 1.0000 - val_loss: 1.7301 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.7368 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.2253 - accuracy: 1.0000 - val_loss: 1.5951 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.2247 - accuracy: 1.0000 - val_loss: 1.4593 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 7s - loss: 0.2262 - accuracy: 1.0000 - val_loss: 1.3174 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.2267 - accuracy: 1.0000 - val_loss: 1.5570 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 7s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 1.7372 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.2237 - accuracy: 1.0000 - val_loss: 1.8682 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 1.9396 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 7s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.9353 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 54/500\n",
            "1/1 - 7s - loss: 0.2216 - accuracy: 1.0000 - val_loss: 2.0247 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.2239 - accuracy: 1.0000 - val_loss: 1.9500 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.2231 - accuracy: 1.0000 - val_loss: 1.8642 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 9s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.5879 - val_accuracy: 0.4706 - 9s/epoch - 9s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.2222 - accuracy: 1.0000 - val_loss: 1.7181 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 7s - loss: 0.2214 - accuracy: 1.0000 - val_loss: 1.7315 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 61/500\n",
            "1/1 - 7s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 1.8670 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 62/500\n",
            "1/1 - 7s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.5169 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 63/500\n",
            "1/1 - 7s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 1.2794 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.5109 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.4898 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 11s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.2213 - val_accuracy: 0.5294 - 11s/epoch - 11s/step\n",
            "Epoch 67/500\n",
            "1/1 - 9s - loss: 0.2208 - accuracy: 1.0000 - val_loss: 1.3622 - val_accuracy: 0.7059 - 9s/epoch - 9s/step\n",
            "Epoch 68/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.1820 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 69/500\n",
            "1/1 - 7s - loss: 0.2204 - accuracy: 1.0000 - val_loss: 1.1648 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.4187 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 12s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 1.5730 - val_accuracy: 0.7647 - 12s/epoch - 12s/step\n",
            "Epoch 72/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.3812 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 1.7135 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 7s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.7501 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 1.6228 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 7s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.5932 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 77/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 2.1567 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 78/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 2.3657 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 79/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 2.2634 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 80/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 2.2323 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 81/500\n",
            "1/1 - 7s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 2.3193 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 82/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 2.3666 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 83/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 2.2708 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 84/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 2.1468 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 85/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.9979 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 86/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.4551 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 87/500\n",
            "1/1 - 7s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.4482 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 88/500\n",
            "1/1 - 7s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 1.3509 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 89/500\n",
            "1/1 - 7s - loss: 0.2197 - accuracy: 1.0000 - val_loss: 1.5638 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 90/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.1581 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 91/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 2.3760 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 92/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 2.7434 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 93/500\n",
            "1/1 - 7s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 2.6162 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 94/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.9969 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 95/500\n",
            "1/1 - 7s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.9489 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 96/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.5604 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 97/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.9905 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 98/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.4803 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 99/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 100/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.6854 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 101/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 2.0704 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 102/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.6832 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 103/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.3400 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 104/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.3028 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 105/500\n",
            "1/1 - 7s - loss: 0.2183 - accuracy: 1.0000 - val_loss: 1.4103 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 106/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 1.4385 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 107/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.1720 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 108/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.3913 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 109/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.1579 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 110/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 1.7221 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 111/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.5100 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 112/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.2463 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 113/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.5978 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 114/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.5435 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 115/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.4497 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 116/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.1087 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 117/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 0.8796 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 118/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.0804 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 119/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.2686 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 120/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 1.0223 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 121/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 122/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 1.1079 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 123/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 2.2842 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 124/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.3057 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 125/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.3070 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 126/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 2.0158 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 127/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 2.0645 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 128/500\n",
            "1/1 - 7s - loss: 0.2177 - accuracy: 1.0000 - val_loss: 1.9044 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 129/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.7888 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 130/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 1.7996 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 131/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 1.7450 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 132/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.8514 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 133/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.8967 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 134/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 1.6591 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 135/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.6618 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 136/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.6128 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 137/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 2.1657 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 138/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.7215 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 139/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.4473 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 140/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.0738 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 141/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 0.9933 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 142/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 143/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.3204 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 144/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 2.2426 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 145/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.1020 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 146/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.7560 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 147/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.1159 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 148/500\n",
            "1/1 - 7s - loss: 0.2163 - accuracy: 1.0000 - val_loss: 2.8828 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 149/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.9300 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 150/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 2.7638 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 151/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 2.6264 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 152/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 2.4963 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 153/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 2.2434 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 154/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.4610 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 155/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.3872 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 156/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 157/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 158/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.2398 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 159/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 1.2843 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 160/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.0464 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 161/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.4087 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 162/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.7104 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 163/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.2883 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 164/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.6940 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 165/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.7251 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 166/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 2.0760 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 167/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.3896 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 168/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.6462 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 169/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.2983 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 170/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 2.0577 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 171/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.8252 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 172/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.9065 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 173/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.2450 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 174/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.4991 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 175/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.4652 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 176/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.5723 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 177/500\n",
            "1/1 - 7s - loss: 0.2149 - accuracy: 1.0000 - val_loss: 2.5809 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 178/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 2.6008 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 179/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 4.2485 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 180/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 4.5508 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 181/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 3.8608 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 182/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 3.6034 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 183/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 4.9853 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 184/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 4.1051 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 185/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 5.0381 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 186/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 5.1120 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 187/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 5.0052 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 188/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 4.1564 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 189/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 2.6842 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 190/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 4.6390 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 191/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 3.7907 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 192/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 3.9015 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 193/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 4.7605 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 194/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.4050 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 195/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.3217 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 196/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.3463 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 197/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 2.3340 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 198/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.4044 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 199/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.9054 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 200/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.1315 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 201/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.1855 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 202/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.0042 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 203/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.6425 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 204/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.9816 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 205/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.4514 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 206/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 4.3458 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 207/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 5.2664 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 208/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 4.3979 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 209/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.7676 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 210/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.6058 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 211/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.9770 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 212/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.2715 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 213/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.3527 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 214/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 2.0300 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 215/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.1813 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 216/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.2544 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 217/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 2.1959 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 218/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 4.0077 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 219/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 4.5958 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 220/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 5.2673 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 221/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 4.9104 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 222/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 4.6549 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 223/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 4.3858 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 224/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 4.6486 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 225/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 3.3867 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 226/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 3.2624 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 227/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 2.3513 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 228/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.3619 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 229/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 4.7385 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 230/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 4.6937 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 231/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 4.7375 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 232/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 4.7009 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 233/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 4.6462 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 234/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 3.8406 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 235/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.1958 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 236/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.2826 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 237/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.4208 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 238/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.5202 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 239/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 1.4040 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 240/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 1.9383 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 241/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.3281 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 242/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.2772 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 243/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.2800 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 244/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.1025 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 245/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.2952 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 246/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.3482 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 247/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 2.8422 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 248/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.5365 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 249/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 2.4153 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 250/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.4061 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 251/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.5729 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 252/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 2.4891 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 253/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.3911 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 254/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 2.6228 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 255/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.7733 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 256/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.6454 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 257/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.6023 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 258/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 2.4626 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 259/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 2.1694 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 260/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 1.8371 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 261/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 2.5155 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 262/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 2.2023 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 263/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.3183 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 264/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.5135 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 265/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 1.9805 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 266/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 2.0562 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 267/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 2.3168 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 268/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.3018 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 269/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.6742 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 270/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.8132 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 271/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.8189 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 272/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 3.3394 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 273/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 3.4734 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 274/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 3.4782 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 275/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 3.3941 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 276/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.4866 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 277/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.9471 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 278/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.2437 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 279/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.6360 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 280/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.5764 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 281/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 2.0321 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 282/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.5701 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 283/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.4070 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 284/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.4720 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 285/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.4633 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 286/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.4089 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 287/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.2480 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 288/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.7922 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 289/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.5346 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 290/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.4936 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 291/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.1814 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 292/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.2342 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 293/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.4352 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 294/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.5255 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 295/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.5074 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 296/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.0993 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 297/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 1.6307 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 298/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.2026 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 299/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.2856 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 300/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.5475 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 301/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.5727 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 302/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.7139 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 303/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.8993 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 304/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.9666 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 305/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 2.7750 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 306/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.8589 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 307/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.3097 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 308/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.3114 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 309/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.3825 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 310/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.8279 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 311/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9536 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 312/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.5116 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 313/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.8716 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 314/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.7255 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 315/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.8008 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 316/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.9170 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 317/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.4467 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 318/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.4736 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 319/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.4098 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 320/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 2.5261 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 321/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.2919 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 322/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.9299 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 323/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 2.1920 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 324/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 2.5293 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 325/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 4.0722 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 326/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.7658 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 327/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 2.8903 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 328/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 2.8578 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 329/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.7881 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 330/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.9645 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 331/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 2.9846 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 332/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 4.6698 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 333/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 5.1296 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 334/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.7965 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 335/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.5627 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 336/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 2.3224 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 337/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.3118 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 338/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.7979 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 339/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.9244 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 340/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.4801 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 341/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.5619 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 342/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.6029 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 343/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 2.7931 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 344/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.8704 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 345/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.9574 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 346/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.6738 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 347/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.4992 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 348/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.4674 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 349/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 2.6143 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 350/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 2.4964 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 351/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.6032 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 352/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 2.9849 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 353/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.8364 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 354/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.8848 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 355/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 2.9316 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 356/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 2.9925 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 357/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.7405 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 358/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 2.7698 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 359/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.6929 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 360/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 2.3773 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 361/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 2.4685 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 362/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.4978 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 363/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 2.5712 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 364/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.5815 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 365/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 2.2769 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 366/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.8240 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 367/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.8082 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 368/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.9660 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 369/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.9358 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 370/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.8642 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 371/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.8374 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 372/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 1.9373 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 373/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.1128 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 374/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.7338 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 375/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.9571 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 376/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 3.1784 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 377/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 3.1638 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 378/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.8267 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 379/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.7327 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 380/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.6965 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 381/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 3.5314 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 382/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.7731 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 383/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.6987 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 384/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.9153 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 385/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.8663 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 386/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.6804 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 387/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.9937 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 388/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 2.0668 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 389/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.8133 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 390/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.8010 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 391/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.0184 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 392/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.6186 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 393/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.5655 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 394/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.7643 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 395/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 1.5809 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 396/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.7244 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 397/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.1771 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 398/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.7894 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 399/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.5937 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 400/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.8898 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 401/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 3.6850 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 402/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 3.7375 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 403/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 3.2059 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 404/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 3.1226 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 405/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 2.1271 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 406/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.7955 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 407/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 3.1018 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 408/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 2.0620 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 409/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.8049 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 410/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.8098 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 411/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.8041 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 412/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.3260 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 413/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.9865 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 414/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.2773 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 415/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.2205 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 416/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 2.0936 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 417/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.2097 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 418/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 2.2445 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 419/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.9477 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 420/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.1911 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 421/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.1790 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 422/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.2883 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 423/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 2.4352 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 424/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.6192 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 425/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.7537 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 426/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.9073 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 427/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.7046 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 428/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.9534 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 429/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.8996 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 430/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.7877 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 431/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.7555 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 432/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.7019 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 433/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 3.4731 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 434/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.5489 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 435/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.4354 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 436/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.3364 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 437/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.1724 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 438/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.8034 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 439/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.6816 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 440/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.5068 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 441/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 2.4069 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 442/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.2891 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 443/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 2.5063 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 444/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.7189 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 445/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.6881 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 446/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.7073 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 447/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 2.4336 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 448/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 2.5786 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 449/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 2.8196 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 450/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 2.4187 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 451/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.2401 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 452/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.8174 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 453/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.9344 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 454/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.9661 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 455/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.5198 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 456/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 2.5805 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 457/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 3.0385 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 458/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 2.8346 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 459/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 2.6565 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 460/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 2.3784 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 461/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 2.8194 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 462/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 2.5249 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 463/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 2.5926 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 464/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 2.1001 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 465/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 2.1213 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 466/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 2.0361 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 467/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 2.4327 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 468/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 2.7442 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 469/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 2.8690 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 470/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 2.7915 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 471/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 4.5196 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 472/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 3.9673 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 473/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 5.4857 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 474/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 5.5680 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 475/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 2.6410 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 476/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 2.7142 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 477/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 2.9115 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 478/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 2.9261 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 479/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 2.9345 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 480/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 2.9967 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 481/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 2.9009 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 482/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 4.8429 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 483/500\n",
            "1/1 - 7s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 3.0572 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 484/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 2.7695 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 485/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 2.8026 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 486/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 2.2810 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 487/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 2.7656 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 488/500\n",
            "1/1 - 7s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 2.6075 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 489/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 2.5016 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 490/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 4.5005 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 491/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 2.4868 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 492/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 2.3846 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 493/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 2.4327 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 494/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 2.6450 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 495/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 1.8773 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 496/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 1.9370 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 497/500\n",
            "1/1 - 7s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 2.1158 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 498/500\n",
            "1/1 - 7s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 2.0014 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 499/500\n",
            "1/1 - 7s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 2.2867 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 500/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 3.3247 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Time Bimodal_EEG+Data = 3726.595645427704 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_2025-01-09_01-31-09\n",
            "saved-model-001-0.4118.hdf5\n",
            "Loss=1.2979 y Accuracy=0.4118\n",
            "\n",
            "saved-model-057-0.4706.hdf5\n",
            "Loss=1.5879 y Accuracy=0.4706\n",
            "\n",
            "saved-model-066-0.5294.hdf5\n",
            "Loss=1.2213 y Accuracy=0.5294\n",
            "\n",
            "saved-model-067-0.7059.hdf5\n",
            "Loss=1.3622 y Accuracy=0.7059\n",
            "\n",
            "saved-model-071-0.7647.hdf5\n",
            "Loss=1.5730 y Accuracy=0.7647\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-071-0.7647.hdf5\n",
            "Loss=1.5730 y Accuracy=0.7647\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title channel atention datos e imagenes\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eq_-VmLlT5tc",
        "outputId": "e88140b0-5339-44ea-a406-72be8a5aa4dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 131s - loss: 1.3505 - accuracy: 0.3088 - val_loss: 1.2919 - val_accuracy: 0.3529 - 131s/epoch - 131s/step\n",
            "Epoch 2/500\n",
            "1/1 - 7s - loss: 1.1926 - accuracy: 0.5294 - val_loss: 1.3418 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 3/500\n",
            "1/1 - 9s - loss: 1.0128 - accuracy: 0.6765 - val_loss: 1.2359 - val_accuracy: 0.4118 - 9s/epoch - 9s/step\n",
            "Epoch 4/500\n",
            "1/1 - 7s - loss: 0.7926 - accuracy: 0.8382 - val_loss: 1.3396 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 0.6787 - accuracy: 0.8529 - val_loss: 1.3595 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 7s - loss: 0.6075 - accuracy: 0.8529 - val_loss: 1.4215 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.5525 - accuracy: 0.8382 - val_loss: 1.4231 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.4788 - accuracy: 0.9265 - val_loss: 1.5466 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.4248 - accuracy: 0.9853 - val_loss: 1.3294 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.3898 - accuracy: 0.9706 - val_loss: 1.3976 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 7s - loss: 0.3395 - accuracy: 0.9853 - val_loss: 1.6013 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.2938 - accuracy: 1.0000 - val_loss: 1.6277 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.2711 - accuracy: 1.0000 - val_loss: 1.6428 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.2622 - accuracy: 1.0000 - val_loss: 1.5041 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.2619 - accuracy: 1.0000 - val_loss: 1.4152 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 7s - loss: 0.2574 - accuracy: 1.0000 - val_loss: 1.6471 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.2447 - accuracy: 1.0000 - val_loss: 1.7489 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.2388 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.2264 - accuracy: 1.0000 - val_loss: 1.7271 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.7663 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 1.6071 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.5044 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.3578 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 1.4824 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.2048 - accuracy: 1.0000 - val_loss: 1.3243 - val_accuracy: 0.0000e+00 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.2041 - accuracy: 1.0000 - val_loss: 1.5993 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.2046 - accuracy: 1.0000 - val_loss: 1.2690 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.2036 - accuracy: 1.0000 - val_loss: 1.3827 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.2033 - accuracy: 1.0000 - val_loss: 1.7466 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.2015 - accuracy: 1.0000 - val_loss: 2.1811 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.2003 - accuracy: 1.0000 - val_loss: 2.2158 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 7s - loss: 0.1997 - accuracy: 1.0000 - val_loss: 2.0188 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.1985 - accuracy: 1.0000 - val_loss: 2.1399 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 7s - loss: 0.1975 - accuracy: 1.0000 - val_loss: 1.9843 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.1962 - accuracy: 1.0000 - val_loss: 1.8698 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 7s - loss: 0.1966 - accuracy: 1.0000 - val_loss: 1.5432 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 37/500\n",
            "1/1 - 7s - loss: 0.1974 - accuracy: 1.0000 - val_loss: 2.0376 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.1963 - accuracy: 1.0000 - val_loss: 2.1577 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.1958 - accuracy: 1.0000 - val_loss: 2.5440 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.1960 - accuracy: 1.0000 - val_loss: 2.2967 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.1945 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.1948 - accuracy: 1.0000 - val_loss: 2.1484 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.1944 - accuracy: 1.0000 - val_loss: 1.5865 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.1938 - accuracy: 1.0000 - val_loss: 2.3404 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.1936 - accuracy: 1.0000 - val_loss: 2.3959 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.1935 - accuracy: 1.0000 - val_loss: 2.0296 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.1930 - accuracy: 1.0000 - val_loss: 2.4070 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 7s - loss: 0.1933 - accuracy: 1.0000 - val_loss: 2.1509 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.1929 - accuracy: 1.0000 - val_loss: 2.0527 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 7s - loss: 0.1932 - accuracy: 1.0000 - val_loss: 3.2665 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.1922 - accuracy: 1.0000 - val_loss: 2.4748 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.1929 - accuracy: 1.0000 - val_loss: 2.1021 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 7s - loss: 0.1922 - accuracy: 1.0000 - val_loss: 4.5067 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 54/500\n",
            "1/1 - 7s - loss: 0.1920 - accuracy: 1.0000 - val_loss: 2.7347 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.1920 - accuracy: 1.0000 - val_loss: 3.8719 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.1919 - accuracy: 1.0000 - val_loss: 1.6794 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 7s - loss: 0.1913 - accuracy: 1.0000 - val_loss: 1.5597 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.1919 - accuracy: 1.0000 - val_loss: 1.2961 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.1915 - accuracy: 1.0000 - val_loss: 1.4488 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 7s - loss: 0.1908 - accuracy: 1.0000 - val_loss: 1.3015 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 61/500\n",
            "1/1 - 9s - loss: 0.1909 - accuracy: 1.0000 - val_loss: 1.2404 - val_accuracy: 0.4706 - 9s/epoch - 9s/step\n",
            "Epoch 62/500\n",
            "1/1 - 7s - loss: 0.1912 - accuracy: 1.0000 - val_loss: 1.1914 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 63/500\n",
            "1/1 - 7s - loss: 0.1910 - accuracy: 1.0000 - val_loss: 1.1878 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.1913 - accuracy: 1.0000 - val_loss: 1.2251 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.1910 - accuracy: 1.0000 - val_loss: 1.2109 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 7s - loss: 0.1912 - accuracy: 1.0000 - val_loss: 1.4305 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 67/500\n",
            "1/1 - 7s - loss: 0.1904 - accuracy: 1.0000 - val_loss: 1.5881 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 68/500\n",
            "1/1 - 7s - loss: 0.1902 - accuracy: 1.0000 - val_loss: 1.5930 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 69/500\n",
            "1/1 - 7s - loss: 0.1906 - accuracy: 1.0000 - val_loss: 2.1266 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.1901 - accuracy: 1.0000 - val_loss: 1.8677 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 7s - loss: 0.1904 - accuracy: 1.0000 - val_loss: 1.8792 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 72/500\n",
            "1/1 - 7s - loss: 0.1906 - accuracy: 1.0000 - val_loss: 2.1386 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.1903 - accuracy: 1.0000 - val_loss: 2.4520 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 7s - loss: 0.1900 - accuracy: 1.0000 - val_loss: 2.5642 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.1901 - accuracy: 1.0000 - val_loss: 1.8203 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 7s - loss: 0.1900 - accuracy: 1.0000 - val_loss: 1.4668 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 77/500\n",
            "1/1 - 7s - loss: 0.1898 - accuracy: 1.0000 - val_loss: 1.3328 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 78/500\n",
            "1/1 - 7s - loss: 0.1898 - accuracy: 1.0000 - val_loss: 1.7058 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 79/500\n",
            "1/1 - 7s - loss: 0.1900 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 80/500\n",
            "1/1 - 7s - loss: 0.1903 - accuracy: 1.0000 - val_loss: 1.2580 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 81/500\n",
            "1/1 - 9s - loss: 0.1901 - accuracy: 1.0000 - val_loss: 1.2421 - val_accuracy: 0.7647 - 9s/epoch - 9s/step\n",
            "Epoch 82/500\n",
            "1/1 - 7s - loss: 0.1897 - accuracy: 1.0000 - val_loss: 1.2676 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 83/500\n",
            "1/1 - 7s - loss: 0.1896 - accuracy: 1.0000 - val_loss: 1.3421 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 84/500\n",
            "1/1 - 7s - loss: 0.1896 - accuracy: 1.0000 - val_loss: 1.4487 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 85/500\n",
            "1/1 - 7s - loss: 0.1899 - accuracy: 1.0000 - val_loss: 1.3252 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 86/500\n",
            "1/1 - 7s - loss: 0.1895 - accuracy: 1.0000 - val_loss: 2.3026 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 87/500\n",
            "1/1 - 7s - loss: 0.1892 - accuracy: 1.0000 - val_loss: 3.0004 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 88/500\n",
            "1/1 - 7s - loss: 0.1895 - accuracy: 1.0000 - val_loss: 2.7240 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 89/500\n",
            "1/1 - 7s - loss: 0.1894 - accuracy: 1.0000 - val_loss: 3.1239 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 90/500\n",
            "1/1 - 7s - loss: 0.1893 - accuracy: 1.0000 - val_loss: 2.3259 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 91/500\n",
            "1/1 - 7s - loss: 0.1892 - accuracy: 1.0000 - val_loss: 2.3233 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 92/500\n",
            "1/1 - 7s - loss: 0.1889 - accuracy: 1.0000 - val_loss: 2.1738 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 93/500\n",
            "1/1 - 7s - loss: 0.1890 - accuracy: 1.0000 - val_loss: 2.5503 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 94/500\n",
            "1/1 - 7s - loss: 0.1889 - accuracy: 1.0000 - val_loss: 2.0120 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 95/500\n",
            "1/1 - 7s - loss: 0.1887 - accuracy: 1.0000 - val_loss: 1.8287 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 96/500\n",
            "1/1 - 7s - loss: 0.1890 - accuracy: 1.0000 - val_loss: 2.8522 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 97/500\n",
            "1/1 - 7s - loss: 0.1887 - accuracy: 1.0000 - val_loss: 2.8355 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 98/500\n",
            "1/1 - 7s - loss: 0.1886 - accuracy: 1.0000 - val_loss: 3.2661 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 99/500\n",
            "1/1 - 7s - loss: 0.1884 - accuracy: 1.0000 - val_loss: 2.9431 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 100/500\n",
            "1/1 - 7s - loss: 0.1883 - accuracy: 1.0000 - val_loss: 1.2367 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 101/500\n",
            "1/1 - 7s - loss: 0.1883 - accuracy: 1.0000 - val_loss: 2.7810 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 102/500\n",
            "1/1 - 7s - loss: 0.1881 - accuracy: 1.0000 - val_loss: 2.8710 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 103/500\n",
            "1/1 - 7s - loss: 0.1883 - accuracy: 1.0000 - val_loss: 2.8154 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 104/500\n",
            "1/1 - 7s - loss: 0.1882 - accuracy: 1.0000 - val_loss: 1.1280 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 105/500\n",
            "1/1 - 7s - loss: 0.1885 - accuracy: 1.0000 - val_loss: 1.9043 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 106/500\n",
            "1/1 - 7s - loss: 0.1888 - accuracy: 1.0000 - val_loss: 3.3045 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 107/500\n",
            "1/1 - 7s - loss: 0.1878 - accuracy: 1.0000 - val_loss: 1.3405 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 108/500\n",
            "1/1 - 7s - loss: 0.1884 - accuracy: 1.0000 - val_loss: 1.3860 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 109/500\n",
            "1/1 - 7s - loss: 0.1882 - accuracy: 1.0000 - val_loss: 1.5547 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 110/500\n",
            "1/1 - 7s - loss: 0.1881 - accuracy: 1.0000 - val_loss: 1.8065 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 111/500\n",
            "1/1 - 7s - loss: 0.1883 - accuracy: 1.0000 - val_loss: 1.4551 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 112/500\n",
            "1/1 - 7s - loss: 0.1879 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 113/500\n",
            "1/1 - 7s - loss: 0.1882 - accuracy: 1.0000 - val_loss: 2.8909 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 114/500\n",
            "1/1 - 7s - loss: 0.1883 - accuracy: 1.0000 - val_loss: 1.7933 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 115/500\n",
            "1/1 - 7s - loss: 0.1878 - accuracy: 1.0000 - val_loss: 2.4108 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 116/500\n",
            "1/1 - 7s - loss: 0.1880 - accuracy: 1.0000 - val_loss: 1.7822 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 117/500\n",
            "1/1 - 7s - loss: 0.1878 - accuracy: 1.0000 - val_loss: 1.8801 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 118/500\n",
            "1/1 - 7s - loss: 0.1876 - accuracy: 1.0000 - val_loss: 2.5338 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 119/500\n",
            "1/1 - 7s - loss: 0.1874 - accuracy: 1.0000 - val_loss: 2.6527 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 120/500\n",
            "1/1 - 7s - loss: 0.1874 - accuracy: 1.0000 - val_loss: 3.8686 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 121/500\n",
            "1/1 - 7s - loss: 0.1875 - accuracy: 1.0000 - val_loss: 3.8781 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 122/500\n",
            "1/1 - 7s - loss: 0.1876 - accuracy: 1.0000 - val_loss: 3.2626 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 123/500\n",
            "1/1 - 7s - loss: 0.1873 - accuracy: 1.0000 - val_loss: 3.6980 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 124/500\n",
            "1/1 - 7s - loss: 0.1871 - accuracy: 1.0000 - val_loss: 2.2199 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 125/500\n",
            "1/1 - 7s - loss: 0.1873 - accuracy: 1.0000 - val_loss: 2.4339 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 126/500\n",
            "1/1 - 7s - loss: 0.1871 - accuracy: 1.0000 - val_loss: 1.5041 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 127/500\n",
            "1/1 - 7s - loss: 0.1871 - accuracy: 1.0000 - val_loss: 2.1870 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 128/500\n",
            "1/1 - 7s - loss: 0.1871 - accuracy: 1.0000 - val_loss: 1.7813 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 129/500\n",
            "1/1 - 7s - loss: 0.1870 - accuracy: 1.0000 - val_loss: 2.2940 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 130/500\n",
            "1/1 - 7s - loss: 0.1871 - accuracy: 1.0000 - val_loss: 2.0908 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 131/500\n",
            "1/1 - 7s - loss: 0.1872 - accuracy: 1.0000 - val_loss: 1.9346 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 132/500\n",
            "1/1 - 7s - loss: 0.1869 - accuracy: 1.0000 - val_loss: 2.6893 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 133/500\n",
            "1/1 - 7s - loss: 0.1871 - accuracy: 1.0000 - val_loss: 2.1961 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 134/500\n",
            "1/1 - 7s - loss: 0.1869 - accuracy: 1.0000 - val_loss: 3.9110 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 135/500\n",
            "1/1 - 7s - loss: 0.1870 - accuracy: 1.0000 - val_loss: 2.1404 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 136/500\n",
            "1/1 - 7s - loss: 0.1869 - accuracy: 1.0000 - val_loss: 3.2153 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 137/500\n",
            "1/1 - 7s - loss: 0.1870 - accuracy: 1.0000 - val_loss: 3.6076 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 138/500\n",
            "1/1 - 7s - loss: 0.1869 - accuracy: 1.0000 - val_loss: 1.9431 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 139/500\n",
            "1/1 - 7s - loss: 0.1867 - accuracy: 1.0000 - val_loss: 2.8661 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 140/500\n",
            "1/1 - 7s - loss: 0.1867 - accuracy: 1.0000 - val_loss: 2.2100 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 141/500\n",
            "1/1 - 7s - loss: 0.1863 - accuracy: 1.0000 - val_loss: 2.0185 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 142/500\n",
            "1/1 - 7s - loss: 0.1863 - accuracy: 1.0000 - val_loss: 1.3940 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 143/500\n",
            "1/1 - 7s - loss: 0.1864 - accuracy: 1.0000 - val_loss: 1.2769 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 144/500\n",
            "1/1 - 7s - loss: 0.1867 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 145/500\n",
            "1/1 - 7s - loss: 0.1864 - accuracy: 1.0000 - val_loss: 1.2852 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 146/500\n",
            "1/1 - 7s - loss: 0.1862 - accuracy: 1.0000 - val_loss: 1.2863 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 147/500\n",
            "1/1 - 7s - loss: 0.1865 - accuracy: 1.0000 - val_loss: 1.3800 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 148/500\n",
            "1/1 - 7s - loss: 0.1861 - accuracy: 1.0000 - val_loss: 1.3310 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 149/500\n",
            "1/1 - 7s - loss: 0.1862 - accuracy: 1.0000 - val_loss: 1.6980 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 150/500\n",
            "1/1 - 7s - loss: 0.1861 - accuracy: 1.0000 - val_loss: 2.2829 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 151/500\n",
            "1/1 - 7s - loss: 0.1861 - accuracy: 1.0000 - val_loss: 2.4778 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 152/500\n",
            "1/1 - 7s - loss: 0.1861 - accuracy: 1.0000 - val_loss: 1.4209 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 153/500\n",
            "1/1 - 7s - loss: 0.1858 - accuracy: 1.0000 - val_loss: 1.7355 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 154/500\n",
            "1/1 - 7s - loss: 0.1859 - accuracy: 1.0000 - val_loss: 2.2576 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 155/500\n",
            "1/1 - 7s - loss: 0.1861 - accuracy: 1.0000 - val_loss: 1.9724 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 156/500\n",
            "1/1 - 7s - loss: 0.1855 - accuracy: 1.0000 - val_loss: 2.5843 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 157/500\n",
            "1/1 - 7s - loss: 0.1856 - accuracy: 1.0000 - val_loss: 2.7819 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 158/500\n",
            "1/1 - 7s - loss: 0.1855 - accuracy: 1.0000 - val_loss: 3.0670 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 159/500\n",
            "1/1 - 7s - loss: 0.1854 - accuracy: 1.0000 - val_loss: 2.7061 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 160/500\n",
            "1/1 - 7s - loss: 0.1856 - accuracy: 1.0000 - val_loss: 2.5778 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 161/500\n",
            "1/1 - 7s - loss: 0.1853 - accuracy: 1.0000 - val_loss: 2.0172 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 162/500\n",
            "1/1 - 7s - loss: 0.1855 - accuracy: 1.0000 - val_loss: 2.5043 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 163/500\n",
            "1/1 - 7s - loss: 0.1854 - accuracy: 1.0000 - val_loss: 2.3336 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 164/500\n",
            "1/1 - 7s - loss: 0.1851 - accuracy: 1.0000 - val_loss: 3.4778 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 165/500\n",
            "1/1 - 7s - loss: 0.1852 - accuracy: 1.0000 - val_loss: 3.1895 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 166/500\n",
            "1/1 - 7s - loss: 0.1856 - accuracy: 1.0000 - val_loss: 2.5849 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 167/500\n",
            "1/1 - 7s - loss: 0.1851 - accuracy: 1.0000 - val_loss: 1.3026 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 168/500\n",
            "1/1 - 7s - loss: 0.1852 - accuracy: 1.0000 - val_loss: 1.5676 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 169/500\n",
            "1/1 - 7s - loss: 0.1850 - accuracy: 1.0000 - val_loss: 2.5467 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 170/500\n",
            "1/1 - 7s - loss: 0.1849 - accuracy: 1.0000 - val_loss: 2.4997 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 171/500\n",
            "1/1 - 7s - loss: 0.1849 - accuracy: 1.0000 - val_loss: 2.9057 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 172/500\n",
            "1/1 - 7s - loss: 0.1846 - accuracy: 1.0000 - val_loss: 3.6601 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 173/500\n",
            "1/1 - 7s - loss: 0.1848 - accuracy: 1.0000 - val_loss: 1.9134 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 174/500\n",
            "1/1 - 7s - loss: 0.1849 - accuracy: 1.0000 - val_loss: 2.3852 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 175/500\n",
            "1/1 - 7s - loss: 0.1847 - accuracy: 1.0000 - val_loss: 2.9471 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 176/500\n",
            "1/1 - 7s - loss: 0.1847 - accuracy: 1.0000 - val_loss: 2.3396 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 177/500\n",
            "1/1 - 7s - loss: 0.1844 - accuracy: 1.0000 - val_loss: 1.4438 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 178/500\n",
            "1/1 - 7s - loss: 0.1846 - accuracy: 1.0000 - val_loss: 1.5185 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 179/500\n",
            "1/1 - 7s - loss: 0.1848 - accuracy: 1.0000 - val_loss: 1.8063 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 180/500\n",
            "1/1 - 7s - loss: 0.1846 - accuracy: 1.0000 - val_loss: 1.8120 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 181/500\n",
            "1/1 - 7s - loss: 0.1844 - accuracy: 1.0000 - val_loss: 1.7218 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 182/500\n",
            "1/1 - 7s - loss: 0.1844 - accuracy: 1.0000 - val_loss: 1.5577 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 183/500\n",
            "1/1 - 7s - loss: 0.1842 - accuracy: 1.0000 - val_loss: 1.5945 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 184/500\n",
            "1/1 - 7s - loss: 0.1840 - accuracy: 1.0000 - val_loss: 1.4672 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 185/500\n",
            "1/1 - 7s - loss: 0.1842 - accuracy: 1.0000 - val_loss: 1.4747 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 186/500\n",
            "1/1 - 7s - loss: 0.1840 - accuracy: 1.0000 - val_loss: 1.4493 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 187/500\n",
            "1/1 - 7s - loss: 0.1842 - accuracy: 1.0000 - val_loss: 1.3288 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 188/500\n",
            "1/1 - 7s - loss: 0.1838 - accuracy: 1.0000 - val_loss: 1.8032 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 189/500\n",
            "1/1 - 7s - loss: 0.1841 - accuracy: 1.0000 - val_loss: 2.0434 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 190/500\n",
            "1/1 - 7s - loss: 0.1839 - accuracy: 1.0000 - val_loss: 1.8051 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 191/500\n",
            "1/1 - 7s - loss: 0.1839 - accuracy: 1.0000 - val_loss: 2.2967 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 192/500\n",
            "1/1 - 7s - loss: 0.1839 - accuracy: 1.0000 - val_loss: 1.4308 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 193/500\n",
            "1/1 - 7s - loss: 0.1836 - accuracy: 1.0000 - val_loss: 1.7009 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 194/500\n",
            "1/1 - 7s - loss: 0.1836 - accuracy: 1.0000 - val_loss: 1.5748 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 195/500\n",
            "1/1 - 7s - loss: 0.1836 - accuracy: 1.0000 - val_loss: 2.6393 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 196/500\n",
            "1/1 - 7s - loss: 0.1835 - accuracy: 1.0000 - val_loss: 1.5167 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 197/500\n",
            "1/1 - 7s - loss: 0.1833 - accuracy: 1.0000 - val_loss: 1.3338 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 198/500\n",
            "1/1 - 7s - loss: 0.1834 - accuracy: 1.0000 - val_loss: 1.4557 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 199/500\n",
            "1/1 - 7s - loss: 0.1834 - accuracy: 1.0000 - val_loss: 1.4152 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 200/500\n",
            "1/1 - 7s - loss: 0.1834 - accuracy: 1.0000 - val_loss: 1.4465 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 201/500\n",
            "1/1 - 7s - loss: 0.1832 - accuracy: 1.0000 - val_loss: 1.7471 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 202/500\n",
            "1/1 - 7s - loss: 0.1830 - accuracy: 1.0000 - val_loss: 1.5174 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 203/500\n",
            "1/1 - 7s - loss: 0.1833 - accuracy: 1.0000 - val_loss: 1.9325 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 204/500\n",
            "1/1 - 7s - loss: 0.1832 - accuracy: 1.0000 - val_loss: 2.9763 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 205/500\n",
            "1/1 - 7s - loss: 0.1832 - accuracy: 1.0000 - val_loss: 1.5159 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 206/500\n",
            "1/1 - 7s - loss: 0.1831 - accuracy: 1.0000 - val_loss: 2.1226 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 207/500\n",
            "1/1 - 7s - loss: 0.1828 - accuracy: 1.0000 - val_loss: 1.9901 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 208/500\n",
            "1/1 - 7s - loss: 0.1830 - accuracy: 1.0000 - val_loss: 1.5863 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 209/500\n",
            "1/1 - 7s - loss: 0.1829 - accuracy: 1.0000 - val_loss: 2.1780 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 210/500\n",
            "1/1 - 7s - loss: 0.1828 - accuracy: 1.0000 - val_loss: 1.4146 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 211/500\n",
            "1/1 - 7s - loss: 0.1827 - accuracy: 1.0000 - val_loss: 1.5725 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 212/500\n",
            "1/1 - 7s - loss: 0.1826 - accuracy: 1.0000 - val_loss: 2.8368 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 213/500\n",
            "1/1 - 7s - loss: 0.1826 - accuracy: 1.0000 - val_loss: 1.6764 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 214/500\n",
            "1/1 - 7s - loss: 0.1825 - accuracy: 1.0000 - val_loss: 1.6570 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 215/500\n",
            "1/1 - 7s - loss: 0.1825 - accuracy: 1.0000 - val_loss: 1.5566 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 216/500\n",
            "1/1 - 7s - loss: 0.1826 - accuracy: 1.0000 - val_loss: 1.8554 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 217/500\n",
            "1/1 - 7s - loss: 0.1824 - accuracy: 1.0000 - val_loss: 1.4093 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 218/500\n",
            "1/1 - 7s - loss: 0.1821 - accuracy: 1.0000 - val_loss: 1.3639 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 219/500\n",
            "1/1 - 7s - loss: 0.1823 - accuracy: 1.0000 - val_loss: 1.5442 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 220/500\n",
            "1/1 - 7s - loss: 0.1820 - accuracy: 1.0000 - val_loss: 1.5715 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 221/500\n",
            "1/1 - 7s - loss: 0.1821 - accuracy: 1.0000 - val_loss: 1.5752 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 222/500\n",
            "1/1 - 7s - loss: 0.1822 - accuracy: 1.0000 - val_loss: 2.1056 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 223/500\n",
            "1/1 - 7s - loss: 0.1821 - accuracy: 1.0000 - val_loss: 3.2906 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 224/500\n",
            "1/1 - 7s - loss: 0.1820 - accuracy: 1.0000 - val_loss: 3.7194 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 225/500\n",
            "1/1 - 7s - loss: 0.1818 - accuracy: 1.0000 - val_loss: 3.0335 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 226/500\n",
            "1/1 - 7s - loss: 0.1820 - accuracy: 1.0000 - val_loss: 2.0588 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 227/500\n",
            "1/1 - 7s - loss: 0.1818 - accuracy: 1.0000 - val_loss: 2.8869 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 228/500\n",
            "1/1 - 7s - loss: 0.1816 - accuracy: 1.0000 - val_loss: 3.6684 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 229/500\n",
            "1/1 - 7s - loss: 0.1819 - accuracy: 1.0000 - val_loss: 3.1028 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 230/500\n",
            "1/1 - 7s - loss: 0.1817 - accuracy: 1.0000 - val_loss: 2.2520 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 231/500\n",
            "1/1 - 7s - loss: 0.1815 - accuracy: 1.0000 - val_loss: 2.2836 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 232/500\n",
            "1/1 - 7s - loss: 0.1816 - accuracy: 1.0000 - val_loss: 2.0051 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 233/500\n",
            "1/1 - 7s - loss: 0.1818 - accuracy: 1.0000 - val_loss: 2.4400 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 234/500\n",
            "1/1 - 7s - loss: 0.1814 - accuracy: 1.0000 - val_loss: 3.1892 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 235/500\n",
            "1/1 - 7s - loss: 0.1815 - accuracy: 1.0000 - val_loss: 2.0870 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 236/500\n",
            "1/1 - 7s - loss: 0.1815 - accuracy: 1.0000 - val_loss: 2.2783 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 237/500\n",
            "1/1 - 7s - loss: 0.1817 - accuracy: 1.0000 - val_loss: 1.4684 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 238/500\n",
            "1/1 - 7s - loss: 0.1812 - accuracy: 1.0000 - val_loss: 1.4652 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 239/500\n",
            "1/1 - 7s - loss: 0.1810 - accuracy: 1.0000 - val_loss: 2.0607 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 240/500\n",
            "1/1 - 7s - loss: 0.1811 - accuracy: 1.0000 - val_loss: 1.9109 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 241/500\n",
            "1/1 - 7s - loss: 0.1812 - accuracy: 1.0000 - val_loss: 2.1234 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 242/500\n",
            "1/1 - 7s - loss: 0.1813 - accuracy: 1.0000 - val_loss: 2.3514 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 243/500\n",
            "1/1 - 7s - loss: 0.1810 - accuracy: 1.0000 - val_loss: 1.1617 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 244/500\n",
            "1/1 - 7s - loss: 0.1808 - accuracy: 1.0000 - val_loss: 1.2442 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 245/500\n",
            "1/1 - 7s - loss: 0.1809 - accuracy: 1.0000 - val_loss: 1.4207 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 246/500\n",
            "1/1 - 7s - loss: 0.1807 - accuracy: 1.0000 - val_loss: 1.3207 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 247/500\n",
            "1/1 - 7s - loss: 0.1808 - accuracy: 1.0000 - val_loss: 1.2978 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 248/500\n",
            "1/1 - 7s - loss: 0.1807 - accuracy: 1.0000 - val_loss: 1.1668 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 249/500\n",
            "1/1 - 7s - loss: 0.1806 - accuracy: 1.0000 - val_loss: 1.8470 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 250/500\n",
            "1/1 - 7s - loss: 0.1804 - accuracy: 1.0000 - val_loss: 1.9244 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 251/500\n",
            "1/1 - 7s - loss: 0.1806 - accuracy: 1.0000 - val_loss: 1.8895 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 252/500\n",
            "1/1 - 7s - loss: 0.1803 - accuracy: 1.0000 - val_loss: 1.7777 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 253/500\n",
            "1/1 - 7s - loss: 0.1804 - accuracy: 1.0000 - val_loss: 2.7395 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 254/500\n",
            "1/1 - 7s - loss: 0.1803 - accuracy: 1.0000 - val_loss: 2.6978 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 255/500\n",
            "1/1 - 7s - loss: 0.1803 - accuracy: 1.0000 - val_loss: 2.8491 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 256/500\n",
            "1/1 - 7s - loss: 0.1801 - accuracy: 1.0000 - val_loss: 1.5249 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 257/500\n",
            "1/1 - 7s - loss: 0.1802 - accuracy: 1.0000 - val_loss: 3.2022 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 258/500\n",
            "1/1 - 7s - loss: 0.1801 - accuracy: 1.0000 - val_loss: 2.6688 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 259/500\n",
            "1/1 - 7s - loss: 0.1799 - accuracy: 1.0000 - val_loss: 2.8620 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 260/500\n",
            "1/1 - 7s - loss: 0.1799 - accuracy: 1.0000 - val_loss: 1.7599 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 261/500\n",
            "1/1 - 7s - loss: 0.1800 - accuracy: 1.0000 - val_loss: 1.5793 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 262/500\n",
            "1/1 - 7s - loss: 0.1797 - accuracy: 1.0000 - val_loss: 2.6675 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 263/500\n",
            "1/1 - 7s - loss: 0.1798 - accuracy: 1.0000 - val_loss: 2.9403 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 264/500\n",
            "1/1 - 7s - loss: 0.1795 - accuracy: 1.0000 - val_loss: 1.7987 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 265/500\n",
            "1/1 - 7s - loss: 0.1797 - accuracy: 1.0000 - val_loss: 1.5821 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 266/500\n",
            "1/1 - 7s - loss: 0.1796 - accuracy: 1.0000 - val_loss: 2.2166 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 267/500\n",
            "1/1 - 7s - loss: 0.1795 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 268/500\n",
            "1/1 - 7s - loss: 0.1794 - accuracy: 1.0000 - val_loss: 1.9917 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 269/500\n",
            "1/1 - 7s - loss: 0.1795 - accuracy: 1.0000 - val_loss: 1.3800 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 270/500\n",
            "1/1 - 7s - loss: 0.1793 - accuracy: 1.0000 - val_loss: 2.3323 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 271/500\n",
            "1/1 - 7s - loss: 0.1792 - accuracy: 1.0000 - val_loss: 2.2550 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 272/500\n",
            "1/1 - 7s - loss: 0.1794 - accuracy: 1.0000 - val_loss: 3.1019 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 273/500\n",
            "1/1 - 7s - loss: 0.1792 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 274/500\n",
            "1/1 - 7s - loss: 0.1793 - accuracy: 1.0000 - val_loss: 2.5686 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 275/500\n",
            "1/1 - 7s - loss: 0.1791 - accuracy: 1.0000 - val_loss: 1.8572 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 276/500\n",
            "1/1 - 7s - loss: 0.1790 - accuracy: 1.0000 - val_loss: 1.3928 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 277/500\n",
            "1/1 - 7s - loss: 0.1789 - accuracy: 1.0000 - val_loss: 2.4540 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 278/500\n",
            "1/1 - 7s - loss: 0.1789 - accuracy: 1.0000 - val_loss: 2.4089 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 279/500\n",
            "1/1 - 7s - loss: 0.1787 - accuracy: 1.0000 - val_loss: 1.9525 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 280/500\n",
            "1/1 - 7s - loss: 0.1790 - accuracy: 1.0000 - val_loss: 1.9464 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 281/500\n",
            "1/1 - 7s - loss: 0.1787 - accuracy: 1.0000 - val_loss: 2.4261 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 282/500\n",
            "1/1 - 7s - loss: 0.1786 - accuracy: 1.0000 - val_loss: 2.6008 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 283/500\n",
            "1/1 - 7s - loss: 0.1784 - accuracy: 1.0000 - val_loss: 2.0331 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 284/500\n",
            "1/1 - 7s - loss: 0.1785 - accuracy: 1.0000 - val_loss: 1.2255 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 285/500\n",
            "1/1 - 7s - loss: 0.1784 - accuracy: 1.0000 - val_loss: 1.3403 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 286/500\n",
            "1/1 - 7s - loss: 0.1782 - accuracy: 1.0000 - val_loss: 1.4329 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 287/500\n",
            "1/1 - 7s - loss: 0.1783 - accuracy: 1.0000 - val_loss: 1.7345 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 288/500\n",
            "1/1 - 7s - loss: 0.1782 - accuracy: 1.0000 - val_loss: 2.6090 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 289/500\n",
            "1/1 - 7s - loss: 0.1782 - accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 290/500\n",
            "1/1 - 7s - loss: 0.1779 - accuracy: 1.0000 - val_loss: 2.5814 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 291/500\n",
            "1/1 - 7s - loss: 0.1780 - accuracy: 1.0000 - val_loss: 1.9747 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 292/500\n",
            "1/1 - 7s - loss: 0.1781 - accuracy: 1.0000 - val_loss: 2.1083 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 293/500\n",
            "1/1 - 7s - loss: 0.1780 - accuracy: 1.0000 - val_loss: 3.7206 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 294/500\n",
            "1/1 - 7s - loss: 0.1780 - accuracy: 1.0000 - val_loss: 2.7556 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 295/500\n",
            "1/1 - 7s - loss: 0.1779 - accuracy: 1.0000 - val_loss: 3.5669 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 296/500\n",
            "1/1 - 7s - loss: 0.1777 - accuracy: 1.0000 - val_loss: 2.3162 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 297/500\n",
            "1/1 - 7s - loss: 0.1776 - accuracy: 1.0000 - val_loss: 2.8921 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 298/500\n",
            "1/1 - 7s - loss: 0.1776 - accuracy: 1.0000 - val_loss: 2.5997 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 299/500\n",
            "1/1 - 7s - loss: 0.1775 - accuracy: 1.0000 - val_loss: 2.8510 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 300/500\n",
            "1/1 - 7s - loss: 0.1775 - accuracy: 1.0000 - val_loss: 3.1201 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 301/500\n",
            "1/1 - 7s - loss: 0.1774 - accuracy: 1.0000 - val_loss: 2.9782 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 302/500\n",
            "1/1 - 7s - loss: 0.1776 - accuracy: 1.0000 - val_loss: 1.7328 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 303/500\n",
            "1/1 - 7s - loss: 0.1774 - accuracy: 1.0000 - val_loss: 2.4478 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 304/500\n",
            "1/1 - 7s - loss: 0.1773 - accuracy: 1.0000 - val_loss: 3.0551 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 305/500\n",
            "1/1 - 7s - loss: 0.1771 - accuracy: 1.0000 - val_loss: 2.0706 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 306/500\n",
            "1/1 - 7s - loss: 0.1772 - accuracy: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 307/500\n",
            "1/1 - 7s - loss: 0.1770 - accuracy: 1.0000 - val_loss: 2.6202 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 308/500\n",
            "1/1 - 7s - loss: 0.1770 - accuracy: 1.0000 - val_loss: 2.8912 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 309/500\n",
            "1/1 - 7s - loss: 0.1769 - accuracy: 1.0000 - val_loss: 2.6422 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 310/500\n",
            "1/1 - 7s - loss: 0.1770 - accuracy: 1.0000 - val_loss: 3.0075 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 311/500\n",
            "1/1 - 7s - loss: 0.1769 - accuracy: 1.0000 - val_loss: 2.6085 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 312/500\n",
            "1/1 - 7s - loss: 0.1768 - accuracy: 1.0000 - val_loss: 2.2110 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 313/500\n",
            "1/1 - 7s - loss: 0.1766 - accuracy: 1.0000 - val_loss: 2.9098 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 314/500\n",
            "1/1 - 7s - loss: 0.1768 - accuracy: 1.0000 - val_loss: 3.3205 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 315/500\n",
            "1/1 - 7s - loss: 0.1767 - accuracy: 1.0000 - val_loss: 2.9751 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 316/500\n",
            "1/1 - 7s - loss: 0.1765 - accuracy: 1.0000 - val_loss: 2.8305 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 317/500\n",
            "1/1 - 7s - loss: 0.1765 - accuracy: 1.0000 - val_loss: 3.1182 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 318/500\n",
            "1/1 - 7s - loss: 0.1764 - accuracy: 1.0000 - val_loss: 2.7381 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 319/500\n",
            "1/1 - 7s - loss: 0.1763 - accuracy: 1.0000 - val_loss: 2.0357 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 320/500\n",
            "1/1 - 7s - loss: 0.1764 - accuracy: 1.0000 - val_loss: 2.0900 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 321/500\n",
            "1/1 - 7s - loss: 0.1761 - accuracy: 1.0000 - val_loss: 3.1142 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 322/500\n",
            "1/1 - 7s - loss: 0.1764 - accuracy: 1.0000 - val_loss: 2.5900 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 323/500\n",
            "1/1 - 7s - loss: 0.1760 - accuracy: 1.0000 - val_loss: 1.7893 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 324/500\n",
            "1/1 - 7s - loss: 0.1761 - accuracy: 1.0000 - val_loss: 1.4643 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 325/500\n",
            "1/1 - 7s - loss: 0.1760 - accuracy: 1.0000 - val_loss: 1.4373 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 326/500\n",
            "1/1 - 7s - loss: 0.1760 - accuracy: 1.0000 - val_loss: 2.0291 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 327/500\n",
            "1/1 - 7s - loss: 0.1760 - accuracy: 1.0000 - val_loss: 1.5935 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 328/500\n",
            "1/1 - 7s - loss: 0.1758 - accuracy: 1.0000 - val_loss: 1.8299 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 329/500\n",
            "1/1 - 7s - loss: 0.1757 - accuracy: 1.0000 - val_loss: 1.3635 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 330/500\n",
            "1/1 - 7s - loss: 0.1758 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 331/500\n",
            "1/1 - 7s - loss: 0.1755 - accuracy: 1.0000 - val_loss: 1.9116 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 332/500\n",
            "1/1 - 7s - loss: 0.1756 - accuracy: 1.0000 - val_loss: 2.5034 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 333/500\n",
            "1/1 - 7s - loss: 0.1757 - accuracy: 1.0000 - val_loss: 3.7583 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 334/500\n",
            "1/1 - 7s - loss: 0.1753 - accuracy: 1.0000 - val_loss: 4.0500 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 335/500\n",
            "1/1 - 7s - loss: 0.1754 - accuracy: 1.0000 - val_loss: 3.2121 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 336/500\n",
            "1/1 - 7s - loss: 0.1753 - accuracy: 1.0000 - val_loss: 3.6306 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 337/500\n",
            "1/1 - 7s - loss: 0.1751 - accuracy: 1.0000 - val_loss: 2.6135 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 338/500\n",
            "1/1 - 7s - loss: 0.1752 - accuracy: 1.0000 - val_loss: 1.8238 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 339/500\n",
            "1/1 - 7s - loss: 0.1754 - accuracy: 1.0000 - val_loss: 1.7692 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 340/500\n",
            "1/1 - 7s - loss: 0.1750 - accuracy: 1.0000 - val_loss: 1.8741 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 341/500\n",
            "1/1 - 7s - loss: 0.1751 - accuracy: 1.0000 - val_loss: 2.6708 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 342/500\n",
            "1/1 - 7s - loss: 0.1750 - accuracy: 1.0000 - val_loss: 1.5110 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 343/500\n",
            "1/1 - 7s - loss: 0.1749 - accuracy: 1.0000 - val_loss: 1.7526 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 344/500\n",
            "1/1 - 7s - loss: 0.1747 - accuracy: 1.0000 - val_loss: 3.0099 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 345/500\n",
            "1/1 - 7s - loss: 0.1749 - accuracy: 1.0000 - val_loss: 3.3337 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 346/500\n",
            "1/1 - 7s - loss: 0.1751 - accuracy: 1.0000 - val_loss: 3.2450 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 347/500\n",
            "1/1 - 7s - loss: 0.1745 - accuracy: 1.0000 - val_loss: 2.3954 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 348/500\n",
            "1/1 - 7s - loss: 0.1746 - accuracy: 1.0000 - val_loss: 1.6727 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 349/500\n",
            "1/1 - 7s - loss: 0.1746 - accuracy: 1.0000 - val_loss: 1.9868 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 350/500\n",
            "1/1 - 7s - loss: 0.1743 - accuracy: 1.0000 - val_loss: 2.1708 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 351/500\n",
            "1/1 - 7s - loss: 0.1744 - accuracy: 1.0000 - val_loss: 1.7558 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 352/500\n",
            "1/1 - 7s - loss: 0.1743 - accuracy: 1.0000 - val_loss: 2.3780 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 353/500\n",
            "1/1 - 7s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 2.1562 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 354/500\n",
            "1/1 - 7s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 3.0518 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 355/500\n",
            "1/1 - 7s - loss: 0.1741 - accuracy: 1.0000 - val_loss: 1.7880 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 356/500\n",
            "1/1 - 7s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 2.1329 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 357/500\n",
            "1/1 - 7s - loss: 0.1739 - accuracy: 1.0000 - val_loss: 3.1287 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 358/500\n",
            "1/1 - 7s - loss: 0.1739 - accuracy: 1.0000 - val_loss: 3.0653 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 359/500\n",
            "1/1 - 7s - loss: 0.1739 - accuracy: 1.0000 - val_loss: 2.5978 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 360/500\n",
            "1/1 - 7s - loss: 0.1737 - accuracy: 1.0000 - val_loss: 2.2326 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 361/500\n",
            "1/1 - 7s - loss: 0.1737 - accuracy: 1.0000 - val_loss: 2.7708 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 362/500\n",
            "1/1 - 7s - loss: 0.1736 - accuracy: 1.0000 - val_loss: 3.0663 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 363/500\n",
            "1/1 - 7s - loss: 0.1736 - accuracy: 1.0000 - val_loss: 0.9612 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 364/500\n",
            "1/1 - 7s - loss: 0.1736 - accuracy: 1.0000 - val_loss: 1.3957 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 365/500\n",
            "1/1 - 7s - loss: 0.1734 - accuracy: 1.0000 - val_loss: 1.2590 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 366/500\n",
            "1/1 - 7s - loss: 0.1734 - accuracy: 1.0000 - val_loss: 1.3271 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 367/500\n",
            "1/1 - 7s - loss: 0.1735 - accuracy: 1.0000 - val_loss: 1.2048 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 368/500\n",
            "1/1 - 7s - loss: 0.1732 - accuracy: 1.0000 - val_loss: 1.2357 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 369/500\n",
            "1/1 - 7s - loss: 0.1732 - accuracy: 1.0000 - val_loss: 1.7576 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 370/500\n",
            "1/1 - 7s - loss: 0.1730 - accuracy: 1.0000 - val_loss: 3.0743 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 371/500\n",
            "1/1 - 7s - loss: 0.1730 - accuracy: 1.0000 - val_loss: 3.0078 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 372/500\n",
            "1/1 - 7s - loss: 0.1730 - accuracy: 1.0000 - val_loss: 4.3646 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 373/500\n",
            "1/1 - 7s - loss: 0.1729 - accuracy: 1.0000 - val_loss: 1.8261 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 374/500\n",
            "1/1 - 7s - loss: 0.1729 - accuracy: 1.0000 - val_loss: 1.3806 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 375/500\n",
            "1/1 - 7s - loss: 0.1728 - accuracy: 1.0000 - val_loss: 1.8327 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 376/500\n",
            "1/1 - 7s - loss: 0.1727 - accuracy: 1.0000 - val_loss: 2.4275 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 377/500\n",
            "1/1 - 7s - loss: 0.1725 - accuracy: 1.0000 - val_loss: 1.7250 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 378/500\n",
            "1/1 - 7s - loss: 0.1726 - accuracy: 1.0000 - val_loss: 2.1622 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 379/500\n",
            "1/1 - 7s - loss: 0.1725 - accuracy: 1.0000 - val_loss: 2.1810 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 380/500\n",
            "1/1 - 7s - loss: 0.1724 - accuracy: 1.0000 - val_loss: 2.7631 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 381/500\n",
            "1/1 - 7s - loss: 0.1723 - accuracy: 1.0000 - val_loss: 1.2606 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 382/500\n",
            "1/1 - 7s - loss: 0.1724 - accuracy: 1.0000 - val_loss: 1.3061 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 383/500\n",
            "1/1 - 7s - loss: 0.1723 - accuracy: 1.0000 - val_loss: 1.6947 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 384/500\n",
            "1/1 - 7s - loss: 0.1721 - accuracy: 1.0000 - val_loss: 2.2149 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 385/500\n",
            "1/1 - 7s - loss: 0.1723 - accuracy: 1.0000 - val_loss: 1.7723 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 386/500\n",
            "1/1 - 7s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 1.9335 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 387/500\n",
            "1/1 - 7s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 1.8860 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 388/500\n",
            "1/1 - 7s - loss: 0.1720 - accuracy: 1.0000 - val_loss: 1.7312 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 389/500\n",
            "1/1 - 7s - loss: 0.1720 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 390/500\n",
            "1/1 - 7s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 1.4160 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 391/500\n",
            "1/1 - 7s - loss: 0.1716 - accuracy: 1.0000 - val_loss: 1.4165 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 392/500\n",
            "1/1 - 7s - loss: 0.1718 - accuracy: 1.0000 - val_loss: 1.4175 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 393/500\n",
            "1/1 - 7s - loss: 0.1715 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 394/500\n",
            "1/1 - 7s - loss: 0.1716 - accuracy: 1.0000 - val_loss: 3.1811 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 395/500\n",
            "1/1 - 7s - loss: 0.1714 - accuracy: 1.0000 - val_loss: 1.8021 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 396/500\n",
            "1/1 - 7s - loss: 0.1714 - accuracy: 1.0000 - val_loss: 2.5507 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 397/500\n",
            "1/1 - 7s - loss: 0.1713 - accuracy: 1.0000 - val_loss: 3.7617 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 398/500\n",
            "1/1 - 7s - loss: 0.1712 - accuracy: 1.0000 - val_loss: 2.9190 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 399/500\n",
            "1/1 - 7s - loss: 0.1713 - accuracy: 1.0000 - val_loss: 3.1459 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 400/500\n",
            "1/1 - 7s - loss: 0.1710 - accuracy: 1.0000 - val_loss: 2.7550 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 401/500\n",
            "1/1 - 7s - loss: 0.1710 - accuracy: 1.0000 - val_loss: 1.0207 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 402/500\n",
            "1/1 - 7s - loss: 0.1711 - accuracy: 1.0000 - val_loss: 1.1179 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 403/500\n",
            "1/1 - 7s - loss: 0.1710 - accuracy: 1.0000 - val_loss: 2.2084 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 404/500\n",
            "1/1 - 7s - loss: 0.1709 - accuracy: 1.0000 - val_loss: 2.1520 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 405/500\n",
            "1/1 - 7s - loss: 0.1707 - accuracy: 1.0000 - val_loss: 1.7278 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 406/500\n",
            "1/1 - 7s - loss: 0.1707 - accuracy: 1.0000 - val_loss: 1.5141 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 407/500\n",
            "1/1 - 7s - loss: 0.1708 - accuracy: 1.0000 - val_loss: 1.3822 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 408/500\n",
            "1/1 - 7s - loss: 0.1705 - accuracy: 1.0000 - val_loss: 1.4539 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 409/500\n",
            "1/1 - 7s - loss: 0.1706 - accuracy: 1.0000 - val_loss: 1.6636 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 410/500\n",
            "1/1 - 7s - loss: 0.1706 - accuracy: 1.0000 - val_loss: 2.4315 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 411/500\n",
            "1/1 - 7s - loss: 0.1704 - accuracy: 1.0000 - val_loss: 2.6139 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 412/500\n",
            "1/1 - 7s - loss: 0.1703 - accuracy: 1.0000 - val_loss: 2.5530 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 413/500\n",
            "1/1 - 7s - loss: 0.1703 - accuracy: 1.0000 - val_loss: 2.0470 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 414/500\n",
            "1/1 - 7s - loss: 0.1703 - accuracy: 1.0000 - val_loss: 1.7220 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 415/500\n",
            "1/1 - 7s - loss: 0.1702 - accuracy: 1.0000 - val_loss: 2.4737 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 416/500\n",
            "1/1 - 7s - loss: 0.1701 - accuracy: 1.0000 - val_loss: 2.5154 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 417/500\n",
            "1/1 - 7s - loss: 0.1699 - accuracy: 1.0000 - val_loss: 3.5047 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 418/500\n",
            "1/1 - 7s - loss: 0.1701 - accuracy: 1.0000 - val_loss: 3.6821 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 419/500\n",
            "1/1 - 7s - loss: 0.1698 - accuracy: 1.0000 - val_loss: 3.4380 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 420/500\n",
            "1/1 - 7s - loss: 0.1697 - accuracy: 1.0000 - val_loss: 2.2030 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 421/500\n",
            "1/1 - 7s - loss: 0.1696 - accuracy: 1.0000 - val_loss: 2.8269 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 422/500\n",
            "1/1 - 7s - loss: 0.1697 - accuracy: 1.0000 - val_loss: 2.5650 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 423/500\n",
            "1/1 - 7s - loss: 0.1696 - accuracy: 1.0000 - val_loss: 2.5218 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 424/500\n",
            "1/1 - 7s - loss: 0.1695 - accuracy: 1.0000 - val_loss: 2.2606 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 425/500\n",
            "1/1 - 7s - loss: 0.1695 - accuracy: 1.0000 - val_loss: 2.6556 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 426/500\n",
            "1/1 - 7s - loss: 0.1694 - accuracy: 1.0000 - val_loss: 2.8563 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 427/500\n",
            "1/1 - 7s - loss: 0.1694 - accuracy: 1.0000 - val_loss: 2.6657 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 428/500\n",
            "1/1 - 7s - loss: 0.1693 - accuracy: 1.0000 - val_loss: 2.2422 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 429/500\n",
            "1/1 - 7s - loss: 0.1693 - accuracy: 1.0000 - val_loss: 2.7864 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 430/500\n",
            "1/1 - 7s - loss: 0.1692 - accuracy: 1.0000 - val_loss: 2.5708 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 431/500\n",
            "1/1 - 7s - loss: 0.1692 - accuracy: 1.0000 - val_loss: 3.5861 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 432/500\n",
            "1/1 - 7s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 2.7714 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 433/500\n",
            "1/1 - 7s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 1.6095 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 434/500\n",
            "1/1 - 7s - loss: 0.1689 - accuracy: 1.0000 - val_loss: 1.2670 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 435/500\n",
            "1/1 - 7s - loss: 0.1689 - accuracy: 1.0000 - val_loss: 1.6230 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 436/500\n",
            "1/1 - 7s - loss: 0.1687 - accuracy: 1.0000 - val_loss: 3.3997 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 437/500\n",
            "1/1 - 7s - loss: 0.1688 - accuracy: 1.0000 - val_loss: 3.6334 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 438/500\n",
            "1/1 - 7s - loss: 0.1687 - accuracy: 1.0000 - val_loss: 2.8422 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 439/500\n",
            "1/1 - 7s - loss: 0.1686 - accuracy: 1.0000 - val_loss: 2.5484 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 440/500\n",
            "1/1 - 7s - loss: 0.1686 - accuracy: 1.0000 - val_loss: 2.9423 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 441/500\n",
            "1/1 - 7s - loss: 0.1685 - accuracy: 1.0000 - val_loss: 3.6022 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 442/500\n",
            "1/1 - 7s - loss: 0.1684 - accuracy: 1.0000 - val_loss: 2.7651 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 443/500\n",
            "1/1 - 7s - loss: 0.1683 - accuracy: 1.0000 - val_loss: 2.4572 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 444/500\n",
            "1/1 - 7s - loss: 0.1682 - accuracy: 1.0000 - val_loss: 2.8711 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 445/500\n",
            "1/1 - 7s - loss: 0.1681 - accuracy: 1.0000 - val_loss: 2.5564 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 446/500\n",
            "1/1 - 7s - loss: 0.1680 - accuracy: 1.0000 - val_loss: 2.2077 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 447/500\n",
            "1/1 - 7s - loss: 0.1679 - accuracy: 1.0000 - val_loss: 2.9449 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 448/500\n",
            "1/1 - 7s - loss: 0.1679 - accuracy: 1.0000 - val_loss: 2.2135 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 449/500\n",
            "1/1 - 7s - loss: 0.1678 - accuracy: 1.0000 - val_loss: 2.9497 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 450/500\n",
            "1/1 - 7s - loss: 0.1679 - accuracy: 1.0000 - val_loss: 2.6254 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 451/500\n",
            "1/1 - 7s - loss: 0.1677 - accuracy: 1.0000 - val_loss: 2.7481 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 452/500\n",
            "1/1 - 7s - loss: 0.1676 - accuracy: 1.0000 - val_loss: 2.8521 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 453/500\n",
            "1/1 - 7s - loss: 0.1675 - accuracy: 1.0000 - val_loss: 2.0983 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 454/500\n",
            "1/1 - 7s - loss: 0.1676 - accuracy: 1.0000 - val_loss: 1.5772 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 455/500\n",
            "1/1 - 7s - loss: 0.1673 - accuracy: 1.0000 - val_loss: 1.4110 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 456/500\n",
            "1/1 - 7s - loss: 0.1675 - accuracy: 1.0000 - val_loss: 2.3701 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 457/500\n",
            "1/1 - 7s - loss: 0.1672 - accuracy: 1.0000 - val_loss: 3.1989 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 458/500\n",
            "1/1 - 7s - loss: 0.1672 - accuracy: 1.0000 - val_loss: 2.9757 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 459/500\n",
            "1/1 - 7s - loss: 0.1671 - accuracy: 1.0000 - val_loss: 2.8501 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 460/500\n",
            "1/1 - 7s - loss: 0.1671 - accuracy: 1.0000 - val_loss: 2.6091 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 461/500\n",
            "1/1 - 7s - loss: 0.1671 - accuracy: 1.0000 - val_loss: 1.7620 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 462/500\n",
            "1/1 - 7s - loss: 0.1669 - accuracy: 1.0000 - val_loss: 1.9152 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 463/500\n",
            "1/1 - 7s - loss: 0.1669 - accuracy: 1.0000 - val_loss: 1.9054 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 464/500\n",
            "1/1 - 7s - loss: 0.1668 - accuracy: 1.0000 - val_loss: 2.2172 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 465/500\n",
            "1/1 - 7s - loss: 0.1668 - accuracy: 1.0000 - val_loss: 2.2522 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 466/500\n",
            "1/1 - 7s - loss: 0.1667 - accuracy: 1.0000 - val_loss: 2.2392 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 467/500\n",
            "1/1 - 7s - loss: 0.1665 - accuracy: 1.0000 - val_loss: 1.7098 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 468/500\n",
            "1/1 - 7s - loss: 0.1667 - accuracy: 1.0000 - val_loss: 1.9390 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 469/500\n",
            "1/1 - 7s - loss: 0.1664 - accuracy: 1.0000 - val_loss: 1.8448 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 470/500\n",
            "1/1 - 7s - loss: 0.1664 - accuracy: 1.0000 - val_loss: 2.3519 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 471/500\n",
            "1/1 - 7s - loss: 0.1664 - accuracy: 1.0000 - val_loss: 3.6143 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 472/500\n",
            "1/1 - 7s - loss: 0.1662 - accuracy: 1.0000 - val_loss: 3.0685 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 473/500\n",
            "1/1 - 7s - loss: 0.1662 - accuracy: 1.0000 - val_loss: 2.0316 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 474/500\n",
            "1/1 - 7s - loss: 0.1662 - accuracy: 1.0000 - val_loss: 2.4394 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 475/500\n",
            "1/1 - 7s - loss: 0.1660 - accuracy: 1.0000 - val_loss: 3.1444 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 476/500\n",
            "1/1 - 7s - loss: 0.1659 - accuracy: 1.0000 - val_loss: 2.3389 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 477/500\n",
            "1/1 - 7s - loss: 0.1659 - accuracy: 1.0000 - val_loss: 2.8045 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 478/500\n",
            "1/1 - 7s - loss: 0.1659 - accuracy: 1.0000 - val_loss: 2.2242 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 479/500\n",
            "1/1 - 7s - loss: 0.1657 - accuracy: 1.0000 - val_loss: 2.3273 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 480/500\n",
            "1/1 - 7s - loss: 0.1656 - accuracy: 1.0000 - val_loss: 1.8555 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 481/500\n",
            "1/1 - 7s - loss: 0.1656 - accuracy: 1.0000 - val_loss: 2.2578 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 482/500\n",
            "1/1 - 7s - loss: 0.1654 - accuracy: 1.0000 - val_loss: 2.6338 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 483/500\n",
            "1/1 - 7s - loss: 0.1655 - accuracy: 1.0000 - val_loss: 1.6331 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 484/500\n",
            "1/1 - 7s - loss: 0.1654 - accuracy: 1.0000 - val_loss: 1.9114 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 485/500\n",
            "1/1 - 7s - loss: 0.1653 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 486/500\n",
            "1/1 - 7s - loss: 0.1652 - accuracy: 1.0000 - val_loss: 2.5267 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 487/500\n",
            "1/1 - 7s - loss: 0.1652 - accuracy: 1.0000 - val_loss: 2.5734 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 488/500\n",
            "1/1 - 7s - loss: 0.1651 - accuracy: 1.0000 - val_loss: 2.4631 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 489/500\n",
            "1/1 - 7s - loss: 0.1652 - accuracy: 1.0000 - val_loss: 2.4133 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 490/500\n",
            "1/1 - 7s - loss: 0.1650 - accuracy: 1.0000 - val_loss: 2.1267 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 491/500\n",
            "1/1 - 7s - loss: 0.1650 - accuracy: 1.0000 - val_loss: 1.1320 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 492/500\n",
            "1/1 - 7s - loss: 0.1649 - accuracy: 1.0000 - val_loss: 1.8327 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 493/500\n",
            "1/1 - 7s - loss: 0.1648 - accuracy: 1.0000 - val_loss: 3.2099 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 494/500\n",
            "1/1 - 7s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 3.1802 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 495/500\n",
            "1/1 - 7s - loss: 0.1645 - accuracy: 1.0000 - val_loss: 2.8863 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 496/500\n",
            "1/1 - 7s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 2.2996 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 497/500\n",
            "1/1 - 7s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 2.7957 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 498/500\n",
            "1/1 - 7s - loss: 0.1646 - accuracy: 1.0000 - val_loss: 3.7275 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 499/500\n",
            "1/1 - 7s - loss: 0.1644 - accuracy: 1.0000 - val_loss: 3.6152 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 500/500\n",
            "1/1 - 7s - loss: 0.1643 - accuracy: 1.0000 - val_loss: 1.7526 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Time Bimodal_EEG+Data = 3626.130590438843 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_2025-01-08_23-46-14\n",
            "saved-model-001-0.3529.hdf5\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Unknown layer: 'DigitCapsuleLayer'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a0d33661fe24>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Llamar a la función de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m results = train(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_train1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Datos planos y Wavs para entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-1da19bb19914>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train1, X_train, y_train, X_valid1, X_valid, y_valid, X_test1, X_test, y_test, batch_size, epochs, model_name)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mFinal_Results_Test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-1da19bb19914>\u001b[0m in \u001b[0;36mFinal_Results_Test\u001b[0;34m(PATH_trained_models, X_test1, X_test, y_test)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_trained_models\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Now X_test1 and X_test are available here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/serialization.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    363\u001b[0m     )\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m             \u001b[0;34mf\"Unknown {printable_module_name}: '{class_name}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;34m\"Please ensure you are using a `keras.utils.custom_object_scope` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: 'DigitCapsuleLayer'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
          ]
        }
      ],
      "source": [
        "# @title capsnet\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtuqsLYwCgz3",
        "outputId": "541e0c1c-2281-4b63-eb02-690cd26ae78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 149s - loss: 1.5832 - accuracy: 0.3824 - val_loss: 1.3066 - val_accuracy: 0.3529 - 149s/epoch - 149s/step\n",
            "Epoch 2/500\n",
            "1/1 - 7s - loss: 1.5231 - accuracy: 0.3529 - val_loss: 1.5012 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 3/500\n",
            "1/1 - 7s - loss: 1.5444 - accuracy: 0.4412 - val_loss: 1.6452 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 4/500\n",
            "1/1 - 7s - loss: 1.1763 - accuracy: 0.5735 - val_loss: 1.5600 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 0.9642 - accuracy: 0.6324 - val_loss: 1.4397 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 9s - loss: 0.8401 - accuracy: 0.6765 - val_loss: 1.3237 - val_accuracy: 0.4118 - 9s/epoch - 9s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.7647 - accuracy: 0.7500 - val_loss: 1.3979 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.8223 - accuracy: 0.7500 - val_loss: 1.4716 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.7042 - accuracy: 0.7941 - val_loss: 1.5176 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.7085 - accuracy: 0.7500 - val_loss: 1.5618 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 7s - loss: 0.7214 - accuracy: 0.7353 - val_loss: 1.5744 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.7184 - accuracy: 0.7500 - val_loss: 1.5824 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.7143 - accuracy: 0.7941 - val_loss: 1.5897 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.6218 - accuracy: 0.7794 - val_loss: 1.5753 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.6349 - accuracy: 0.7794 - val_loss: 1.5651 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 7s - loss: 0.6032 - accuracy: 0.8235 - val_loss: 1.5655 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.6446 - accuracy: 0.7647 - val_loss: 1.5735 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.5708 - accuracy: 0.8382 - val_loss: 1.5652 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.5851 - accuracy: 0.8088 - val_loss: 1.5574 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.5952 - accuracy: 0.7794 - val_loss: 1.5558 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.5701 - accuracy: 0.8529 - val_loss: 1.5616 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.6045 - accuracy: 0.8382 - val_loss: 1.5688 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.5633 - accuracy: 0.8088 - val_loss: 1.5761 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.5578 - accuracy: 0.8235 - val_loss: 1.5832 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.5681 - accuracy: 0.8088 - val_loss: 1.6001 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.5509 - accuracy: 0.8382 - val_loss: 1.6909 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.5528 - accuracy: 0.8088 - val_loss: 1.7733 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.5534 - accuracy: 0.7941 - val_loss: 2.0074 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.5369 - accuracy: 0.8235 - val_loss: 2.1101 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.5156 - accuracy: 0.8529 - val_loss: 2.0488 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.5062 - accuracy: 0.8529 - val_loss: 2.0379 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 7s - loss: 0.5092 - accuracy: 0.8676 - val_loss: 2.1053 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.5267 - accuracy: 0.7794 - val_loss: 2.1203 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 7s - loss: 0.4810 - accuracy: 0.8676 - val_loss: 2.0807 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.4686 - accuracy: 0.8971 - val_loss: 1.8826 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 7s - loss: 0.4687 - accuracy: 0.8529 - val_loss: 2.0546 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 37/500\n",
            "1/1 - 7s - loss: 0.4590 - accuracy: 0.8971 - val_loss: 2.2153 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.4641 - accuracy: 0.8824 - val_loss: 2.1009 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.4252 - accuracy: 0.9118 - val_loss: 1.5972 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.3996 - accuracy: 0.9265 - val_loss: 1.2696 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.3852 - accuracy: 0.9265 - val_loss: 1.4557 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.3670 - accuracy: 0.9706 - val_loss: 1.5294 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.3823 - accuracy: 0.9412 - val_loss: 1.3467 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.3679 - accuracy: 0.9265 - val_loss: 1.9262 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.3682 - accuracy: 0.9412 - val_loss: 1.2673 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.3012 - accuracy: 0.9853 - val_loss: 1.8288 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.3393 - accuracy: 0.9559 - val_loss: 2.1446 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 7s - loss: 0.3515 - accuracy: 0.9412 - val_loss: 2.1182 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.3052 - accuracy: 0.9853 - val_loss: 2.1125 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 7s - loss: 0.3233 - accuracy: 0.9853 - val_loss: 1.6745 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.3258 - accuracy: 0.9853 - val_loss: 2.1333 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.2832 - accuracy: 1.0000 - val_loss: 2.2115 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 7s - loss: 0.2707 - accuracy: 1.0000 - val_loss: 2.2458 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 54/500\n",
            "1/1 - 9s - loss: 0.2619 - accuracy: 1.0000 - val_loss: 1.1830 - val_accuracy: 0.5294 - 9s/epoch - 9s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.2635 - accuracy: 1.0000 - val_loss: 1.3386 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.2562 - accuracy: 1.0000 - val_loss: 1.6356 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 7s - loss: 0.2576 - accuracy: 1.0000 - val_loss: 1.3919 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.2546 - accuracy: 1.0000 - val_loss: 1.7761 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.2563 - accuracy: 0.9853 - val_loss: 1.9475 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 7s - loss: 0.2520 - accuracy: 1.0000 - val_loss: 2.1598 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 61/500\n",
            "1/1 - 10s - loss: 0.2438 - accuracy: 1.0000 - val_loss: 0.9090 - val_accuracy: 0.7647 - 10s/epoch - 10s/step\n",
            "Epoch 62/500\n",
            "1/1 - 7s - loss: 0.2424 - accuracy: 1.0000 - val_loss: 1.1642 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 63/500\n",
            "1/1 - 7s - loss: 0.2394 - accuracy: 1.0000 - val_loss: 1.1328 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.2395 - accuracy: 1.0000 - val_loss: 1.2664 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.2346 - accuracy: 1.0000 - val_loss: 1.2913 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 7s - loss: 0.2331 - accuracy: 1.0000 - val_loss: 1.0666 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 67/500\n",
            "1/1 - 7s - loss: 0.2321 - accuracy: 1.0000 - val_loss: 1.1653 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 68/500\n",
            "1/1 - 7s - loss: 0.2371 - accuracy: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 69/500\n",
            "1/1 - 7s - loss: 0.2305 - accuracy: 1.0000 - val_loss: 1.0323 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.2308 - accuracy: 1.0000 - val_loss: 1.0950 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 7s - loss: 0.2291 - accuracy: 1.0000 - val_loss: 1.3623 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 72/500\n",
            "1/1 - 7s - loss: 0.2298 - accuracy: 1.0000 - val_loss: 1.5896 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.2290 - accuracy: 1.0000 - val_loss: 1.7979 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 7s - loss: 0.2276 - accuracy: 1.0000 - val_loss: 1.7673 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.2284 - accuracy: 1.0000 - val_loss: 1.8743 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 7s - loss: 0.2272 - accuracy: 1.0000 - val_loss: 1.9413 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 77/500\n",
            "1/1 - 7s - loss: 0.2276 - accuracy: 1.0000 - val_loss: 1.9381 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 78/500\n",
            "1/1 - 7s - loss: 0.2273 - accuracy: 1.0000 - val_loss: 1.8677 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 79/500\n",
            "1/1 - 7s - loss: 0.2253 - accuracy: 1.0000 - val_loss: 1.8241 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 80/500\n",
            "1/1 - 7s - loss: 0.2252 - accuracy: 1.0000 - val_loss: 1.7723 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 81/500\n",
            "1/1 - 7s - loss: 0.2246 - accuracy: 1.0000 - val_loss: 1.6811 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 82/500\n",
            "1/1 - 7s - loss: 0.2244 - accuracy: 1.0000 - val_loss: 1.6200 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 83/500\n",
            "1/1 - 7s - loss: 0.2263 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 84/500\n",
            "1/1 - 7s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 0.9743 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 85/500\n",
            "1/1 - 7s - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.9592 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 86/500\n",
            "1/1 - 7s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.9769 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 87/500\n",
            "1/1 - 7s - loss: 0.2227 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 88/500\n",
            "1/1 - 7s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 89/500\n",
            "1/1 - 7s - loss: 0.2229 - accuracy: 1.0000 - val_loss: 1.0127 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 90/500\n",
            "1/1 - 7s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 1.0401 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 91/500\n",
            "1/1 - 7s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 92/500\n",
            "1/1 - 7s - loss: 0.2217 - accuracy: 1.0000 - val_loss: 1.0604 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 93/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.0834 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 94/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 1.0678 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 95/500\n",
            "1/1 - 7s - loss: 0.2211 - accuracy: 1.0000 - val_loss: 1.1104 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 96/500\n",
            "1/1 - 7s - loss: 0.2205 - accuracy: 1.0000 - val_loss: 1.1350 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 97/500\n",
            "1/1 - 7s - loss: 0.2206 - accuracy: 1.0000 - val_loss: 1.1118 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 98/500\n",
            "1/1 - 7s - loss: 0.2201 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 99/500\n",
            "1/1 - 7s - loss: 0.2202 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 100/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.0502 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 101/500\n",
            "1/1 - 7s - loss: 0.2195 - accuracy: 1.0000 - val_loss: 1.0152 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 102/500\n",
            "1/1 - 7s - loss: 0.2192 - accuracy: 1.0000 - val_loss: 1.0230 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 103/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.9827 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 104/500\n",
            "1/1 - 7s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 105/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 106/500\n",
            "1/1 - 7s - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.9483 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 107/500\n",
            "1/1 - 7s - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.9862 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 108/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.0137 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 109/500\n",
            "1/1 - 7s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 1.0391 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 110/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 0.9873 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 111/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.9324 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 112/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.9320 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 113/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9263 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 114/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9296 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 115/500\n",
            "1/1 - 7s - loss: 0.2171 - accuracy: 1.0000 - val_loss: 0.9533 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 116/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 117/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.7049 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 118/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.6299 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 119/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 0.9202 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 120/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 1.1690 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 121/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.3798 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 122/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.3082 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 123/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.5020 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 124/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 1.4795 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 125/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.4720 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 126/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 1.6839 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 127/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 1.7127 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 128/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.5828 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 129/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.4337 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 130/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.4646 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 131/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.3928 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 132/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.3073 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 133/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.2897 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 134/500\n",
            "1/1 - 7s - loss: 0.2139 - accuracy: 1.0000 - val_loss: 1.3548 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 135/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.2598 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 136/500\n",
            "1/1 - 7s - loss: 0.2136 - accuracy: 1.0000 - val_loss: 1.0316 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 137/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 138/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 139/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 140/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 0.9355 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 141/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 0.8701 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 142/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 0.8181 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 143/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.7667 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 144/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 0.7848 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 145/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 146/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.7928 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 147/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 148/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.8621 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 149/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 0.8551 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 150/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 0.9800 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 151/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.8393 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 152/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 1.1192 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 153/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 1.4267 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 154/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.4155 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 155/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.4565 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 156/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.3958 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 157/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.3001 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 158/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 159/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 160/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 161/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2515 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 162/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.5443 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 163/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.4470 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 164/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.1697 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 165/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 166/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 0.9141 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 167/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 0.8259 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 168/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.8023 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 169/500\n",
            "1/1 - 9s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.8235 - 9s/epoch - 9s/step\n",
            "Epoch 170/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 171/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 172/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.4812 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 173/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.7315 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 174/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.7185 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 175/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.6596 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 176/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.8291 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 177/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.8264 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 178/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.8056 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 179/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 1.8114 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 180/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.8181 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 181/500\n",
            "1/1 - 7s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 1.7047 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 182/500\n",
            "1/1 - 7s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 1.6430 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 183/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.2638 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 184/500\n",
            "1/1 - 7s - loss: 0.2061 - accuracy: 1.0000 - val_loss: 1.2366 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 185/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.2713 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 186/500\n",
            "1/1 - 7s - loss: 0.2058 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 187/500\n",
            "1/1 - 7s - loss: 0.2058 - accuracy: 1.0000 - val_loss: 1.0801 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 188/500\n",
            "1/1 - 7s - loss: 0.2054 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 189/500\n",
            "1/1 - 7s - loss: 0.2053 - accuracy: 1.0000 - val_loss: 0.9581 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 190/500\n",
            "1/1 - 7s - loss: 0.2052 - accuracy: 1.0000 - val_loss: 1.0828 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 191/500\n",
            "1/1 - 7s - loss: 0.2050 - accuracy: 1.0000 - val_loss: 1.0757 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 192/500\n",
            "1/1 - 7s - loss: 0.2049 - accuracy: 1.0000 - val_loss: 0.8899 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 193/500\n",
            "1/1 - 7s - loss: 0.2047 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 194/500\n",
            "1/1 - 7s - loss: 0.2046 - accuracy: 1.0000 - val_loss: 1.0095 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 195/500\n",
            "1/1 - 7s - loss: 0.2045 - accuracy: 1.0000 - val_loss: 0.9429 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 196/500\n",
            "1/1 - 7s - loss: 0.2044 - accuracy: 1.0000 - val_loss: 1.0323 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 197/500\n",
            "1/1 - 7s - loss: 0.2041 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 198/500\n",
            "1/1 - 7s - loss: 0.2040 - accuracy: 1.0000 - val_loss: 1.0547 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 199/500\n",
            "1/1 - 7s - loss: 0.2038 - accuracy: 1.0000 - val_loss: 1.1381 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 200/500\n",
            "1/1 - 7s - loss: 0.2037 - accuracy: 1.0000 - val_loss: 0.9983 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 201/500\n",
            "1/1 - 7s - loss: 0.2036 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 202/500\n",
            "1/1 - 7s - loss: 0.2033 - accuracy: 1.0000 - val_loss: 1.2795 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 203/500\n",
            "1/1 - 7s - loss: 0.2032 - accuracy: 1.0000 - val_loss: 1.5135 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 204/500\n",
            "1/1 - 7s - loss: 0.2031 - accuracy: 1.0000 - val_loss: 1.4088 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 205/500\n",
            "1/1 - 7s - loss: 0.2029 - accuracy: 1.0000 - val_loss: 1.6676 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 206/500\n",
            "1/1 - 7s - loss: 0.2028 - accuracy: 1.0000 - val_loss: 1.6199 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 207/500\n",
            "1/1 - 7s - loss: 0.2026 - accuracy: 1.0000 - val_loss: 1.6453 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 208/500\n",
            "1/1 - 7s - loss: 0.2025 - accuracy: 1.0000 - val_loss: 1.4863 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 209/500\n",
            "1/1 - 7s - loss: 0.2023 - accuracy: 1.0000 - val_loss: 1.2128 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 210/500\n",
            "1/1 - 7s - loss: 0.2022 - accuracy: 1.0000 - val_loss: 0.9780 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 211/500\n",
            "1/1 - 7s - loss: 0.2020 - accuracy: 1.0000 - val_loss: 0.9525 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 212/500\n",
            "1/1 - 7s - loss: 0.2018 - accuracy: 1.0000 - val_loss: 1.1446 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 213/500\n",
            "1/1 - 7s - loss: 0.2017 - accuracy: 1.0000 - val_loss: 1.0534 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 214/500\n",
            "1/1 - 7s - loss: 0.2015 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 215/500\n",
            "1/1 - 7s - loss: 0.2014 - accuracy: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 216/500\n",
            "1/1 - 7s - loss: 0.2012 - accuracy: 1.0000 - val_loss: 0.9954 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 217/500\n",
            "1/1 - 7s - loss: 0.2011 - accuracy: 1.0000 - val_loss: 1.3596 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 218/500\n",
            "1/1 - 7s - loss: 0.2009 - accuracy: 1.0000 - val_loss: 1.4048 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 219/500\n",
            "1/1 - 7s - loss: 0.2007 - accuracy: 1.0000 - val_loss: 1.3337 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 220/500\n",
            "1/1 - 7s - loss: 0.2006 - accuracy: 1.0000 - val_loss: 1.3671 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 221/500\n",
            "1/1 - 7s - loss: 0.2004 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 222/500\n",
            "1/1 - 7s - loss: 0.2004 - accuracy: 1.0000 - val_loss: 1.5483 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 223/500\n",
            "1/1 - 7s - loss: 0.2002 - accuracy: 1.0000 - val_loss: 1.5797 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 224/500\n",
            "1/1 - 7s - loss: 0.2000 - accuracy: 1.0000 - val_loss: 1.4565 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 225/500\n",
            "1/1 - 7s - loss: 0.1998 - accuracy: 1.0000 - val_loss: 1.4794 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 226/500\n",
            "1/1 - 7s - loss: 0.1996 - accuracy: 1.0000 - val_loss: 1.2543 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 227/500\n",
            "1/1 - 7s - loss: 0.1995 - accuracy: 1.0000 - val_loss: 1.3065 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 228/500\n",
            "1/1 - 7s - loss: 0.1994 - accuracy: 1.0000 - val_loss: 1.3731 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 229/500\n",
            "1/1 - 7s - loss: 0.1992 - accuracy: 1.0000 - val_loss: 1.3629 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 230/500\n",
            "1/1 - 7s - loss: 0.1991 - accuracy: 1.0000 - val_loss: 1.6622 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 231/500\n",
            "1/1 - 7s - loss: 0.1989 - accuracy: 1.0000 - val_loss: 1.5467 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 232/500\n",
            "1/1 - 7s - loss: 0.1988 - accuracy: 1.0000 - val_loss: 1.5003 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 233/500\n",
            "1/1 - 7s - loss: 0.1986 - accuracy: 1.0000 - val_loss: 1.4858 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 234/500\n",
            "1/1 - 7s - loss: 0.1984 - accuracy: 1.0000 - val_loss: 1.4751 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 235/500\n",
            "1/1 - 7s - loss: 0.1982 - accuracy: 1.0000 - val_loss: 1.4292 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 236/500\n",
            "1/1 - 7s - loss: 0.1982 - accuracy: 1.0000 - val_loss: 1.3401 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 237/500\n",
            "1/1 - 7s - loss: 0.1980 - accuracy: 1.0000 - val_loss: 1.4698 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 238/500\n",
            "1/1 - 7s - loss: 0.1978 - accuracy: 1.0000 - val_loss: 1.4080 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 239/500\n",
            "1/1 - 7s - loss: 0.1977 - accuracy: 1.0000 - val_loss: 1.3956 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 240/500\n",
            "1/1 - 7s - loss: 0.1975 - accuracy: 1.0000 - val_loss: 1.3630 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 241/500\n",
            "1/1 - 7s - loss: 0.1973 - accuracy: 1.0000 - val_loss: 1.2783 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 242/500\n",
            "1/1 - 7s - loss: 0.1972 - accuracy: 1.0000 - val_loss: 1.4139 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 243/500\n",
            "1/1 - 7s - loss: 0.1970 - accuracy: 1.0000 - val_loss: 1.2629 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 244/500\n",
            "1/1 - 7s - loss: 0.1969 - accuracy: 1.0000 - val_loss: 1.3635 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 245/500\n",
            "1/1 - 7s - loss: 0.1967 - accuracy: 1.0000 - val_loss: 1.3935 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 246/500\n",
            "1/1 - 7s - loss: 0.1966 - accuracy: 1.0000 - val_loss: 1.3890 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 247/500\n",
            "1/1 - 7s - loss: 0.1964 - accuracy: 1.0000 - val_loss: 1.6833 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 248/500\n",
            "1/1 - 7s - loss: 0.1962 - accuracy: 1.0000 - val_loss: 1.6127 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 249/500\n",
            "1/1 - 7s - loss: 0.1962 - accuracy: 1.0000 - val_loss: 2.3033 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 250/500\n",
            "1/1 - 7s - loss: 0.1959 - accuracy: 1.0000 - val_loss: 2.3885 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 251/500\n",
            "1/1 - 7s - loss: 0.1958 - accuracy: 1.0000 - val_loss: 2.4399 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 252/500\n",
            "1/1 - 7s - loss: 0.1956 - accuracy: 1.0000 - val_loss: 2.3207 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 253/500\n",
            "1/1 - 7s - loss: 0.1955 - accuracy: 1.0000 - val_loss: 2.4568 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 254/500\n",
            "1/1 - 7s - loss: 0.1953 - accuracy: 1.0000 - val_loss: 2.2290 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 255/500\n",
            "1/1 - 7s - loss: 0.1952 - accuracy: 1.0000 - val_loss: 2.0727 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 256/500\n",
            "1/1 - 7s - loss: 0.1950 - accuracy: 1.0000 - val_loss: 1.9899 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 257/500\n",
            "1/1 - 7s - loss: 0.1949 - accuracy: 1.0000 - val_loss: 1.8029 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 258/500\n",
            "1/1 - 7s - loss: 0.1947 - accuracy: 1.0000 - val_loss: 1.7213 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 259/500\n",
            "1/1 - 7s - loss: 0.1946 - accuracy: 1.0000 - val_loss: 1.8023 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 260/500\n",
            "1/1 - 7s - loss: 0.1944 - accuracy: 1.0000 - val_loss: 1.7169 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 261/500\n",
            "1/1 - 7s - loss: 0.1942 - accuracy: 1.0000 - val_loss: 1.2967 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 262/500\n",
            "1/1 - 7s - loss: 0.1941 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 263/500\n",
            "1/1 - 7s - loss: 0.1939 - accuracy: 1.0000 - val_loss: 1.2263 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 264/500\n",
            "1/1 - 7s - loss: 0.1938 - accuracy: 1.0000 - val_loss: 1.4090 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 265/500\n",
            "1/1 - 7s - loss: 0.1936 - accuracy: 1.0000 - val_loss: 1.4137 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 266/500\n",
            "1/1 - 7s - loss: 0.1934 - accuracy: 1.0000 - val_loss: 1.5202 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 267/500\n",
            "1/1 - 7s - loss: 0.1933 - accuracy: 1.0000 - val_loss: 1.5607 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 268/500\n",
            "1/1 - 7s - loss: 0.1931 - accuracy: 1.0000 - val_loss: 1.4909 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 269/500\n",
            "1/1 - 7s - loss: 0.1930 - accuracy: 1.0000 - val_loss: 1.8188 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 270/500\n",
            "1/1 - 7s - loss: 0.1928 - accuracy: 1.0000 - val_loss: 1.8400 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 271/500\n",
            "1/1 - 7s - loss: 0.1927 - accuracy: 1.0000 - val_loss: 1.7381 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 272/500\n",
            "1/1 - 7s - loss: 0.1925 - accuracy: 1.0000 - val_loss: 1.9152 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 273/500\n",
            "1/1 - 7s - loss: 0.1924 - accuracy: 1.0000 - val_loss: 1.8802 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 274/500\n",
            "1/1 - 7s - loss: 0.1922 - accuracy: 1.0000 - val_loss: 1.8815 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 275/500\n",
            "1/1 - 7s - loss: 0.1921 - accuracy: 1.0000 - val_loss: 1.5878 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 276/500\n",
            "1/1 - 7s - loss: 0.1919 - accuracy: 1.0000 - val_loss: 1.4187 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 277/500\n",
            "1/1 - 7s - loss: 0.1918 - accuracy: 1.0000 - val_loss: 1.5729 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 278/500\n",
            "1/1 - 7s - loss: 0.1916 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 279/500\n",
            "1/1 - 7s - loss: 0.1915 - accuracy: 1.0000 - val_loss: 1.5336 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 280/500\n",
            "1/1 - 7s - loss: 0.1913 - accuracy: 1.0000 - val_loss: 1.5750 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 281/500\n",
            "1/1 - 7s - loss: 0.1912 - accuracy: 1.0000 - val_loss: 1.6427 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 282/500\n",
            "1/1 - 7s - loss: 0.1910 - accuracy: 1.0000 - val_loss: 1.7244 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 283/500\n",
            "1/1 - 7s - loss: 0.1909 - accuracy: 1.0000 - val_loss: 1.3712 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 284/500\n",
            "1/1 - 7s - loss: 0.1906 - accuracy: 1.0000 - val_loss: 1.5248 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 285/500\n",
            "1/1 - 7s - loss: 0.1905 - accuracy: 1.0000 - val_loss: 1.6857 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 286/500\n",
            "1/1 - 7s - loss: 0.1904 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 287/500\n",
            "1/1 - 7s - loss: 0.1902 - accuracy: 1.0000 - val_loss: 0.9770 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 288/500\n",
            "1/1 - 7s - loss: 0.1901 - accuracy: 1.0000 - val_loss: 1.5013 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 289/500\n",
            "1/1 - 7s - loss: 0.1898 - accuracy: 1.0000 - val_loss: 1.4196 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 290/500\n",
            "1/1 - 7s - loss: 0.1897 - accuracy: 1.0000 - val_loss: 1.8320 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 291/500\n",
            "1/1 - 7s - loss: 0.1896 - accuracy: 1.0000 - val_loss: 1.7531 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 292/500\n",
            "1/1 - 7s - loss: 0.1894 - accuracy: 1.0000 - val_loss: 1.6850 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 293/500\n",
            "1/1 - 7s - loss: 0.1893 - accuracy: 1.0000 - val_loss: 1.3864 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 294/500\n",
            "1/1 - 7s - loss: 0.1891 - accuracy: 1.0000 - val_loss: 1.4174 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 295/500\n",
            "1/1 - 7s - loss: 0.1890 - accuracy: 1.0000 - val_loss: 1.1935 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 296/500\n",
            "1/1 - 7s - loss: 0.1887 - accuracy: 1.0000 - val_loss: 1.2794 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 297/500\n",
            "1/1 - 7s - loss: 0.1887 - accuracy: 1.0000 - val_loss: 1.2831 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 298/500\n",
            "1/1 - 7s - loss: 0.1885 - accuracy: 1.0000 - val_loss: 1.8270 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 299/500\n",
            "1/1 - 7s - loss: 0.1883 - accuracy: 1.0000 - val_loss: 1.8363 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 300/500\n",
            "1/1 - 7s - loss: 0.1882 - accuracy: 1.0000 - val_loss: 1.9178 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 301/500\n",
            "1/1 - 7s - loss: 0.1880 - accuracy: 1.0000 - val_loss: 1.9325 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 302/500\n",
            "1/1 - 7s - loss: 0.1878 - accuracy: 1.0000 - val_loss: 2.0207 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 303/500\n",
            "1/1 - 7s - loss: 0.1877 - accuracy: 1.0000 - val_loss: 1.9971 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 304/500\n",
            "1/1 - 7s - loss: 0.1876 - accuracy: 1.0000 - val_loss: 1.8320 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 305/500\n",
            "1/1 - 7s - loss: 0.1874 - accuracy: 1.0000 - val_loss: 1.7166 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 306/500\n",
            "1/1 - 7s - loss: 0.1872 - accuracy: 1.0000 - val_loss: 1.5911 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 307/500\n",
            "1/1 - 7s - loss: 0.1871 - accuracy: 1.0000 - val_loss: 1.6865 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 308/500\n",
            "1/1 - 7s - loss: 0.1869 - accuracy: 1.0000 - val_loss: 1.5315 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 309/500\n",
            "1/1 - 7s - loss: 0.1868 - accuracy: 1.0000 - val_loss: 1.3927 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 310/500\n",
            "1/1 - 7s - loss: 0.1866 - accuracy: 1.0000 - val_loss: 1.4528 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 311/500\n",
            "1/1 - 7s - loss: 0.1864 - accuracy: 1.0000 - val_loss: 1.2601 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 312/500\n",
            "1/1 - 7s - loss: 0.1863 - accuracy: 1.0000 - val_loss: 1.2870 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 313/500\n",
            "1/1 - 7s - loss: 0.1861 - accuracy: 1.0000 - val_loss: 1.2615 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 314/500\n",
            "1/1 - 7s - loss: 0.1860 - accuracy: 1.0000 - val_loss: 1.3292 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 315/500\n",
            "1/1 - 7s - loss: 0.1859 - accuracy: 1.0000 - val_loss: 1.3106 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 316/500\n",
            "1/1 - 7s - loss: 0.1857 - accuracy: 1.0000 - val_loss: 1.4092 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 317/500\n",
            "1/1 - 7s - loss: 0.1855 - accuracy: 1.0000 - val_loss: 1.5514 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 318/500\n",
            "1/1 - 7s - loss: 0.1855 - accuracy: 1.0000 - val_loss: 1.7240 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 319/500\n",
            "1/1 - 7s - loss: 0.1852 - accuracy: 1.0000 - val_loss: 2.1710 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 320/500\n",
            "1/1 - 7s - loss: 0.1851 - accuracy: 1.0000 - val_loss: 2.4837 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 321/500\n",
            "1/1 - 7s - loss: 0.1849 - accuracy: 1.0000 - val_loss: 2.5009 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 322/500\n",
            "1/1 - 7s - loss: 0.1847 - accuracy: 1.0000 - val_loss: 2.5660 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 323/500\n",
            "1/1 - 7s - loss: 0.1846 - accuracy: 1.0000 - val_loss: 2.4723 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 324/500\n",
            "1/1 - 7s - loss: 0.1844 - accuracy: 1.0000 - val_loss: 2.7762 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 325/500\n",
            "1/1 - 7s - loss: 0.1843 - accuracy: 1.0000 - val_loss: 2.6279 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 326/500\n",
            "1/1 - 7s - loss: 0.1841 - accuracy: 1.0000 - val_loss: 2.5349 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 327/500\n",
            "1/1 - 7s - loss: 0.1840 - accuracy: 1.0000 - val_loss: 2.5549 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 328/500\n",
            "1/1 - 7s - loss: 0.1838 - accuracy: 1.0000 - val_loss: 2.2142 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 329/500\n",
            "1/1 - 7s - loss: 0.1836 - accuracy: 1.0000 - val_loss: 1.6455 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 330/500\n",
            "1/1 - 7s - loss: 0.1835 - accuracy: 1.0000 - val_loss: 1.6476 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 331/500\n",
            "1/1 - 7s - loss: 0.1833 - accuracy: 1.0000 - val_loss: 2.1262 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 332/500\n",
            "1/1 - 7s - loss: 0.1831 - accuracy: 1.0000 - val_loss: 2.0494 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 333/500\n",
            "1/1 - 7s - loss: 0.1830 - accuracy: 1.0000 - val_loss: 2.3176 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 334/500\n",
            "1/1 - 7s - loss: 0.1828 - accuracy: 1.0000 - val_loss: 2.0559 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 335/500\n",
            "1/1 - 7s - loss: 0.1827 - accuracy: 1.0000 - val_loss: 1.9115 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 336/500\n",
            "1/1 - 7s - loss: 0.1825 - accuracy: 1.0000 - val_loss: 1.7411 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 337/500\n",
            "1/1 - 7s - loss: 0.1824 - accuracy: 1.0000 - val_loss: 2.1885 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 338/500\n",
            "1/1 - 7s - loss: 0.1823 - accuracy: 1.0000 - val_loss: 2.1078 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 339/500\n",
            "1/1 - 7s - loss: 0.1821 - accuracy: 1.0000 - val_loss: 2.0787 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 340/500\n",
            "1/1 - 7s - loss: 0.1819 - accuracy: 1.0000 - val_loss: 2.2870 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 341/500\n",
            "1/1 - 7s - loss: 0.1818 - accuracy: 1.0000 - val_loss: 2.1412 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 342/500\n",
            "1/1 - 7s - loss: 0.1816 - accuracy: 1.0000 - val_loss: 2.1399 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 343/500\n",
            "1/1 - 7s - loss: 0.1814 - accuracy: 1.0000 - val_loss: 2.1704 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 344/500\n",
            "1/1 - 7s - loss: 0.1813 - accuracy: 1.0000 - val_loss: 2.4809 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 345/500\n",
            "1/1 - 7s - loss: 0.1812 - accuracy: 1.0000 - val_loss: 2.4880 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 346/500\n",
            "1/1 - 7s - loss: 0.1810 - accuracy: 1.0000 - val_loss: 2.2727 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 347/500\n",
            "1/1 - 7s - loss: 0.1809 - accuracy: 1.0000 - val_loss: 2.1698 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 348/500\n",
            "1/1 - 7s - loss: 0.1807 - accuracy: 1.0000 - val_loss: 2.0504 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 349/500\n",
            "1/1 - 7s - loss: 0.1805 - accuracy: 1.0000 - val_loss: 2.0770 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 350/500\n",
            "1/1 - 7s - loss: 0.1804 - accuracy: 1.0000 - val_loss: 2.0574 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 351/500\n",
            "1/1 - 7s - loss: 0.1802 - accuracy: 1.0000 - val_loss: 2.0415 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 352/500\n",
            "1/1 - 7s - loss: 0.1800 - accuracy: 1.0000 - val_loss: 2.1163 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 353/500\n",
            "1/1 - 7s - loss: 0.1799 - accuracy: 1.0000 - val_loss: 2.3034 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 354/500\n",
            "1/1 - 7s - loss: 0.1797 - accuracy: 1.0000 - val_loss: 2.2587 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 355/500\n",
            "1/1 - 7s - loss: 0.1796 - accuracy: 1.0000 - val_loss: 2.3782 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 356/500\n",
            "1/1 - 7s - loss: 0.1794 - accuracy: 1.0000 - val_loss: 2.0900 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 357/500\n",
            "1/1 - 7s - loss: 0.1793 - accuracy: 1.0000 - val_loss: 2.1608 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 358/500\n",
            "1/1 - 7s - loss: 0.1791 - accuracy: 1.0000 - val_loss: 2.1846 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 359/500\n",
            "1/1 - 7s - loss: 0.1790 - accuracy: 1.0000 - val_loss: 2.5145 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 360/500\n",
            "1/1 - 7s - loss: 0.1788 - accuracy: 1.0000 - val_loss: 2.3546 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 361/500\n",
            "1/1 - 7s - loss: 0.1787 - accuracy: 1.0000 - val_loss: 2.3049 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 362/500\n",
            "1/1 - 7s - loss: 0.1785 - accuracy: 1.0000 - val_loss: 2.4809 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 363/500\n",
            "1/1 - 7s - loss: 0.1784 - accuracy: 1.0000 - val_loss: 2.3115 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 364/500\n",
            "1/1 - 7s - loss: 0.1782 - accuracy: 1.0000 - val_loss: 2.2727 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 365/500\n",
            "1/1 - 7s - loss: 0.1781 - accuracy: 1.0000 - val_loss: 2.0168 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 366/500\n",
            "1/1 - 7s - loss: 0.1779 - accuracy: 1.0000 - val_loss: 1.9957 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 367/500\n",
            "1/1 - 7s - loss: 0.1777 - accuracy: 1.0000 - val_loss: 2.1696 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 368/500\n",
            "1/1 - 7s - loss: 0.1776 - accuracy: 1.0000 - val_loss: 1.8832 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 369/500\n",
            "1/1 - 7s - loss: 0.1774 - accuracy: 1.0000 - val_loss: 2.0183 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 370/500\n",
            "1/1 - 7s - loss: 0.1772 - accuracy: 1.0000 - val_loss: 2.0568 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 371/500\n",
            "1/1 - 7s - loss: 0.1771 - accuracy: 1.0000 - val_loss: 1.9591 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 372/500\n",
            "1/1 - 7s - loss: 0.1770 - accuracy: 1.0000 - val_loss: 1.9296 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 373/500\n",
            "1/1 - 7s - loss: 0.1769 - accuracy: 1.0000 - val_loss: 2.0152 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 374/500\n",
            "1/1 - 7s - loss: 0.1766 - accuracy: 1.0000 - val_loss: 2.2150 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 375/500\n",
            "1/1 - 7s - loss: 0.1765 - accuracy: 1.0000 - val_loss: 2.0716 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 376/500\n",
            "1/1 - 7s - loss: 0.1763 - accuracy: 1.0000 - val_loss: 2.1009 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 377/500\n",
            "1/1 - 7s - loss: 0.1762 - accuracy: 1.0000 - val_loss: 2.0981 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 378/500\n",
            "1/1 - 7s - loss: 0.1760 - accuracy: 1.0000 - val_loss: 2.1929 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 379/500\n",
            "1/1 - 7s - loss: 0.1759 - accuracy: 1.0000 - val_loss: 2.4300 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 380/500\n",
            "1/1 - 7s - loss: 0.1757 - accuracy: 1.0000 - val_loss: 2.1740 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 381/500\n",
            "1/1 - 7s - loss: 0.1756 - accuracy: 1.0000 - val_loss: 2.1715 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 382/500\n",
            "1/1 - 7s - loss: 0.1754 - accuracy: 1.0000 - val_loss: 2.3361 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 383/500\n",
            "1/1 - 7s - loss: 0.1752 - accuracy: 1.0000 - val_loss: 2.1426 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 384/500\n",
            "1/1 - 7s - loss: 0.1751 - accuracy: 1.0000 - val_loss: 2.1246 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 385/500\n",
            "1/1 - 7s - loss: 0.1750 - accuracy: 1.0000 - val_loss: 1.9294 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 386/500\n",
            "1/1 - 7s - loss: 0.1748 - accuracy: 1.0000 - val_loss: 1.9448 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 387/500\n",
            "1/1 - 7s - loss: 0.1746 - accuracy: 1.0000 - val_loss: 2.1673 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 388/500\n",
            "1/1 - 7s - loss: 0.1745 - accuracy: 1.0000 - val_loss: 2.1161 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 389/500\n",
            "1/1 - 7s - loss: 0.1743 - accuracy: 1.0000 - val_loss: 2.0181 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 390/500\n",
            "1/1 - 7s - loss: 0.1742 - accuracy: 1.0000 - val_loss: 1.9604 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 391/500\n",
            "1/1 - 7s - loss: 0.1740 - accuracy: 1.0000 - val_loss: 1.8228 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 392/500\n",
            "1/1 - 7s - loss: 0.1739 - accuracy: 1.0000 - val_loss: 1.8879 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 393/500\n",
            "1/1 - 7s - loss: 0.1737 - accuracy: 1.0000 - val_loss: 1.8587 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 394/500\n",
            "1/1 - 7s - loss: 0.1735 - accuracy: 1.0000 - val_loss: 2.0011 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 395/500\n",
            "1/1 - 7s - loss: 0.1734 - accuracy: 1.0000 - val_loss: 2.1529 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 396/500\n",
            "1/1 - 7s - loss: 0.1732 - accuracy: 1.0000 - val_loss: 2.2145 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 397/500\n",
            "1/1 - 7s - loss: 0.1731 - accuracy: 1.0000 - val_loss: 2.2040 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 398/500\n",
            "1/1 - 7s - loss: 0.1729 - accuracy: 1.0000 - val_loss: 2.0955 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 399/500\n",
            "1/1 - 7s - loss: 0.1728 - accuracy: 1.0000 - val_loss: 1.9719 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 400/500\n",
            "1/1 - 7s - loss: 0.1726 - accuracy: 1.0000 - val_loss: 2.1606 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 401/500\n",
            "1/1 - 7s - loss: 0.1725 - accuracy: 1.0000 - val_loss: 2.0151 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 402/500\n",
            "1/1 - 7s - loss: 0.1723 - accuracy: 1.0000 - val_loss: 2.0064 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 403/500\n",
            "1/1 - 7s - loss: 0.1721 - accuracy: 1.0000 - val_loss: 2.0931 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 404/500\n",
            "1/1 - 7s - loss: 0.1720 - accuracy: 1.0000 - val_loss: 2.1081 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 405/500\n",
            "1/1 - 7s - loss: 0.1719 - accuracy: 1.0000 - val_loss: 2.0661 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 406/500\n",
            "1/1 - 7s - loss: 0.1717 - accuracy: 1.0000 - val_loss: 2.0334 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 407/500\n",
            "1/1 - 7s - loss: 0.1715 - accuracy: 1.0000 - val_loss: 2.1613 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 408/500\n",
            "1/1 - 7s - loss: 0.1714 - accuracy: 1.0000 - val_loss: 2.1943 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 409/500\n",
            "1/1 - 7s - loss: 0.1713 - accuracy: 1.0000 - val_loss: 2.2014 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 410/500\n",
            "1/1 - 7s - loss: 0.1711 - accuracy: 1.0000 - val_loss: 2.1010 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 411/500\n",
            "1/1 - 7s - loss: 0.1709 - accuracy: 1.0000 - val_loss: 2.0761 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 412/500\n",
            "1/1 - 7s - loss: 0.1708 - accuracy: 1.0000 - val_loss: 2.0064 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 413/500\n",
            "1/1 - 7s - loss: 0.1707 - accuracy: 1.0000 - val_loss: 2.1030 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 414/500\n",
            "1/1 - 7s - loss: 0.1705 - accuracy: 1.0000 - val_loss: 2.4367 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 415/500\n",
            "1/1 - 7s - loss: 0.1704 - accuracy: 1.0000 - val_loss: 2.1436 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 416/500\n",
            "1/1 - 7s - loss: 0.1702 - accuracy: 1.0000 - val_loss: 2.0917 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 417/500\n",
            "1/1 - 7s - loss: 0.1700 - accuracy: 1.0000 - val_loss: 2.0191 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 418/500\n",
            "1/1 - 7s - loss: 0.1699 - accuracy: 1.0000 - val_loss: 2.0931 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 419/500\n",
            "1/1 - 7s - loss: 0.1697 - accuracy: 1.0000 - val_loss: 2.0769 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 420/500\n",
            "1/1 - 7s - loss: 0.1696 - accuracy: 1.0000 - val_loss: 2.1551 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 421/500\n",
            "1/1 - 7s - loss: 0.1694 - accuracy: 1.0000 - val_loss: 2.2462 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 422/500\n",
            "1/1 - 7s - loss: 0.1692 - accuracy: 1.0000 - val_loss: 2.2649 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 423/500\n",
            "1/1 - 7s - loss: 0.1691 - accuracy: 1.0000 - val_loss: 2.1861 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 424/500\n",
            "1/1 - 7s - loss: 0.1689 - accuracy: 1.0000 - val_loss: 2.3245 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 425/500\n",
            "1/1 - 7s - loss: 0.1688 - accuracy: 1.0000 - val_loss: 2.2783 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 426/500\n",
            "1/1 - 7s - loss: 0.1687 - accuracy: 1.0000 - val_loss: 2.3073 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 427/500\n",
            "1/1 - 7s - loss: 0.1685 - accuracy: 1.0000 - val_loss: 2.1683 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 428/500\n",
            "1/1 - 7s - loss: 0.1683 - accuracy: 1.0000 - val_loss: 2.1665 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 429/500\n",
            "1/1 - 7s - loss: 0.1682 - accuracy: 1.0000 - val_loss: 2.1664 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 430/500\n",
            "1/1 - 7s - loss: 0.1680 - accuracy: 1.0000 - val_loss: 2.3654 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 431/500\n",
            "1/1 - 7s - loss: 0.1679 - accuracy: 1.0000 - val_loss: 2.7934 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 432/500\n",
            "1/1 - 7s - loss: 0.1677 - accuracy: 1.0000 - val_loss: 2.5032 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 433/500\n",
            "1/1 - 7s - loss: 0.1676 - accuracy: 1.0000 - val_loss: 2.5843 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 434/500\n",
            "1/1 - 7s - loss: 0.1674 - accuracy: 1.0000 - val_loss: 2.8164 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 435/500\n",
            "1/1 - 7s - loss: 0.1673 - accuracy: 1.0000 - val_loss: 2.6632 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 436/500\n",
            "1/1 - 7s - loss: 0.1671 - accuracy: 1.0000 - val_loss: 2.3384 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 437/500\n",
            "1/1 - 7s - loss: 0.1670 - accuracy: 1.0000 - val_loss: 2.3383 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 438/500\n",
            "1/1 - 7s - loss: 0.1668 - accuracy: 1.0000 - val_loss: 2.3827 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 439/500\n",
            "1/1 - 7s - loss: 0.1667 - accuracy: 1.0000 - val_loss: 2.3284 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 440/500\n",
            "1/1 - 7s - loss: 0.1665 - accuracy: 1.0000 - val_loss: 2.6005 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 441/500\n",
            "1/1 - 7s - loss: 0.1664 - accuracy: 1.0000 - val_loss: 2.3574 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 442/500\n",
            "1/1 - 7s - loss: 0.1662 - accuracy: 1.0000 - val_loss: 2.4039 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 443/500\n",
            "1/1 - 7s - loss: 0.1661 - accuracy: 1.0000 - val_loss: 2.2532 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 444/500\n",
            "1/1 - 7s - loss: 0.1659 - accuracy: 1.0000 - val_loss: 2.1967 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 445/500\n",
            "1/1 - 7s - loss: 0.1658 - accuracy: 1.0000 - val_loss: 2.1194 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 446/500\n",
            "1/1 - 7s - loss: 0.1656 - accuracy: 1.0000 - val_loss: 2.0974 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 447/500\n",
            "1/1 - 7s - loss: 0.1655 - accuracy: 1.0000 - val_loss: 2.0729 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 448/500\n",
            "1/1 - 7s - loss: 0.1653 - accuracy: 1.0000 - val_loss: 2.0748 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 449/500\n",
            "1/1 - 7s - loss: 0.1652 - accuracy: 1.0000 - val_loss: 2.2720 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 450/500\n",
            "1/1 - 7s - loss: 0.1650 - accuracy: 1.0000 - val_loss: 2.2905 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 451/500\n",
            "1/1 - 7s - loss: 0.1648 - accuracy: 1.0000 - val_loss: 2.2399 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 452/500\n",
            "1/1 - 7s - loss: 0.1647 - accuracy: 1.0000 - val_loss: 2.2837 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 453/500\n",
            "1/1 - 7s - loss: 0.1645 - accuracy: 1.0000 - val_loss: 2.3656 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 454/500\n",
            "1/1 - 7s - loss: 0.1644 - accuracy: 1.0000 - val_loss: 2.2849 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 455/500\n",
            "1/1 - 7s - loss: 0.1642 - accuracy: 1.0000 - val_loss: 2.2725 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 456/500\n",
            "1/1 - 7s - loss: 0.1641 - accuracy: 1.0000 - val_loss: 2.2044 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 457/500\n",
            "1/1 - 7s - loss: 0.1639 - accuracy: 1.0000 - val_loss: 2.2356 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 458/500\n",
            "1/1 - 7s - loss: 0.1638 - accuracy: 1.0000 - val_loss: 2.1806 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 459/500\n",
            "1/1 - 7s - loss: 0.1637 - accuracy: 1.0000 - val_loss: 2.2059 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 460/500\n",
            "1/1 - 7s - loss: 0.1635 - accuracy: 1.0000 - val_loss: 2.3757 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 461/500\n",
            "1/1 - 7s - loss: 0.1634 - accuracy: 1.0000 - val_loss: 2.2128 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 462/500\n",
            "1/1 - 7s - loss: 0.1632 - accuracy: 1.0000 - val_loss: 2.2368 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 463/500\n",
            "1/1 - 7s - loss: 0.1630 - accuracy: 1.0000 - val_loss: 2.2573 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 464/500\n",
            "1/1 - 7s - loss: 0.1629 - accuracy: 1.0000 - val_loss: 2.2554 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 465/500\n",
            "1/1 - 7s - loss: 0.1628 - accuracy: 1.0000 - val_loss: 2.0890 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 466/500\n",
            "1/1 - 7s - loss: 0.1626 - accuracy: 1.0000 - val_loss: 2.1366 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 467/500\n",
            "1/1 - 7s - loss: 0.1624 - accuracy: 1.0000 - val_loss: 2.1486 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 468/500\n",
            "1/1 - 7s - loss: 0.1623 - accuracy: 1.0000 - val_loss: 2.1247 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 469/500\n",
            "1/1 - 7s - loss: 0.1621 - accuracy: 1.0000 - val_loss: 2.1553 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 470/500\n",
            "1/1 - 7s - loss: 0.1620 - accuracy: 1.0000 - val_loss: 2.1849 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 471/500\n",
            "1/1 - 7s - loss: 0.1619 - accuracy: 1.0000 - val_loss: 2.1402 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 472/500\n",
            "1/1 - 7s - loss: 0.1617 - accuracy: 1.0000 - val_loss: 1.9334 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 473/500\n",
            "1/1 - 7s - loss: 0.1616 - accuracy: 1.0000 - val_loss: 1.8401 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 474/500\n",
            "1/1 - 7s - loss: 0.1614 - accuracy: 1.0000 - val_loss: 2.0715 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 475/500\n",
            "1/1 - 7s - loss: 0.1613 - accuracy: 1.0000 - val_loss: 2.1618 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 476/500\n",
            "1/1 - 7s - loss: 0.1611 - accuracy: 1.0000 - val_loss: 2.1278 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 477/500\n",
            "1/1 - 7s - loss: 0.1610 - accuracy: 1.0000 - val_loss: 1.8677 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 478/500\n",
            "1/1 - 7s - loss: 0.1608 - accuracy: 1.0000 - val_loss: 1.5826 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 479/500\n",
            "1/1 - 7s - loss: 0.1607 - accuracy: 1.0000 - val_loss: 1.8832 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 480/500\n",
            "1/1 - 7s - loss: 0.1605 - accuracy: 1.0000 - val_loss: 1.8600 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 481/500\n",
            "1/1 - 7s - loss: 0.1604 - accuracy: 1.0000 - val_loss: 1.9924 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 482/500\n",
            "1/1 - 7s - loss: 0.1602 - accuracy: 1.0000 - val_loss: 1.7374 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 483/500\n",
            "1/1 - 7s - loss: 0.1600 - accuracy: 1.0000 - val_loss: 1.9127 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 484/500\n",
            "1/1 - 7s - loss: 0.1599 - accuracy: 1.0000 - val_loss: 1.9753 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 485/500\n",
            "1/1 - 7s - loss: 0.1598 - accuracy: 1.0000 - val_loss: 2.2090 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 486/500\n",
            "1/1 - 7s - loss: 0.1596 - accuracy: 1.0000 - val_loss: 2.3903 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 487/500\n",
            "1/1 - 7s - loss: 0.1595 - accuracy: 1.0000 - val_loss: 2.3190 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 488/500\n",
            "1/1 - 7s - loss: 0.1593 - accuracy: 1.0000 - val_loss: 2.3754 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 489/500\n",
            "1/1 - 7s - loss: 0.1592 - accuracy: 1.0000 - val_loss: 2.1035 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 490/500\n",
            "1/1 - 7s - loss: 0.1591 - accuracy: 1.0000 - val_loss: 1.9807 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 491/500\n",
            "1/1 - 7s - loss: 0.1589 - accuracy: 1.0000 - val_loss: 1.9688 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 492/500\n",
            "1/1 - 7s - loss: 0.1587 - accuracy: 1.0000 - val_loss: 1.9995 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 493/500\n",
            "1/1 - 7s - loss: 0.1586 - accuracy: 1.0000 - val_loss: 1.6554 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 494/500\n",
            "1/1 - 7s - loss: 0.1584 - accuracy: 1.0000 - val_loss: 1.9004 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 495/500\n",
            "1/1 - 7s - loss: 0.1583 - accuracy: 1.0000 - val_loss: 1.9927 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 496/500\n",
            "1/1 - 7s - loss: 0.1581 - accuracy: 1.0000 - val_loss: 2.3455 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 497/500\n",
            "1/1 - 7s - loss: 0.1580 - accuracy: 1.0000 - val_loss: 2.2279 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 498/500\n",
            "1/1 - 7s - loss: 0.1578 - accuracy: 1.0000 - val_loss: 2.3053 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 499/500\n",
            "1/1 - 7s - loss: 0.1577 - accuracy: 1.0000 - val_loss: 2.3312 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 500/500\n",
            "1/1 - 7s - loss: 0.1576 - accuracy: 1.0000 - val_loss: 2.4815 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Time Bimodal_EEG+Data = 3677.7349593639374 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_2025-01-08_22-39-48\n",
            "saved-model-001-0.3529.hdf5\n",
            "Loss=1.3066 y Accuracy=0.3529\n",
            "\n",
            "saved-model-006-0.4118.hdf5\n",
            "Loss=1.3237 y Accuracy=0.4118\n",
            "\n",
            "saved-model-054-0.5294.hdf5\n",
            "Loss=1.1830 y Accuracy=0.5294\n",
            "\n",
            "saved-model-061-0.7647.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 510 calls to <function Model.make_test_function.<locals>.test_function at 0x787eabb5c1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=0.9090 y Accuracy=0.7647\n",
            "\n",
            "saved-model-169-0.8235.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 511 calls to <function Model.make_test_function.<locals>.test_function at 0x787eab090550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=0.6490 y Accuracy=0.8235\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-169-0.8235.hdf5\n",
            "Loss=0.6490 y Accuracy=0.8235\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title lr exponencial\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H-VOHBonX8H",
        "outputId": "16684167-5272-4700-d4a3-1491227373d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the training...\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 144s - loss: 1.6168 - accuracy: 0.3824 - val_loss: 1.3405 - val_accuracy: 0.2353 - 144s/epoch - 144s/step\n",
            "Epoch 2/500\n",
            "1/1 - 7s - loss: 1.3240 - accuracy: 0.5294 - val_loss: 1.3540 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 3/500\n",
            "1/1 - 9s - loss: 1.0383 - accuracy: 0.6618 - val_loss: 1.3481 - val_accuracy: 0.3529 - 9s/epoch - 9s/step\n",
            "Epoch 4/500\n",
            "1/1 - 7s - loss: 0.8467 - accuracy: 0.7500 - val_loss: 1.3747 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 5/500\n",
            "1/1 - 7s - loss: 0.5953 - accuracy: 0.8382 - val_loss: 1.3778 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 6/500\n",
            "1/1 - 7s - loss: 0.6539 - accuracy: 0.8235 - val_loss: 1.3888 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 7/500\n",
            "1/1 - 7s - loss: 0.6417 - accuracy: 0.8676 - val_loss: 1.5116 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 8/500\n",
            "1/1 - 7s - loss: 0.5987 - accuracy: 0.8235 - val_loss: 1.7191 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 9/500\n",
            "1/1 - 7s - loss: 0.5646 - accuracy: 0.8971 - val_loss: 2.4351 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 10/500\n",
            "1/1 - 7s - loss: 0.4543 - accuracy: 0.9118 - val_loss: 2.6261 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 11/500\n",
            "1/1 - 7s - loss: 0.4670 - accuracy: 0.9412 - val_loss: 2.5942 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 12/500\n",
            "1/1 - 7s - loss: 0.4008 - accuracy: 0.9559 - val_loss: 2.5687 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 13/500\n",
            "1/1 - 7s - loss: 0.3547 - accuracy: 0.9706 - val_loss: 2.5112 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 14/500\n",
            "1/1 - 7s - loss: 0.3503 - accuracy: 0.9706 - val_loss: 2.4916 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 15/500\n",
            "1/1 - 7s - loss: 0.3322 - accuracy: 0.9706 - val_loss: 2.4728 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 16/500\n",
            "1/1 - 7s - loss: 0.3074 - accuracy: 1.0000 - val_loss: 2.4034 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 17/500\n",
            "1/1 - 7s - loss: 0.3005 - accuracy: 1.0000 - val_loss: 2.3549 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 18/500\n",
            "1/1 - 7s - loss: 0.2917 - accuracy: 1.0000 - val_loss: 2.3581 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 19/500\n",
            "1/1 - 7s - loss: 0.2779 - accuracy: 1.0000 - val_loss: 2.3171 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 20/500\n",
            "1/1 - 7s - loss: 0.2855 - accuracy: 0.9853 - val_loss: 2.2376 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 21/500\n",
            "1/1 - 7s - loss: 0.2559 - accuracy: 1.0000 - val_loss: 2.2067 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 22/500\n",
            "1/1 - 7s - loss: 0.2636 - accuracy: 0.9853 - val_loss: 2.1944 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 23/500\n",
            "1/1 - 7s - loss: 0.2561 - accuracy: 1.0000 - val_loss: 2.1851 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 24/500\n",
            "1/1 - 7s - loss: 0.2459 - accuracy: 1.0000 - val_loss: 2.1914 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 25/500\n",
            "1/1 - 7s - loss: 0.2475 - accuracy: 1.0000 - val_loss: 2.2188 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 26/500\n",
            "1/1 - 7s - loss: 0.2418 - accuracy: 1.0000 - val_loss: 2.2292 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 27/500\n",
            "1/1 - 7s - loss: 0.2392 - accuracy: 1.0000 - val_loss: 2.2361 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 28/500\n",
            "1/1 - 7s - loss: 0.2374 - accuracy: 1.0000 - val_loss: 2.2594 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 29/500\n",
            "1/1 - 7s - loss: 0.2358 - accuracy: 1.0000 - val_loss: 2.2792 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 30/500\n",
            "1/1 - 7s - loss: 0.2354 - accuracy: 1.0000 - val_loss: 2.2976 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 31/500\n",
            "1/1 - 7s - loss: 0.2317 - accuracy: 1.0000 - val_loss: 2.2864 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 32/500\n",
            "1/1 - 7s - loss: 0.2293 - accuracy: 1.0000 - val_loss: 2.2908 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 33/500\n",
            "1/1 - 7s - loss: 0.2302 - accuracy: 1.0000 - val_loss: 2.3022 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 34/500\n",
            "1/1 - 7s - loss: 0.2289 - accuracy: 1.0000 - val_loss: 2.3204 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 35/500\n",
            "1/1 - 7s - loss: 0.2357 - accuracy: 1.0000 - val_loss: 2.4697 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 36/500\n",
            "1/1 - 7s - loss: 0.2287 - accuracy: 1.0000 - val_loss: 2.4952 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 37/500\n",
            "1/1 - 7s - loss: 0.2295 - accuracy: 1.0000 - val_loss: 2.5150 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 38/500\n",
            "1/1 - 7s - loss: 0.2275 - accuracy: 1.0000 - val_loss: 2.5174 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 39/500\n",
            "1/1 - 7s - loss: 0.2283 - accuracy: 1.0000 - val_loss: 2.5520 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 40/500\n",
            "1/1 - 7s - loss: 0.2268 - accuracy: 1.0000 - val_loss: 2.5259 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 41/500\n",
            "1/1 - 7s - loss: 0.2269 - accuracy: 1.0000 - val_loss: 2.4552 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 42/500\n",
            "1/1 - 7s - loss: 0.2282 - accuracy: 1.0000 - val_loss: 2.4065 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 43/500\n",
            "1/1 - 7s - loss: 0.2251 - accuracy: 1.0000 - val_loss: 2.3613 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 44/500\n",
            "1/1 - 7s - loss: 0.2243 - accuracy: 1.0000 - val_loss: 2.3620 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 45/500\n",
            "1/1 - 7s - loss: 0.2245 - accuracy: 1.0000 - val_loss: 2.3730 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 46/500\n",
            "1/1 - 7s - loss: 0.2249 - accuracy: 1.0000 - val_loss: 2.4369 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 47/500\n",
            "1/1 - 7s - loss: 0.2226 - accuracy: 1.0000 - val_loss: 2.4157 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 48/500\n",
            "1/1 - 7s - loss: 0.2233 - accuracy: 1.0000 - val_loss: 2.4953 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 49/500\n",
            "1/1 - 7s - loss: 0.2232 - accuracy: 1.0000 - val_loss: 2.5264 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 50/500\n",
            "1/1 - 9s - loss: 0.2220 - accuracy: 1.0000 - val_loss: 2.0448 - val_accuracy: 0.4706 - 9s/epoch - 9s/step\n",
            "Epoch 51/500\n",
            "1/1 - 7s - loss: 0.2223 - accuracy: 1.0000 - val_loss: 2.2260 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 52/500\n",
            "1/1 - 7s - loss: 0.2219 - accuracy: 1.0000 - val_loss: 2.1231 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 53/500\n",
            "1/1 - 7s - loss: 0.2228 - accuracy: 1.0000 - val_loss: 2.3255 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 54/500\n",
            "1/1 - 7s - loss: 0.2215 - accuracy: 1.0000 - val_loss: 2.4772 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 55/500\n",
            "1/1 - 7s - loss: 0.2218 - accuracy: 1.0000 - val_loss: 2.7150 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 56/500\n",
            "1/1 - 7s - loss: 0.2221 - accuracy: 1.0000 - val_loss: 2.5919 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 57/500\n",
            "1/1 - 7s - loss: 0.2213 - accuracy: 1.0000 - val_loss: 2.6781 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 58/500\n",
            "1/1 - 7s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 2.5589 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 59/500\n",
            "1/1 - 7s - loss: 0.2203 - accuracy: 1.0000 - val_loss: 2.7250 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 60/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 2.4994 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 61/500\n",
            "1/1 - 7s - loss: 0.2200 - accuracy: 1.0000 - val_loss: 2.0955 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 62/500\n",
            "1/1 - 9s - loss: 0.2209 - accuracy: 1.0000 - val_loss: 0.9915 - val_accuracy: 0.5882 - 9s/epoch - 9s/step\n",
            "Epoch 63/500\n",
            "1/1 - 9s - loss: 0.2199 - accuracy: 1.0000 - val_loss: 0.9624 - val_accuracy: 0.7059 - 9s/epoch - 9s/step\n",
            "Epoch 64/500\n",
            "1/1 - 7s - loss: 0.2196 - accuracy: 1.0000 - val_loss: 1.0333 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 65/500\n",
            "1/1 - 7s - loss: 0.2207 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 66/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.0903 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 67/500\n",
            "1/1 - 7s - loss: 0.2191 - accuracy: 1.0000 - val_loss: 1.3949 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 68/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.9022 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 69/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 2.0279 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 70/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 1.9650 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 71/500\n",
            "1/1 - 7s - loss: 0.2190 - accuracy: 1.0000 - val_loss: 1.9535 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 72/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.8907 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 73/500\n",
            "1/1 - 7s - loss: 0.2198 - accuracy: 1.0000 - val_loss: 1.0335 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 74/500\n",
            "1/1 - 7s - loss: 0.2194 - accuracy: 1.0000 - val_loss: 1.0245 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 75/500\n",
            "1/1 - 7s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 1.0603 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 76/500\n",
            "1/1 - 9s - loss: 0.2188 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.8235 - 9s/epoch - 9s/step\n",
            "Epoch 77/500\n",
            "1/1 - 7s - loss: 0.2186 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 78/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.8612 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 79/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.0358 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 80/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.9473 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 81/500\n",
            "1/1 - 7s - loss: 0.2176 - accuracy: 1.0000 - val_loss: 0.8773 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 82/500\n",
            "1/1 - 7s - loss: 0.2184 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 83/500\n",
            "1/1 - 7s - loss: 0.2181 - accuracy: 1.0000 - val_loss: 1.5467 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 84/500\n",
            "1/1 - 7s - loss: 0.2179 - accuracy: 1.0000 - val_loss: 1.6171 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 85/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 1.0934 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 86/500\n",
            "1/1 - 7s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.9824 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 87/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.9726 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 88/500\n",
            "1/1 - 7s - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.8860 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 89/500\n",
            "1/1 - 7s - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 90/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.7630 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 91/500\n",
            "1/1 - 7s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 0.7958 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 92/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.8508 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 93/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 1.0116 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 94/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 0.9982 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 95/500\n",
            "1/1 - 7s - loss: 0.2172 - accuracy: 1.0000 - val_loss: 1.3536 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 96/500\n",
            "1/1 - 7s - loss: 0.2178 - accuracy: 1.0000 - val_loss: 1.8721 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 97/500\n",
            "1/1 - 7s - loss: 0.2175 - accuracy: 1.0000 - val_loss: 2.3543 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 98/500\n",
            "1/1 - 7s - loss: 0.2169 - accuracy: 1.0000 - val_loss: 2.2992 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 99/500\n",
            "1/1 - 7s - loss: 0.2173 - accuracy: 1.0000 - val_loss: 3.0385 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 100/500\n",
            "1/1 - 7s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 3.0684 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 101/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 3.1418 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 102/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 3.0380 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 103/500\n",
            "1/1 - 7s - loss: 0.2167 - accuracy: 1.0000 - val_loss: 2.9644 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 104/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 2.9770 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 105/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 2.8339 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 106/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.8798 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 107/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 3.0305 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 108/500\n",
            "1/1 - 7s - loss: 0.2161 - accuracy: 1.0000 - val_loss: 3.0848 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 109/500\n",
            "1/1 - 7s - loss: 0.2165 - accuracy: 1.0000 - val_loss: 2.8120 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 110/500\n",
            "1/1 - 7s - loss: 0.2168 - accuracy: 1.0000 - val_loss: 2.8890 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 111/500\n",
            "1/1 - 7s - loss: 0.2166 - accuracy: 1.0000 - val_loss: 2.6702 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 112/500\n",
            "1/1 - 7s - loss: 0.2164 - accuracy: 1.0000 - val_loss: 1.7799 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 113/500\n",
            "1/1 - 7s - loss: 0.2170 - accuracy: 1.0000 - val_loss: 1.7376 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 114/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.0480 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 115/500\n",
            "1/1 - 7s - loss: 0.2162 - accuracy: 1.0000 - val_loss: 2.1909 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 116/500\n",
            "1/1 - 7s - loss: 0.2160 - accuracy: 1.0000 - val_loss: 2.4940 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 117/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 2.1775 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 118/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 2.0526 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 119/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 1.8078 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 120/500\n",
            "1/1 - 7s - loss: 0.2157 - accuracy: 1.0000 - val_loss: 2.3076 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 121/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 2.5649 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 122/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 1.8625 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 123/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 1.8530 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 124/500\n",
            "1/1 - 7s - loss: 0.2159 - accuracy: 1.0000 - val_loss: 3.0945 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 125/500\n",
            "1/1 - 7s - loss: 0.2158 - accuracy: 1.0000 - val_loss: 2.9678 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 126/500\n",
            "1/1 - 7s - loss: 0.2156 - accuracy: 1.0000 - val_loss: 1.9517 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 127/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 1.0711 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 128/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 129/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.4984 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 130/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 2.2089 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 131/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 2.2304 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 132/500\n",
            "1/1 - 7s - loss: 0.2154 - accuracy: 1.0000 - val_loss: 1.8082 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 133/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.3810 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 134/500\n",
            "1/1 - 7s - loss: 0.2155 - accuracy: 1.0000 - val_loss: 2.3344 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 135/500\n",
            "1/1 - 7s - loss: 0.2151 - accuracy: 1.0000 - val_loss: 2.4922 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 136/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.4537 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 137/500\n",
            "1/1 - 7s - loss: 0.2152 - accuracy: 1.0000 - val_loss: 2.3281 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 138/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 2.3239 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 139/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 2.3358 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 140/500\n",
            "1/1 - 7s - loss: 0.2153 - accuracy: 1.0000 - val_loss: 2.6527 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 141/500\n",
            "1/1 - 7s - loss: 0.2150 - accuracy: 1.0000 - val_loss: 2.1406 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 142/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.0642 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 143/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.2236 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 144/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.3246 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 145/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 146/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.3448 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 147/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.7938 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 148/500\n",
            "1/1 - 7s - loss: 0.2147 - accuracy: 1.0000 - val_loss: 1.7284 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 149/500\n",
            "1/1 - 7s - loss: 0.2148 - accuracy: 1.0000 - val_loss: 1.5225 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 150/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.2890 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 151/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.2700 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 152/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.2264 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 153/500\n",
            "1/1 - 7s - loss: 0.2144 - accuracy: 1.0000 - val_loss: 1.0887 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 154/500\n",
            "1/1 - 7s - loss: 0.2146 - accuracy: 1.0000 - val_loss: 1.7616 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 155/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 2.3555 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 156/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.3755 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 157/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 2.5764 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 158/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 2.3937 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 159/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 2.1093 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 160/500\n",
            "1/1 - 7s - loss: 0.2145 - accuracy: 1.0000 - val_loss: 1.1074 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 161/500\n",
            "1/1 - 7s - loss: 0.2142 - accuracy: 1.0000 - val_loss: 1.0512 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 162/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 163/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.5583 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 164/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 1.3290 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 165/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 1.9531 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 166/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 1.1849 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 167/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.1542 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 168/500\n",
            "1/1 - 7s - loss: 0.2141 - accuracy: 1.0000 - val_loss: 1.4591 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 169/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 2.1167 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 170/500\n",
            "1/1 - 7s - loss: 0.2140 - accuracy: 1.0000 - val_loss: 2.8279 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 171/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 3.4854 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 172/500\n",
            "1/1 - 7s - loss: 0.2143 - accuracy: 1.0000 - val_loss: 3.4979 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 173/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 3.7822 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 174/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 3.9661 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 175/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 4.0129 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 176/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 3.9620 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 177/500\n",
            "1/1 - 7s - loss: 0.2138 - accuracy: 1.0000 - val_loss: 4.0251 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 178/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 3.9425 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 179/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 3.4621 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 180/500\n",
            "1/1 - 7s - loss: 0.2137 - accuracy: 1.0000 - val_loss: 2.7895 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 181/500\n",
            "1/1 - 7s - loss: 0.2135 - accuracy: 1.0000 - val_loss: 1.8824 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 182/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 1.5839 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 183/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 2.3684 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 184/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 2.4567 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 185/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.6011 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 186/500\n",
            "1/1 - 7s - loss: 0.2134 - accuracy: 1.0000 - val_loss: 2.6660 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 187/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 3.4954 - val_accuracy: 0.2353 - 7s/epoch - 7s/step\n",
            "Epoch 188/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.6279 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 189/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.4013 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 190/500\n",
            "1/1 - 7s - loss: 0.2131 - accuracy: 1.0000 - val_loss: 2.1748 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 191/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 2.3982 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 192/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.3675 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 193/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 2.6926 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 194/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.8377 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 195/500\n",
            "1/1 - 7s - loss: 0.2133 - accuracy: 1.0000 - val_loss: 1.2107 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 196/500\n",
            "1/1 - 7s - loss: 0.2132 - accuracy: 1.0000 - val_loss: 1.0909 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 197/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.1188 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 198/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 199/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 2.3148 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 200/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 3.4918 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 201/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 3.8779 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 202/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 3.8071 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 203/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 3.7667 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 204/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 3.2722 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 205/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 2.7465 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 206/500\n",
            "1/1 - 7s - loss: 0.2129 - accuracy: 1.0000 - val_loss: 3.2627 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 207/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 3.1984 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 208/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 2.9217 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 209/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 3.1276 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 210/500\n",
            "1/1 - 7s - loss: 0.2128 - accuracy: 1.0000 - val_loss: 2.3594 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 211/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 1.9942 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 212/500\n",
            "1/1 - 7s - loss: 0.2130 - accuracy: 1.0000 - val_loss: 2.2006 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 213/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 2.6365 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 214/500\n",
            "1/1 - 7s - loss: 0.2127 - accuracy: 1.0000 - val_loss: 3.0675 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 215/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 3.3718 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 216/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 2.7950 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 217/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.7256 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 218/500\n",
            "1/1 - 7s - loss: 0.2124 - accuracy: 1.0000 - val_loss: 1.5590 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 219/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 1.8259 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 220/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 221/500\n",
            "1/1 - 7s - loss: 0.2125 - accuracy: 1.0000 - val_loss: 1.2771 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 222/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 2.1439 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 223/500\n",
            "1/1 - 7s - loss: 0.2126 - accuracy: 1.0000 - val_loss: 3.0212 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 224/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 2.4560 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 225/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 1.7789 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 226/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.4416 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 227/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 3.0367 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 228/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 2.4944 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 229/500\n",
            "1/1 - 7s - loss: 0.2123 - accuracy: 1.0000 - val_loss: 2.6528 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 230/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 3.5277 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 231/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 3.5670 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 232/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.8201 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 233/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 2.4536 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 234/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.9805 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 235/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.2016 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 236/500\n",
            "1/1 - 7s - loss: 0.2119 - accuracy: 1.0000 - val_loss: 1.2979 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 237/500\n",
            "1/1 - 7s - loss: 0.2120 - accuracy: 1.0000 - val_loss: 1.3346 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 238/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.0318 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 239/500\n",
            "1/1 - 7s - loss: 0.2122 - accuracy: 1.0000 - val_loss: 3.0022 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 240/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.4314 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 241/500\n",
            "1/1 - 7s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.7609 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 242/500\n",
            "1/1 - 7s - loss: 0.2118 - accuracy: 1.0000 - val_loss: 2.7154 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 243/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 3.2393 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 244/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.9698 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 245/500\n",
            "1/1 - 7s - loss: 0.2117 - accuracy: 1.0000 - val_loss: 2.9302 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 246/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 247/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.8610 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 248/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.3268 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 249/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.8953 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 250/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.2243 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 251/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.2674 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 252/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 1.2109 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 253/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 2.1153 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 254/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.4412 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 255/500\n",
            "1/1 - 7s - loss: 0.2116 - accuracy: 1.0000 - val_loss: 3.0905 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 256/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.8094 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 257/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 2.0864 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 258/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 2.2403 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 259/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 2.3221 - val_accuracy: 0.2941 - 7s/epoch - 7s/step\n",
            "Epoch 260/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 2.4004 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 261/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 2.5686 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 262/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.1910 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 263/500\n",
            "1/1 - 7s - loss: 0.2111 - accuracy: 1.0000 - val_loss: 1.8888 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 264/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 1.9891 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 265/500\n",
            "1/1 - 7s - loss: 0.2115 - accuracy: 1.0000 - val_loss: 1.3672 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 266/500\n",
            "1/1 - 7s - loss: 0.2113 - accuracy: 1.0000 - val_loss: 1.3694 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 267/500\n",
            "1/1 - 7s - loss: 0.2114 - accuracy: 1.0000 - val_loss: 1.6041 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 268/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.1479 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 269/500\n",
            "1/1 - 7s - loss: 0.2112 - accuracy: 1.0000 - val_loss: 2.6208 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 270/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 2.2459 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 271/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.5404 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 272/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.2953 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 273/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 1.7588 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 274/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.5686 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 275/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 2.3594 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 276/500\n",
            "1/1 - 7s - loss: 0.2110 - accuracy: 1.0000 - val_loss: 2.4517 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 277/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 3.2869 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 278/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 2.6424 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 279/500\n",
            "1/1 - 7s - loss: 0.2109 - accuracy: 1.0000 - val_loss: 2.8645 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 280/500\n",
            "1/1 - 7s - loss: 0.2108 - accuracy: 1.0000 - val_loss: 3.1354 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 281/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.0711 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 282/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.2784 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 283/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.1961 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 284/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.2663 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 285/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.4719 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 286/500\n",
            "1/1 - 7s - loss: 0.2107 - accuracy: 1.0000 - val_loss: 1.5948 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 287/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 2.4656 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 288/500\n",
            "1/1 - 7s - loss: 0.2106 - accuracy: 1.0000 - val_loss: 1.9168 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 289/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.6262 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 290/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.8181 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 291/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.7616 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 292/500\n",
            "1/1 - 7s - loss: 0.2105 - accuracy: 1.0000 - val_loss: 2.7914 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 293/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.9924 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 294/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.9266 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 295/500\n",
            "1/1 - 7s - loss: 0.2104 - accuracy: 1.0000 - val_loss: 2.9352 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 296/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.9512 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 297/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.3600 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 298/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.5953 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 299/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.8184 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 300/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 2.8297 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 301/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.7277 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 302/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 2.6697 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 303/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.6366 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 304/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.3123 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 305/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.6185 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 306/500\n",
            "1/1 - 7s - loss: 0.2102 - accuracy: 1.0000 - val_loss: 1.3198 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 307/500\n",
            "1/1 - 7s - loss: 0.2103 - accuracy: 1.0000 - val_loss: 1.4813 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 308/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.7965 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 309/500\n",
            "1/1 - 7s - loss: 0.2101 - accuracy: 1.0000 - val_loss: 1.8248 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 310/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.9754 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 311/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 2.1575 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 312/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.7188 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 313/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.2224 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 314/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 1.6741 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 315/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.9658 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 316/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 2.4669 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 317/500\n",
            "1/1 - 7s - loss: 0.2100 - accuracy: 1.0000 - val_loss: 2.4022 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 318/500\n",
            "1/1 - 7s - loss: 0.2099 - accuracy: 1.0000 - val_loss: 1.4480 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 319/500\n",
            "1/1 - 7s - loss: 0.2098 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 320/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.1014 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 321/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.8416 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 322/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.5223 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 323/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.7939 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 324/500\n",
            "1/1 - 7s - loss: 0.2097 - accuracy: 1.0000 - val_loss: 2.5562 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 325/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.1018 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 326/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.1962 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 327/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 3.0195 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 328/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 3.3951 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 329/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 2.8633 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 330/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 2.7942 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 331/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.6413 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 332/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.4556 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 333/500\n",
            "1/1 - 7s - loss: 0.2095 - accuracy: 1.0000 - val_loss: 1.3717 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 334/500\n",
            "1/1 - 7s - loss: 0.2096 - accuracy: 1.0000 - val_loss: 1.2918 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 335/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.5861 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 336/500\n",
            "1/1 - 7s - loss: 0.2093 - accuracy: 1.0000 - val_loss: 1.2480 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 337/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.9586 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 338/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.7623 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 339/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 3.0629 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 340/500\n",
            "1/1 - 7s - loss: 0.2094 - accuracy: 1.0000 - val_loss: 2.2720 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 341/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.4069 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 342/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 2.1793 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 343/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 2.3924 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 344/500\n",
            "1/1 - 7s - loss: 0.2091 - accuracy: 1.0000 - val_loss: 1.8817 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 345/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.5562 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 346/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.6129 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 347/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.8063 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 348/500\n",
            "1/1 - 7s - loss: 0.2092 - accuracy: 1.0000 - val_loss: 1.6865 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 349/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.5364 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 350/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.5172 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 351/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.3742 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 352/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 1.7403 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 353/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 3.6872 - val_accuracy: 0.4706 - 7s/epoch - 7s/step\n",
            "Epoch 354/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 4.3237 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 355/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 3.8327 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 356/500\n",
            "1/1 - 7s - loss: 0.2090 - accuracy: 1.0000 - val_loss: 2.9038 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 357/500\n",
            "1/1 - 7s - loss: 0.2089 - accuracy: 1.0000 - val_loss: 3.0150 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 358/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 3.3247 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 359/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 2.8767 - val_accuracy: 0.4118 - 7s/epoch - 7s/step\n",
            "Epoch 360/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.9622 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 361/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.2343 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 362/500\n",
            "1/1 - 7s - loss: 0.2088 - accuracy: 1.0000 - val_loss: 1.7802 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 363/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.5728 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 364/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.5637 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 365/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.7842 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 366/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 2.0883 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 367/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.4290 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 368/500\n",
            "1/1 - 7s - loss: 0.2087 - accuracy: 1.0000 - val_loss: 1.5704 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 369/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 1.6948 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 370/500\n",
            "1/1 - 7s - loss: 0.2086 - accuracy: 1.0000 - val_loss: 1.6627 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 371/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.7572 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 372/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.3569 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 373/500\n",
            "1/1 - 7s - loss: 0.2085 - accuracy: 1.0000 - val_loss: 2.2538 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 374/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 2.4411 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 375/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 1.5053 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 376/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.4378 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 377/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.1482 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 378/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.8772 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 379/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.0449 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 380/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 1.8190 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 381/500\n",
            "1/1 - 7s - loss: 0.2083 - accuracy: 1.0000 - val_loss: 2.3097 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 382/500\n",
            "1/1 - 7s - loss: 0.2084 - accuracy: 1.0000 - val_loss: 1.9837 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 383/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 1.8924 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 384/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.1265 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 385/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.0001 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 386/500\n",
            "1/1 - 7s - loss: 0.2082 - accuracy: 1.0000 - val_loss: 2.0270 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 387/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.2214 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 388/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.2278 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 389/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 2.1601 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 390/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 2.2144 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 391/500\n",
            "1/1 - 7s - loss: 0.2081 - accuracy: 1.0000 - val_loss: 2.0501 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 392/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.7539 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 393/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.7074 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 394/500\n",
            "1/1 - 7s - loss: 0.2080 - accuracy: 1.0000 - val_loss: 1.5365 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 395/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.5181 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 396/500\n",
            "1/1 - 7s - loss: 0.2079 - accuracy: 1.0000 - val_loss: 1.9985 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 397/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.9078 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 398/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.6586 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 399/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.5074 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 400/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.5329 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 401/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 1.5118 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 402/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 1.4019 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 403/500\n",
            "1/1 - 7s - loss: 0.2078 - accuracy: 1.0000 - val_loss: 1.7413 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 404/500\n",
            "1/1 - 7s - loss: 0.2076 - accuracy: 1.0000 - val_loss: 2.7302 - val_accuracy: 0.3529 - 7s/epoch - 7s/step\n",
            "Epoch 405/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 2.6112 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 406/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 3.1676 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 407/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 2.8478 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 408/500\n",
            "1/1 - 7s - loss: 0.2077 - accuracy: 1.0000 - val_loss: 2.0067 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 409/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 410/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.4359 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 411/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.6695 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 412/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.9610 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 413/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.5559 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 414/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.4932 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 415/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.8507 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 416/500\n",
            "1/1 - 7s - loss: 0.2075 - accuracy: 1.0000 - val_loss: 1.5026 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 417/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.4902 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 418/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.6379 - val_accuracy: 0.5294 - 7s/epoch - 7s/step\n",
            "Epoch 419/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.5623 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 420/500\n",
            "1/1 - 7s - loss: 0.2074 - accuracy: 1.0000 - val_loss: 1.4134 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 421/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.3307 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 422/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.6291 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 423/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.5145 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 424/500\n",
            "1/1 - 7s - loss: 0.2073 - accuracy: 1.0000 - val_loss: 1.5797 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 425/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.8326 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 426/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.8463 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 427/500\n",
            "1/1 - 7s - loss: 0.2072 - accuracy: 1.0000 - val_loss: 1.9586 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 428/500\n",
            "1/1 - 7s - loss: 0.2071 - accuracy: 1.0000 - val_loss: 1.9576 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 429/500\n",
            "1/1 - 7s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 2.0055 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 430/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 1.9497 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 431/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.7289 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 432/500\n",
            "1/1 - 7s - loss: 0.2070 - accuracy: 1.0000 - val_loss: 1.4191 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 433/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 1.8813 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 434/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 3.3007 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 435/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 3.1260 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 436/500\n",
            "1/1 - 7s - loss: 0.2069 - accuracy: 1.0000 - val_loss: 2.3702 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 437/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.6692 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 438/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 2.4760 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 439/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 1.9473 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 440/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 1.2022 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 441/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 1.6594 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 442/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 1.6766 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 443/500\n",
            "1/1 - 7s - loss: 0.2068 - accuracy: 1.0000 - val_loss: 1.2307 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 444/500\n",
            "1/1 - 7s - loss: 0.2066 - accuracy: 1.0000 - val_loss: 1.1809 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 445/500\n",
            "1/1 - 7s - loss: 0.2067 - accuracy: 1.0000 - val_loss: 3.1468 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 446/500\n",
            "1/1 - 7s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 2.6550 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 447/500\n",
            "1/1 - 7s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.8270 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 448/500\n",
            "1/1 - 7s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.8184 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 449/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.4563 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 450/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.3888 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 451/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.3754 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 452/500\n",
            "1/1 - 7s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.3652 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 453/500\n",
            "1/1 - 7s - loss: 0.2065 - accuracy: 1.0000 - val_loss: 1.3254 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 454/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.3270 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 455/500\n",
            "1/1 - 7s - loss: 0.2063 - accuracy: 1.0000 - val_loss: 1.5072 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 456/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.2657 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 457/500\n",
            "1/1 - 7s - loss: 0.2063 - accuracy: 1.0000 - val_loss: 1.4636 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 458/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 1.6112 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 459/500\n",
            "1/1 - 7s - loss: 0.2063 - accuracy: 1.0000 - val_loss: 1.5478 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 460/500\n",
            "1/1 - 7s - loss: 0.2064 - accuracy: 1.0000 - val_loss: 3.2938 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 461/500\n",
            "1/1 - 7s - loss: 0.2062 - accuracy: 1.0000 - val_loss: 3.3538 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 462/500\n",
            "1/1 - 7s - loss: 0.2061 - accuracy: 1.0000 - val_loss: 2.3958 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 463/500\n",
            "1/1 - 7s - loss: 0.2062 - accuracy: 1.0000 - val_loss: 2.5532 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 464/500\n",
            "1/1 - 7s - loss: 0.2061 - accuracy: 1.0000 - val_loss: 3.1390 - val_accuracy: 0.6471 - 7s/epoch - 7s/step\n",
            "Epoch 465/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 3.0923 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 466/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 3.1165 - val_accuracy: 0.5882 - 7s/epoch - 7s/step\n",
            "Epoch 467/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.7610 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 468/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.5898 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 469/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.6613 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 470/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.7567 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 471/500\n",
            "1/1 - 7s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 2.1415 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 472/500\n",
            "1/1 - 7s - loss: 0.2060 - accuracy: 1.0000 - val_loss: 1.7465 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 473/500\n",
            "1/1 - 7s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 1.5845 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 474/500\n",
            "1/1 - 7s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 1.3639 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 475/500\n",
            "1/1 - 7s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 1.3483 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 476/500\n",
            "1/1 - 7s - loss: 0.2059 - accuracy: 1.0000 - val_loss: 1.9295 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 477/500\n",
            "1/1 - 7s - loss: 0.2058 - accuracy: 1.0000 - val_loss: 1.3841 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 478/500\n",
            "1/1 - 7s - loss: 0.2058 - accuracy: 1.0000 - val_loss: 1.4183 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 479/500\n",
            "1/1 - 7s - loss: 0.2057 - accuracy: 1.0000 - val_loss: 2.3005 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 480/500\n",
            "1/1 - 7s - loss: 0.2056 - accuracy: 1.0000 - val_loss: 2.1275 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 481/500\n",
            "1/1 - 7s - loss: 0.2056 - accuracy: 1.0000 - val_loss: 2.3695 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 482/500\n",
            "1/1 - 7s - loss: 0.2056 - accuracy: 1.0000 - val_loss: 2.2291 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 483/500\n",
            "1/1 - 7s - loss: 0.2056 - accuracy: 1.0000 - val_loss: 1.3409 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 484/500\n",
            "1/1 - 7s - loss: 0.2057 - accuracy: 1.0000 - val_loss: 1.3906 - val_accuracy: 0.8235 - 7s/epoch - 7s/step\n",
            "Epoch 485/500\n",
            "1/1 - 7s - loss: 0.2056 - accuracy: 1.0000 - val_loss: 1.4191 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 486/500\n",
            "1/1 - 7s - loss: 0.2055 - accuracy: 1.0000 - val_loss: 1.7698 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 487/500\n",
            "1/1 - 7s - loss: 0.2056 - accuracy: 1.0000 - val_loss: 1.5768 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 488/500\n",
            "1/1 - 7s - loss: 0.2055 - accuracy: 1.0000 - val_loss: 1.8371 - val_accuracy: 0.7059 - 7s/epoch - 7s/step\n",
            "Epoch 489/500\n",
            "1/1 - 7s - loss: 0.2054 - accuracy: 1.0000 - val_loss: 1.6500 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 490/500\n",
            "1/1 - 7s - loss: 0.2054 - accuracy: 1.0000 - val_loss: 1.6974 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 491/500\n",
            "1/1 - 7s - loss: 0.2054 - accuracy: 1.0000 - val_loss: 1.5906 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 492/500\n",
            "1/1 - 7s - loss: 0.2054 - accuracy: 1.0000 - val_loss: 1.7075 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 493/500\n",
            "1/1 - 7s - loss: 0.2053 - accuracy: 1.0000 - val_loss: 1.7009 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 494/500\n",
            "1/1 - 7s - loss: 0.2053 - accuracy: 1.0000 - val_loss: 1.5736 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 495/500\n",
            "1/1 - 7s - loss: 0.2052 - accuracy: 1.0000 - val_loss: 1.6054 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 496/500\n",
            "1/1 - 7s - loss: 0.2052 - accuracy: 1.0000 - val_loss: 1.6203 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 497/500\n",
            "1/1 - 7s - loss: 0.2053 - accuracy: 1.0000 - val_loss: 1.7098 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 498/500\n",
            "1/1 - 7s - loss: 0.2052 - accuracy: 1.0000 - val_loss: 1.7144 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 499/500\n",
            "1/1 - 7s - loss: 0.2052 - accuracy: 1.0000 - val_loss: 1.9751 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Epoch 500/500\n",
            "1/1 - 7s - loss: 0.2052 - accuracy: 1.0000 - val_loss: 1.4221 - val_accuracy: 0.7647 - 7s/epoch - 7s/step\n",
            "Time Bimodal_EEG+Data = 3628.9213507175446 [seconds]\n",
            "\n",
            "\n",
            "/content/logs/Bimodal_EEG+Data_2025-01-08_21-00-02\n",
            "saved-model-001-0.2353.hdf5\n",
            "Loss=1.3405 y Accuracy=0.2353\n",
            "\n",
            "saved-model-003-0.3529.hdf5\n",
            "Loss=1.3481 y Accuracy=0.3529\n",
            "\n",
            "saved-model-050-0.4706.hdf5\n",
            "Loss=2.0448 y Accuracy=0.4706\n",
            "\n",
            "saved-model-062-0.5882.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 510 calls to <function Model.make_test_function.<locals>.test_function at 0x7e82b9cb52d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=0.9915 y Accuracy=0.5882\n",
            "\n",
            "saved-model-063-0.7059.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 511 calls to <function Model.make_test_function.<locals>.test_function at 0x7e82b32db7f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss=0.9624 y Accuracy=0.7059\n",
            "\n",
            "saved-model-076-0.8235.hdf5\n",
            "Loss=0.7930 y Accuracy=0.8235\n",
            "\n",
            "\n",
            "\n",
            "Best\n",
            "saved-model-076-0.8235.hdf5\n",
            "Loss=0.7930 y Accuracy=0.8235\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title lr 0.0001\n",
        "batch_size = 128\n",
        "epochs = 500\n",
        "model_name = \"Bimodal_EEG+Data\"\n",
        "\n",
        "# Llamar a la función de entrenamiento\n",
        "results = train(\n",
        "    model=model,\n",
        "    X_train1=X_train_flat, X_train=X_train_img, y_train=y_train,  # Datos planos y Wavs para entrenamiento\n",
        "    X_valid1=X_test_flat, X_valid=X_test_img, y_valid=y_test,     # Usar datos planos y Wavs de X_test como validación\n",
        "    X_test1=X_test_flat, X_test=X_test_img, y_test=y_test,        # Conjunto de prueba\n",
        "    batch_size=batch_size, epochs=epochs,\n",
        "    model_name=model_name\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "12Kq1luXELUX",
        "9k6kPNDhFJS_",
        "kyE04oUjFOIq",
        "VD13NMM1FwOi",
        "4dmWVW-bF22N",
        "KbWdIqMHGXc9",
        "yNKHllLbMl-D",
        "3ad1-ZVaGZ2o",
        "EToG6mrvs9zr",
        "9HOwLcJxkDTu"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}